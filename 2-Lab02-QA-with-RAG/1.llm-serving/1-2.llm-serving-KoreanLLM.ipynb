{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e033ac1-83ae-4c0e-95b8-4a8753755335",
   "metadata": {
    "tags": []
   },
   "source": [
    "# llm-serving: Korean Model\n",
    "* Container: `Data Science 3.0` (studio, python 3.10), `conda_pytorch_p310` (notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b30f2-55c5-4fc0-8c1a-5f4ad3aad974",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 참조: \n",
    "- Model 정보\n",
    "    - beomi/KoAlpaca-Polyglot-12.8B\n",
    "        - This model is a fine-tuned version of EleutherAI/polyglot-ko-12.8b on a KoAlpaca Dataset v1.1b\n",
    "        - https://huggingface.co/beomi/KoAlpaca-Polyglot-12.8B\n",
    "    - EleutherAI/polyglot-ko-12.8b\n",
    "        - Polyglot-Ko-12.8B was trained for 167 billion tokens over 301,000 steps on 256 A100 GPUs with the GPT-NeoX framework. It was trained as an autoregressive language model, using cross-entropy loss to maximize the likelihood of predicting the next token.\n",
    "        - License: Apache 2.0\n",
    "        - https://huggingface.co/EleutherAI/polyglot-ko-12.8b\n",
    "    - nlpai-lab/kullm-polyglot-12.8b-v2\n",
    "        - https://huggingface.co/nlpai-lab/kullm-polyglot-12.8b-v2\n",
    "        \n",
    "- Doc\n",
    "    - Large model inference tutorials\n",
    "        - https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-tutorials.html\n",
    "    - Use DJL with the SageMaker Python SDK\n",
    "        - https://sagemaker.readthedocs.io/en/stable/frameworks/djl/using_djl.html\n",
    "        \n",
    "- 블로그\n",
    "    - https://aws.amazon.com/ko/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker-using-djlserving-and-deepspeed-model-parallel-inference/\n",
    "    - 코드\n",
    "        - https://github.com/aws/amazon-sagemaker-examples/blob/main/inference/generativeai/deepspeed/GPT-J-6B_DJLServing_with_PySDK.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5060b58-1783-4ea5-8bae-156cb6cd89d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Install packages and env. setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "670c3e1d-4d2f-4ed3-9a76-1a8f1b9879a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a93cc20f-04be-4fb9-84fa-83959c0c5b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../utils') # src 폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd85ffa-0162-4b00-83e1-de61ed7adf93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8448558f-4b94-4e87-8147-79200ae2cc72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already revised\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo service docker restart\n",
    "    echo \"Docker Restart\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f7bb5c4-9be9-4995-8d79-bad3578906bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (23.1.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.171.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.26.162)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.24.3)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.20.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.5.3)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.3.0)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML==6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (6.0)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.2.0)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (3.5.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.162 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.29.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.6.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.15.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema->sagemaker) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.6)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.2)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.14)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.162->boto3<2.0,>=1.26.131->sagemaker) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install -U sagemaker\n",
    "    \n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cec3ff-1138-4d44-aeb6-f80ca2e865a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. SageMaker endpoint 의 추론 도커 이미지 인 DLC image URL 가져오기\n",
    "- We get DLC image URL for djl-deepspeed 0.21.0 and set SageMaker settings\n",
    "- Deep learning contatiners\n",
    "    - https://github.com/aws/deep-learning-containers/blob/master/available_images.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "43e71bc1-1bf1-4da8-af4a-41908142caa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5ebcc39-75c7-41c5-801a-12cd4dc2e361",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "session = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = session._region_name\n",
    "bucket = session.default_bucket()  # bucket to house artifacts\n",
    "img_uri = image_uris.retrieve(framework=\"djl-deepspeed\", region=region, version=\"0.22.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58f4b182-6659-408b-bfc8-a66faa0b13b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE URI: 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.22.1-deepspeed0.9.2-cu118\n"
     ]
    }
   ],
   "source": [
    "print (f'IMAGE URI: {img_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5860876-b5d5-48ff-8a03-7067be9622c7",
   "metadata": {},
   "source": [
    "## 2. Set configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e87b06e0-27e6-4e0c-9244-ebb0795ca88f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b22daf-b7e4-4fd6-afea-b108f6526aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1. Model selection\n",
    "Korean LLMs: Kullm-polyglot-12-8b-v2, Polyglot-Kor-5-8B, KoAlpaca-12-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae4cac8d-36c1-4753-9c8b-5de56dc5fd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serve_model = \"Kullm-polyglot-12-8b-v2\"\n",
    "model_artifact_name = f'./models/{serve_model}.tar.gz' # 모델 패키징 할 파일 이름\n",
    "serve_model_path = f'./models/{serve_model}'\n",
    "s3_location = f's3://{bucket}/{serve_model}' # 모델 패키징 S3 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13f7a8ad-7b5b-48ce-8961-a4fd79e0fcea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serve_model:  Kullm-polyglot-12-8b-v2\n",
      "model_artifact_name:  ./models/Kullm-polyglot-12-8b-v2.tar.gz\n",
      "serve_model_path:  ./models/Kullm-polyglot-12-8b-v2\n",
      "model packaging s3 location:  s3://sagemaker-us-east-1-419974056037/Kullm-polyglot-12-8b-v2\n"
     ]
    }
   ],
   "source": [
    "print(\"serve_model: \", serve_model)\n",
    "print(\"model_artifact_name: \", model_artifact_name)\n",
    "print(\"serve_model_path: \", serve_model_path)\n",
    "print(\"model packaging s3 location: \", s3_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e6dda-1cf0-4102-a5db-58c11962527f",
   "metadata": {},
   "source": [
    "### Step 2.2. Create a `model.py` and `serving.properties`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b0e2fa-1f0c-4a95-9e8f-ef7bff1d0f7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.1. model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5588e1a0-f8ab-48d8-afad-a2199baee431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./models/Kullm-polyglot-12-8b-v2/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./models/Kullm-polyglot-12-8b-v2/model.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import deepspeed\n",
    "from djl_python import Input, Output\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, GPTNeoXLayer\n",
    "\n",
    "predictor = None\n",
    "\n",
    "def get_model(properties):\n",
    "    \n",
    "    model_name = \"nlpai-lab/kullm-polyglot-12.8b-v2\"\n",
    "    tensor_parallel = properties[\"tensor_parallel_degree\"]\n",
    "    local_rank = int(os.getenv(\"LOCAL_RANK\", \"0\"))\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    model.eval()\n",
    "    model = deepspeed.init_inference(\n",
    "        model,\n",
    "        mp_size=tensor_parallel,\n",
    "        dtype=model.dtype,\n",
    "        replace_method=\"auto\",\n",
    "        #replace_with_kernel_inject=True,\n",
    "        injection_policy={\n",
    "            GPTNeoXLayer:('attention.dense', 'mlp.dense_4h_to_h')\n",
    "        }\n",
    "    )\n",
    "    generator = pipeline(\n",
    "        task=\"text-generation\", model=model, tokenizer=tokenizer, device=local_rank\n",
    "    )\n",
    "    # https://huggingface.co/docs/hub/models-tasks\n",
    "    return generator\n",
    "    \n",
    "def handle(inputs: Input) -> None:\n",
    "    \n",
    "    global predictor\n",
    "    if not predictor:\n",
    "        predictor = get_model(inputs.get_properties())\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        print (\"is_empty\")\n",
    "        return None\n",
    "\n",
    "    data = inputs.get_as_json() #inputs.get_as_string()\n",
    "    \n",
    "    print (\"data:\",  data)\n",
    "    \n",
    "    input_prompt, params = data[\"prompt\"], data[\"params\"]\n",
    "    \n",
    "    print (\"input_prompt\", input_prompt)\n",
    "    print (\"params\", params)\n",
    "    \n",
    "    result = predictor(\n",
    "        input_prompt,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    print (\"result:\", result)\n",
    "    return Output().add_as_json(result) #Output().add(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fde59-6f16-4e1a-bfbb-1918e7447ea7",
   "metadata": {},
   "source": [
    "#### 2.2.2. serving.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "65f579bd-2694-4f2e-8fe6-c516953ccb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./models/Kullm-polyglot-12-8b-v2/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./models/Kullm-polyglot-12-8b-v2/serving.properties\n",
    "\n",
    "engine = DeepSpeed\n",
    "\n",
    "# passing extra options to model.py or built-in handler\n",
    "job_queue_size=100\n",
    "batch_size=1\n",
    "max_batch_delay=1\n",
    "max_idle_time=60\n",
    "#gpu.minWorkers=4\n",
    "#gpu.maxWorkers=4 \n",
    "\n",
    "# defines custom environment variables\n",
    "#env=SERVING_NUMBER_OF_NETTY_THREADS=2\n",
    "\n",
    "# Allows to load DeepSpeed workers in parallel\n",
    "option.parallel_loading=true\n",
    "\n",
    "# specify tensor parallel degree (number of partitions)\n",
    "option.tensor_parallel_degree=4\n",
    "\n",
    "# specify per model timeout\n",
    "option.model_loading_timeout=600\n",
    "option.predict_timeout=240\n",
    "\n",
    "# mark the model as failure after python process crashing 10 times\n",
    "retry_threshold=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be1f7e8-45e4-4c7c-8d15-89774109e5c6",
   "metadata": {},
   "source": [
    "### 2.3. mode selection (local/cloud)\n",
    " - **local 모드의 경우 현재 error 발생, 원인 파악중**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4366a5e8-b066-4f92-a247-0b01c5b80505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_local_mode = False\n",
    "\n",
    "if use_local_mode:\n",
    "    instance_type = \"local_gpu\"\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "else:\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    instance_type = \"ml.g5.12xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31751a3f-5e57-49cc-a854-0b819d83540a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance_type  : ml.g5.12xlarge\n"
     ]
    }
   ],
   "source": [
    "print(\"instance_type  :\", instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26107e0-3d8b-4ef6-9eff-f84ec77d56bb",
   "metadata": {},
   "source": [
    "## 3. model packaging\n",
    "- `model.py` and `serving.properties`\n",
    "- The code below creates the SageMaker model file (`model.tar.gz`) and upload it to S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c433e6e0-8eef-4453-9391-18c5f4818e73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/Kullm-polyglot-12-8b-v2\n",
      "./models/Kullm-polyglot-12-8b-v2.tar.gz\n",
      "./models/Kullm-polyglot-12-8b-v2/\n",
      "./models/Kullm-polyglot-12-8b-v2/serving.properties\n",
      "./models/Kullm-polyglot-12-8b-v2/model.py\n",
      "./models/Kullm-polyglot-12-8b-v2/.ipynb_checkpoints/\n",
      "./models/Kullm-polyglot-12-8b-v2/.ipynb_checkpoints/model-checkpoint.py\n",
      "./models/Kullm-polyglot-12-8b-v2/.ipynb_checkpoints/serving-checkpoint.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh -s {serve_model_path} {model_artifact_name}\n",
    "serve_model=$1\n",
    "model_artifact_name=$2\n",
    "echo $serve_model\n",
    "echo $model_artifact_name\n",
    "rm -rf $serve_model_path/.ipynb_checkpoints\n",
    "tar -czvf $model_artifact_name $serve_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c6c358-208e-43da-a9b6-98bf29ba4e09",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. upload model package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8a999ac5-3713-4baa-9551-c016e74ece77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_tar_url = sagemaker.s3.S3Uploader.upload(model_artifact_name, s3_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f2127fcd-1eeb-4775-8dc0-49a29ca51fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_tar_url:  s3://sagemaker-us-east-1-419974056037/Kullm-polyglot-12-8b-v2/Kullm-polyglot-12-8b-v2.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"model_tar_url: \", model_tar_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2229110-5b8d-4797-b4cc-a503d4b04804",
   "metadata": {},
   "source": [
    "## 5. create sagemaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1d12618-616a-4480-b4fa-b49b62fcc2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import image_uris, get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cef06eb-34d7-4958-93ca-28319128d757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(model_name, role, sagemaker_session, inference_image_uri, model_s3_url):\n",
    "    model = Model(\n",
    "        image_uri=inference_image_uri,\n",
    "        model_data=model_s3_url,\n",
    "        role=role,\n",
    "        name=model_name,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "77879c29-ce9b-431c-9f0c-e2f213d10cf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "model_name = f'{serve_model}-' + time_stamp\n",
    "sm_model = create_model(model_name, role, sagemaker_session, img_uri, model_tar_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf84be-565e-4eaf-8f85-fafb22f9c012",
   "metadata": {},
   "source": [
    "## 6. create sagemaker endpoint\n",
    "- It will take about 10 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf199e49-5589-4ab4-9039-b023fffa6e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serializers, deserializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f440e6c1-5891-48e9-84da-c569fba94b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deploy_model(model, sagemaker_session, instance_type, _endpoint_name):\n",
    "    model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=instance_type,\n",
    "        endpoint_name=_endpoint_name\n",
    "    )\n",
    "    predictor = sagemaker.Predictor(\n",
    "        endpoint_name=_endpoint_name,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        serializer=serializers.JSONSerializer(),\n",
    "        deserializer=deserializers.JSONDeserializer()\n",
    "    )\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76d37fbd-9a71-4306-9db7-dbfd5bc40d95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------!CPU times: user 138 ms, sys: 10.9 ms, total: 149 ms\n",
      "Wall time: 11min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "endpoint_name = f'{serve_model}-' + time_stamp\n",
    "predictor = deploy_model(sm_model, sagemaker_session, instance_type, endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "631caf3e-7ecc-4892-be6e-66ec106483e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint_name:  Kullm-polyglot-12-8b-v2-2023-07-10-05-48-59\n"
     ]
    }
   ],
   "source": [
    "print(\"endpoint_name: \", predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9218113e-a096-40ed-ac7c-b3909676f70a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 7. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef93f8c-0007-4d1f-a36f-8fb7296d516a",
   "metadata": {},
   "source": [
    "### 7.1 Prompt setting for Kullm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5e2b7cb2-3b80-4862-969a-cb4ea5109138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inference_utils import Prompter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df4e75dd-6e7d-473c-b9c9-1c41c336dc3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompter = Prompter(\"kullm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a8e0e-f3e6-4975-b725-289e247ff998",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7.2 Generator parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3051fc-ee61-458f-aa64-0a686d61ac99",
   "metadata": {
    "tags": []
   },
   "source": [
    "### options for generation\n",
    "* **temperature**: Controls randomness in the model. Lower values will make the model more deterministic and higher values will make the model more random. Default value is 1.0.\n",
    "* **max_new_tokens**: The maximum number of tokens to generate. Default value is 20, max value is 512.\n",
    "* **repetition_penalty**: Controls the likelihood of repetition, defaults to null.\n",
    "* **seed**: The seed to use for random generation, default is null.\n",
    "* **stop**: A list of tokens to stop the generation. The generation will stop when one of the tokens is generated.\n",
    "* **top_k**: The number of highest probability vocabulary tokens to keep for top-k-filtering. Default value is null, which disables top-k-filtering.\n",
    "* **top_p**: The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling, default to null\n",
    "* **do_sample**: Whether or not to use sampling ; use greedy decoding otherwise. Default value is false.\n",
    "* **best_of**: Generate best_of sequences and return the one if the highest token logprobs, default to null.\n",
    "* **details**: Whether or not to return details about the generation. Default value is false.\n",
    "* **return_full_text**: Whether or not to return the full text or only the generated part. Default value is false.\n",
    "* **truncate**: Whether or not to truncate the input to the maximum length of the model. Default value is true.\n",
    "* **typical_p**: The typical probability of a token. Default value is null.\n",
    "* **watermark**: The watermark to use for the generation. Default value is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d3ed9b6-a002-4ce4-a6a4-eeddbfcd2189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"do_sample\":False, \n",
    "    \"max_new_tokens\":128,\n",
    "    \"temperature\":0,\n",
    "    \"top_k\":0,\n",
    "    \"top_p\":0.9,\n",
    "    \"return_full_text\":False,\n",
    "    \"repetition_penalty\":1.1,\n",
    "    \"presence_penalty\":None,\n",
    "    \"eos_token_id\":2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a75fac-9a71-4760-8bf6-230ab6644009",
   "metadata": {},
   "source": [
    "### 7.3 QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48a39520-8963-4471-916e-27de8cf712d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from inference_utils import invoke_inference, parse_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd2cc071-528e-4df1-a886-e728e98b0603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \"타워의 높이는 330미터 (1,083피트), [6] 81층 건물과 거의 같은 높이이며 파리에서 가장 높은 구조물입니다.밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\"\n",
    "false_context = \"타워의 높이는 3미터 (10피트) 이고 [6] 높이는 81층 건물과 거의 같으며 파리에서 가장 높은 구조물입니다.밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\"\n",
    "irrelevant_context = \"밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf951719-9292-424c-8f35-6a5a8edb6cc6",
   "metadata": {},
   "source": [
    "True context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "35702944-aae3-42a4-879f-c5cbafc42b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      " 아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "에펠탑의 높이는 얼마입니까?\n",
      "\n",
      "### 입력:\n",
      "타워의 높이는 330미터 (1,083피트), [6] 81층 건물과 거의 같은 높이이며 파리에서 가장 높은 구조물입니다.밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\n",
      "\n",
      "### 응답:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"에펠탑의 높이는 얼마입니까?\"\n",
    "c = context\n",
    "prompt = prompter.generate_prompt(q, c)\n",
    "data = {\n",
    "    \"prompt\": [prompt,],\n",
    "    \"params\": params\n",
    "}\n",
    "print(\"prompt: \\n\", data[\"prompt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5ab138b7-3107-4109-9b81-dc0290b1d028",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 ms, sys: 61 µs, total: 21 ms\n",
      "Wall time: 2.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'에펠탑의 높이는 330미터(1,083피트)입니다.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "res = invoke_inference(endpoint_name, data)\n",
    "parse_response(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3a824-b878-446e-b584-c178db20087b",
   "metadata": {},
   "source": [
    "False context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a40eb74-328b-40e6-8545-37182c81e6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      " 아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "에펠탑의 높이는 얼마입니까?\n",
      "\n",
      "### 입력:\n",
      "타워의 높이는 3미터 (10피트) 이고 [6] 높이는 81층 건물과 거의 같으며 파리에서 가장 높은 구조물입니다.밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\n",
      "\n",
      "### 응답:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"에펠탑의 높이는 얼마입니까?\"\n",
    "c = false_context\n",
    "prompt = prompter.generate_prompt(q, c)\n",
    "data = {\n",
    "    \"prompt\": [prompt,],\n",
    "    \"params\": params\n",
    "}\n",
    "print(\"prompt: \\n\", data[\"prompt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65800ab1-9380-467c-8d9d-83cef0f5ae2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 0 ns, total: 19.9 ms\n",
      "Wall time: 993 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'에펠탑의 높이는 약 3미터(10피트)입니다.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "res = invoke_inference(endpoint_name, data)\n",
    "parse_response(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ca725-fc9b-491b-aa68-fb6f92704195",
   "metadata": {},
   "source": [
    "Irrelevant context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8db26974-bb59-44c3-b6e8-a7d3c6c32cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      " 아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "에펠탑의 높이는 얼마입니까?\n",
      "\n",
      "### 입력:\n",
      "밑면은 정사각형이며 각 변의 크기는 125미터 (410피트) 입니다.건설 기간 동안 에펠탑은 워싱턴 기념탑을 제치고 세계에서 가장 높은 인공 건축물이 되었으며, 1930년 뉴욕 크라이슬러 빌딩이 완공될 때까지 41년 동안 이 타이틀을 유지했습니다.높이 200m와 300m를 모두 뛰어넘은 세계 최초의 구조물이었습니다.1957년 타워 꼭대기에 방송 안테나가 추가되면서 지금은 크라이슬러 빌딩보다 5.2미터 (17피트) 더 높아졌습니다.송신기를 제외하고 에펠탑은 미요 육교 다음으로 프랑스에서 두 번째로 높은 독립형 건축물입니다.\n",
      "\n",
      "### 응답:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"에펠탑의 높이는 얼마입니까?\"\n",
    "c = irrelevant_context\n",
    "prompt = prompter.generate_prompt(q, c)\n",
    "data = {\n",
    "    \"prompt\": [prompt,],\n",
    "    \"params\": params\n",
    "}\n",
    "print(\"prompt: \\n\", data[\"prompt\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2afcca47-d961-43cc-bc2f-be804330e4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 317 µs, total: 21.4 ms\n",
      "Wall time: 1.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'에펠탑의 높이는 약 324미터(984피트)입니다.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "res = invoke_inference(endpoint_name, data)\n",
    "parse_response(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c6581-dd87-4c9c-9c67-9840cbeb4163",
   "metadata": {},
   "source": [
    "## 8. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06165798-e258-46d7-95f9-144177f0429a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8.1. Delete the endpoint\n",
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5455a222-422b-4daa-8a10-07e4e48c9323",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class clean_up():\n",
    "    \n",
    "    def __init__(self, ):    \n",
    "        pass\n",
    "    \n",
    "    def delete_endpoint(self, client, endpoint_name ,is_del_model=True):\n",
    "        \n",
    "        response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "        EndpointConfigName = response['EndpointConfigName']\n",
    "\n",
    "        response = client.describe_endpoint_config(EndpointConfigName=EndpointConfigName)\n",
    "        model_name = response['ProductionVariants'][0]['ModelName']    \n",
    "\n",
    "        if is_del_model: # 모델도 삭제 여부 임.\n",
    "            client.delete_model(ModelName=model_name)    \n",
    "\n",
    "        client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        client.delete_endpoint_config(EndpointConfigName=EndpointConfigName)    \n",
    "\n",
    "        print(f'--- Deleted model: {model_name}')\n",
    "        print(f'--- Deleted endpoint: {endpoint_name}')\n",
    "        print(f'--- Deleted endpoint_config: {EndpointConfigName}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "184ecbb7-ed79-415d-a06e-4ada3deadb47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Deleted model: Kullm-polyglot-12-8b-v2-2023-07-10-04-48-35\n",
      "--- Deleted endpoint: Kullm-polyglot-12-8b-v2-2023-07-10-04-48-35\n",
      "--- Deleted endpoint_config: Kullm-polyglot-12-8b-v2-2023-07-10-04-48-35\n"
     ]
    }
   ],
   "source": [
    "clean = clean_up()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "## 2.training \n",
    "clean.delete_endpoint(sm_client, endpoint_name ,is_del_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62109e4-08cb-4563-8d76-d9eb8fb562f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
