{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# 로컬에서 훈련 하기\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b5f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "!huggingface-cli login --token {HF_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcebd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_DATASETS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_HOME'] = \"/home/ec2-user/SageMaker/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24bce431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder:  ../data/naver-news-summarization-ko\n",
      "train_data_json:  ../data/naver-news-summarization-ko/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "%store -r data_folder\n",
    "%store -r train_data_json \n",
    "%store -r validation_data_json \n",
    "%store -r test_data_json \n",
    "\n",
    "print(\"data_folder: \", data_folder)\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f53c-d21d-4fca-b69d-6a85d966353c",
   "metadata": {},
   "source": [
    "## 2. 베이스 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d514e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "output_dir = \"/home/ec2-user/SageMaker/models/llama-3-8b-naver-news\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403f6b8",
   "metadata": {},
   "source": [
    "### Config YAML 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72d30120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile llama_3_8b_fsdp_qlora.yaml\n",
    "# script parameters\n",
    "model_id:  \"meta-llama/Meta-Llama-3-8B\" # Hugging Face model id\n",
    "dataset_path: \"../data/naver-news-summarization-ko\"                      # path to dataset\n",
    "max_seq_len:  2048              # max sequence length for model and packing of the dataset\n",
    "# training parameters\n",
    "output_dir: \"/home/ec2-user/SageMaker/models/llama-3-8b-naver-news\" # Temporary output directory for model checkpoints\n",
    "report_to: \"tensorboard\"               # report metrics to tensorboard\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap offload\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851f75d",
   "metadata": {},
   "source": [
    "## 3. 훈련 Script 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-28 14:15:58,314] torch.distributed.run: [WARNING] \n",
      "[2024-06-28 14:15:58,314] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-06-28 14:15:58,314] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-06-28 14:15:58,314] torch.distributed.run: [WARNING] *****************************************\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "[W Utils.hpp:133] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function getCvarInt)\n",
      "## script_args: \n",
      " ScriptArguments(dataset_path='../data/naver-news-summarization-ko', model_id='meta-llama/Meta-Llama-3-8B', max_seq_length=512)\n",
      "## training_args: \n",
      " TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>, <FSDPOption.OFFLOAD: 'offload'>],\n",
      "fsdp_config={'backward_prefetch': 'backward_pre', 'forward_prefetch': 'false', 'use_orig_params': 'false', 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news/runs/Jun28_14-16-01_ip-172-16-162-249.ec2.internal,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=0.3,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "## script_args.dataset_path: \n",
      " ../data/naver-news-summarization-ko\n",
      "Generating train split: 10 examples [00:00, 2757.96 examples/s]\n",
      "Generating train split: 10 examples [00:00, 9644.30 examples/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████████████████████████| 10/10 [00:00<00:00, 392.42 examples/s]\n",
      "Map: 100%|█████████████████████████████| 10/10 [00:00<00:00, 2691.07 examples/s]\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "SK바이오사이언스가 글로벌 사업의 고도화를 위해 조직 개편을 단행했다. SK바이오사이언스는 기존 해외사업개발실을 BD Business Development 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직인 Global RA Regulatory Affairs 실을 신설한다고 1일 밝혔다. SK바이오사이언스는 지난해 코로나19 COVID 19 백신 위탁 생산 등으로 주목받는 백신 기업으로 부상하며 글로벌 사업의 영역과 규모가 급속도로 성장 중이다. 이러한 성장 속도에 맞춰 기존 전담 조직인 해외사업개발실을 보다 세분화 및 전문화하고자 BD 1 3실로 확대 재편했다. BD 1 3실은 앞으로 기존에 영위 중인 백신 사업뿐만 아니라 세포·유전자치료제 CGT 등 신규 사업에 대한 △글로벌 네트워크들과의 공동 개발 △신규 C D MO 수주 △개발 제품 상업화 등 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당한다. 또한 Global RA실을 신설해 미국 유럽 등 해외 선진국의 GMP Good Manufacturing Practice 를 확보하는 등 국제적인 수준의 관련 인증 및 허가 획득에도 더욱 박차를 가할 방침이다. CMC팀도 신설됐다. CMC는 화학 Chemistry 제조 Manufacturing 품질 Control 의 약자다. CMC팀은 완제 의약품을 만드는 공정 개발 process development 과 품질 관리 quality control 부문에서 핵심적인 역할을 수행한다. 연구부터 임상 허가 생산 품질에 이르는 GMP 관련 제반 업무를 관리한다. SK바이오사이언스는 이번 조직 개편이 글로벌 탑티어 바이오 기업으로의 성장을 더욱 앞당기고 초격차 경쟁력 확보의 계기가 될 것으로 기대하고 있다. SK바이오사이언스는 지난달 29일 국내 최초 코로나19 백신인 스카이코비원 SKYCovione 멀티주 의 품목허가를 획득했다. 이어 국가출하승인 및 WHO 등 해외 승인을 통해 국내외 백신 시장에 본격 진출할 예정이다.<|end_of_text|>\n",
      "\n",
      "Assistant: SK바이오사이언스가 글로벌 사업의 고도화를 위해 기존 해외사업개발실을 백신사업뿐만 아니라 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당하는 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직을 신설한다고 1일 밝혔다.<|end_of_text|>\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "한탄바이러스 발견 노벨상 유력 후보로 자주 거론 한국을 대표하는 의학자이자 미생물학자 이호왕 고려대 명예교수. 고려대의대 제공 한탄바이러스를 발견한 우리나라 대표 의과학자 이호왕 고려대 명예교수가 5일 숙환으로 별세했다. 향년 94세. 고인은 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자다. 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다. 1928년 함경남도 신흥에서 출생한 고인은 1973년 고대의대에 부임해 의과대학장을 지냈으며 1982년 세계보건기구 신증후출혈열연구협력센터 소장 2000년 대한민국학술원 회장 등을 역임했다. 1979년 미국 최고민간인공로훈장 1987년 인촌상 1992년 호암상 1995년 태국 프린스 마히돌상 2001년 일본 니케이 아시아상 2002년 과학기술훈장 창조장 2009년 서재필의학상 2018년 대한민국 과학기술유공자로 추대됐으며 2002년 미국 학술원 NAS 외국회원 2009년 일본 학사원 명예회원에 선정되며 국내외 학계에서 활발한 활동을 이어왔다. 고인의 빈소는 고려대 안암병원 장례식장 303호에 마련됐다. 발인은 7일 오전 11시 50분이고 장지는 서울추모공원이다. 고인은 1976년 3월 경기도 동두천 한탄강 유역에서 채집한 등줄쥐의 폐 조직에서 세계 최초로 유행성출혈열 병원체와 면역체를 발견한 것으로 널리 알려졌다. 고인은 이 병원체 바이러스를 발견장소의 이름을 따 명명했다. 그 유명한 한탄 바이러스 의 발견이었다. 고인이 병원체를 발견하기 전까지 이 유행성출혈열은 당시 정체불명의 괴질로 유명했다. 1916년 러시아 블라디보스토크에서 첫 환자가 보고된 뒤 2차 세계대전과 6·25전쟁을 거치며 수천 명의 희생자를 냈다. 당시 소련과 중국은 대대적인 인체실험까지 벌였고 미국은 노벨상 수상자 2명이 포함된 연구진 200여명과 막대한 예산을 투입해 정체를 밝히려고 애썼지만 감염 경로와 원인 병원체를 찾지 못했다. 한탄바이러스가 발견된 이후 국내에선 백신제조까지 일사천리로 이뤄졌다. 1991년 녹십자는 고인과 공동연구를 유행성출혈열 예방 백신 ‘한타 박스’를 내놨다. 바이러스 발견자가 진단법과 예방 백신까지 개발한 최초 사례다. 지금도 휴전선 일대에 근무하는 군인과 주민은 이 주사를 맞는다. 고인은 한탄바이러스 분리와 백신 개발로 유력한 노벨상 수상자로 거론되기도 했다. 2019년 9월 연구데이터 분석기업 클래리베이터 애널리틱스가 선정한 ‘2021년 피인용 우수 연구자’ 16명 중 한 명으로 꼽혔기 때문이다. 당시 국내 기관 소속 연구자로는 다섯 번째 한국인으로는 네 번째였다. 클래리베이트의 피인용 우수 연구자는 1970년 이후 등록된 과학기술인용색인 SCI 논문 5200만여 건 중 최상위 0.01%에 속하는 2000회 이상 인용된 논문을 보유하면서 동시에 연구가 독창적이고 인류에 높은 공헌을 한 경우 선정된다. 노벨상 수상의 예측 지표 중 하나로 여겨진다. 고인은 또한 한국인이 사랑하는 근대 과학자였다. 지난 2016년 과학기술정보통신부 전신인 미래창조과학부와 한국과학창의재단 한국경제신문이 진행한 우리 생활을 변화시킨 근현대 대표 과학기술인’ 조사에서 한국이 낳은 세계적 물리학자인 고 故 이휘소 박사가 대한민국 최고 과학자에 이어 고인을 두 번째로 많이 꼽았다.<|end_of_text|>\n",
      "\n",
      "Assistant: 이 이호왕 고려대 명예교수는 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자이며, 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다.<|end_of_text|>\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "SK바이오사이언스가 글로벌 사업의 고도화를 위해 조직 개편을 단행했다. SK바이오사이언스는 기존 해외사업개발실을 BD Business Development 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직인 Global RA Regulatory Affairs 실을 신설한다고 1일 밝혔다. SK바이오사이언스는 지난해 코로나19 COVID 19 백신 위탁 생산 등으로 주목받는 백신 기업으로 부상하며 글로벌 사업의 영역과 규모가 급속도로 성장 중이다. 이러한 성장 속도에 맞춰 기존 전담 조직인 해외사업개발실을 보다 세분화 및 전문화하고자 BD 1 3실로 확대 재편했다. BD 1 3실은 앞으로 기존에 영위 중인 백신 사업뿐만 아니라 세포·유전자치료제 CGT 등 신규 사업에 대한 △글로벌 네트워크들과의 공동 개발 △신규 C D MO 수주 △개발 제품 상업화 등 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당한다. 또한 Global RA실을 신설해 미국 유럽 등 해외 선진국의 GMP Good Manufacturing Practice 를 확보하는 등 국제적인 수준의 관련 인증 및 허가 획득에도 더욱 박차를 가할 방침이다. CMC팀도 신설됐다. CMC는 화학 Chemistry 제조 Manufacturing 품질 Control 의 약자다. CMC팀은 완제 의약품을 만드는 공정 개발 process development 과 품질 관리 quality control 부문에서 핵심적인 역할을 수행한다. 연구부터 임상 허가 생산 품질에 이르는 GMP 관련 제반 업무를 관리한다. SK바이오사이언스는 이번 조직 개편이 글로벌 탑티어 바이오 기업으로의 성장을 더욱 앞당기고 초격차 경쟁력 확보의 계기가 될 것으로 기대하고 있다. SK바이오사이언스는 지난달 29일 국내 최초 코로나19 백신인 스카이코비원 SKYCovione 멀티주 의 품목허가를 획득했다. 이어 국가출하승인 및 WHO 등 해외 승인을 통해 국내외 백신 시장에 본격 진출할 예정이다.<|end_of_text|>\n",
      "\n",
      "Assistant: SK바이오사이언스가 글로벌 사업의 고도화를 위해 기존 해외사업개발실을 백신사업뿐만 아니라 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당하는 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직을 신설한다고 1일 밝혔다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "SK바이오사이언스가 글로벌 사업의 고도화를 위해 조직 개편을 단행했다. SK바이오사이언스는 기존 해외사업개발실을 BD Business Development 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직인 Global RA Regulatory Affairs 실을 신설한다고 1일 밝혔다. SK바이오사이언스는 지난해 코로나19 COVID 19 백신 위탁 생산 등으로 주목받는 백신 기업으로 부상하며 글로벌 사업의 영역과 규모가 급속도로 성장 중이다. 이러한 성장 속도에 맞춰 기존 전담 조직인 해외사업개발실을 보다 세분화 및 전문화하고자 BD 1 3실로 확대 재편했다. BD 1 3실은 앞으로 기존에 영위 중인 백신 사업뿐만 아니라 세포·유전자치료제 CGT 등 신규 사업에 대한 △글로벌 네트워크들과의 공동 개발 △신규 C D MO 수주 △개발 제품 상업화 등 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당한다. 또한 Global RA실을 신설해 미국 유럽 등 해외 선진국의 GMP Good Manufacturing Practice 를 확보하는 등 국제적인 수준의 관련 인증 및 허가 획득에도 더욱 박차를 가할 방침이다. CMC팀도 신설됐다. CMC는 화학 Chemistry 제조 Manufacturing 품질 Control 의 약자다. CMC팀은 완제 의약품을 만드는 공정 개발 process development 과 품질 관리 quality control 부문에서 핵심적인 역할을 수행한다. 연구부터 임상 허가 생산 품질에 이르는 GMP 관련 제반 업무를 관리한다. SK바이오사이언스는 이번 조직 개편이 글로벌 탑티어 바이오 기업으로의 성장을 더욱 앞당기고 초격차 경쟁력 확보의 계기가 될 것으로 기대하고 있다. SK바이오사이언스는 지난달 29일 국내 최초 코로나19 백신인 스카이코비원 SKYCovione 멀티주 의 품목허가를 획득했다. 이어 국가출하승인 및 WHO 등 해외 승인을 통해 국내외 백신 시장에 본격 진출할 예정이다.<|end_of_text|>\n",
      "\n",
      "Assistant: SK바이오사이언스가 글로벌 사업의 고도화를 위해 기존 해외사업개발실을 백신사업뿐만 아니라 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당하는 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직을 신설한다고 1일 밝혔다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "SK바이오사이언스가 글로벌 사업의 고도화를 위해 조직 개편을 단행했다. SK바이오사이언스는 기존 해외사업개발실을 BD Business Development 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직인 Global RA Regulatory Affairs 실을 신설한다고 1일 밝혔다. SK바이오사이언스는 지난해 코로나19 COVID 19 백신 위탁 생산 등으로 주목받는 백신 기업으로 부상하며 글로벌 사업의 영역과 규모가 급속도로 성장 중이다. 이러한 성장 속도에 맞춰 기존 전담 조직인 해외사업개발실을 보다 세분화 및 전문화하고자 BD 1 3실로 확대 재편했다. BD 1 3실은 앞으로 기존에 영위 중인 백신 사업뿐만 아니라 세포·유전자치료제 CGT 등 신규 사업에 대한 △글로벌 네트워크들과의 공동 개발 △신규 C D MO 수주 △개발 제품 상업화 등 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당한다. 또한 Global RA실을 신설해 미국 유럽 등 해외 선진국의 GMP Good Manufacturing Practice 를 확보하는 등 국제적인 수준의 관련 인증 및 허가 획득에도 더욱 박차를 가할 방침이다. CMC팀도 신설됐다. CMC는 화학 Chemistry 제조 Manufacturing 품질 Control 의 약자다. CMC팀은 완제 의약품을 만드는 공정 개발 process development 과 품질 관리 quality control 부문에서 핵심적인 역할을 수행한다. 연구부터 임상 허가 생산 품질에 이르는 GMP 관련 제반 업무를 관리한다. SK바이오사이언스는 이번 조직 개편이 글로벌 탑티어 바이오 기업으로의 성장을 더욱 앞당기고 초격차 경쟁력 확보의 계기가 될 것으로 기대하고 있다. SK바이오사이언스는 지난달 29일 국내 최초 코로나19 백신인 스카이코비원 SKYCovione 멀티주 의 품목허가를 획득했다. 이어 국가출하승인 및 WHO 등 해외 승인을 통해 국내외 백신 시장에 본격 진출할 예정이다.<|end_of_text|>\n",
      "\n",
      "Assistant: SK바이오사이언스가 글로벌 사업의 고도화를 위해 기존 해외사업개발실을 백신사업뿐만 아니라 다양한 영역의 사업을 고도화하고 실행력을 높이는 업무를 담당하는 1 3실로 확대 재편하고 글로벌 규제 및 허가 전담 조직을 신설한다고 1일 밝혔다.<|end_of_text|>\n",
      "\n",
      "\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "한탄바이러스 발견 노벨상 유력 후보로 자주 거론 한국을 대표하는 의학자이자 미생물학자 이호왕 고려대 명예교수. 고려대의대 제공 한탄바이러스를 발견한 우리나라 대표 의과학자 이호왕 고려대 명예교수가 5일 숙환으로 별세했다. 향년 94세. 고인은 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자다. 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다. 1928년 함경남도 신흥에서 출생한 고인은 1973년 고대의대에 부임해 의과대학장을 지냈으며 1982년 세계보건기구 신증후출혈열연구협력센터 소장 2000년 대한민국학술원 회장 등을 역임했다. 1979년 미국 최고민간인공로훈장 1987년 인촌상 1992년 호암상 1995년 태국 프린스 마히돌상 2001년 일본 니케이 아시아상 2002년 과학기술훈장 창조장 2009년 서재필의학상 2018년 대한민국 과학기술유공자로 추대됐으며 2002년 미국 학술원 NAS 외국회원 2009년 일본 학사원 명예회원에 선정되며 국내외 학계에서 활발한 활동을 이어왔다. 고인의 빈소는 고려대 안암병원 장례식장 303호에 마련됐다. 발인은 7일 오전 11시 50분이고 장지는 서울추모공원이다. 고인은 1976년 3월 경기도 동두천 한탄강 유역에서 채집한 등줄쥐의 폐 조직에서 세계 최초로 유행성출혈열 병원체와 면역체를 발견한 것으로 널리 알려졌다. 고인은 이 병원체 바이러스를 발견장소의 이름을 따 명명했다. 그 유명한 한탄 바이러스 의 발견이었다. 고인이 병원체를 발견하기 전까지 이 유행성출혈열은 당시 정체불명의 괴질로 유명했다. 1916년 러시아 블라디보스토크에서 첫 환자가 보고된 뒤 2차 세계대전과 6·25전쟁을 거치며 수천 명의 희생자를 냈다. 당시 소련과 중국은 대대적인 인체실험까지 벌였고 미국은 노벨상 수상자 2명이 포함된 연구진 200여명과 막대한 예산을 투입해 정체를 밝히려고 애썼지만 감염 경로와 원인 병원체를 찾지 못했다. 한탄바이러스가 발견된 이후 국내에선 백신제조까지 일사천리로 이뤄졌다. 1991년 녹십자는 고인과 공동연구를 유행성출혈열 예방 백신 ‘한타 박스’를 내놨다. 바이러스 발견자가 진단법과 예방 백신까지 개발한 최초 사례다. 지금도 휴전선 일대에 근무하는 군인과 주민은 이 주사를 맞는다. 고인은 한탄바이러스 분리와 백신 개발로 유력한 노벨상 수상자로 거론되기도 했다. 2019년 9월 연구데이터 분석기업 클래리베이터 애널리틱스가 선정한 ‘2021년 피인용 우수 연구자’ 16명 중 한 명으로 꼽혔기 때문이다. 당시 국내 기관 소속 연구자로는 다섯 번째 한국인으로는 네 번째였다. 클래리베이트의 피인용 우수 연구자는 1970년 이후 등록된 과학기술인용색인 SCI 논문 5200만여 건 중 최상위 0.01%에 속하는 2000회 이상 인용된 논문을 보유하면서 동시에 연구가 독창적이고 인류에 높은 공헌을 한 경우 선정된다. 노벨상 수상의 예측 지표 중 하나로 여겨진다. 고인은 또한 한국인이 사랑하는 근대 과학자였다. 지난 2016년 과학기술정보통신부 전신인 미래창조과학부와 한국과학창의재단 한국경제신문이 진행한 우리 생활을 변화시킨 근현대 대표 과학기술인’ 조사에서 한국이 낳은 세계적 물리학자인 고 故 이휘소 박사가 대한민국 최고 과학자에 이어 고인을 두 번째로 많이 꼽았다.<|end_of_text|>\n",
      "\n",
      "Assistant: 이 이호왕 고려대 명예교수는 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자이며, 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "한탄바이러스 발견 노벨상 유력 후보로 자주 거론 한국을 대표하는 의학자이자 미생물학자 이호왕 고려대 명예교수. 고려대의대 제공 한탄바이러스를 발견한 우리나라 대표 의과학자 이호왕 고려대 명예교수가 5일 숙환으로 별세했다. 향년 94세. 고인은 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자다. 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다. 1928년 함경남도 신흥에서 출생한 고인은 1973년 고대의대에 부임해 의과대학장을 지냈으며 1982년 세계보건기구 신증후출혈열연구협력센터 소장 2000년 대한민국학술원 회장 등을 역임했다. 1979년 미국 최고민간인공로훈장 1987년 인촌상 1992년 호암상 1995년 태국 프린스 마히돌상 2001년 일본 니케이 아시아상 2002년 과학기술훈장 창조장 2009년 서재필의학상 2018년 대한민국 과학기술유공자로 추대됐으며 2002년 미국 학술원 NAS 외국회원 2009년 일본 학사원 명예회원에 선정되며 국내외 학계에서 활발한 활동을 이어왔다. 고인의 빈소는 고려대 안암병원 장례식장 303호에 마련됐다. 발인은 7일 오전 11시 50분이고 장지는 서울추모공원이다. 고인은 1976년 3월 경기도 동두천 한탄강 유역에서 채집한 등줄쥐의 폐 조직에서 세계 최초로 유행성출혈열 병원체와 면역체를 발견한 것으로 널리 알려졌다. 고인은 이 병원체 바이러스를 발견장소의 이름을 따 명명했다. 그 유명한 한탄 바이러스 의 발견이었다. 고인이 병원체를 발견하기 전까지 이 유행성출혈열은 당시 정체불명의 괴질로 유명했다. 1916년 러시아 블라디보스토크에서 첫 환자가 보고된 뒤 2차 세계대전과 6·25전쟁을 거치며 수천 명의 희생자를 냈다. 당시 소련과 중국은 대대적인 인체실험까지 벌였고 미국은 노벨상 수상자 2명이 포함된 연구진 200여명과 막대한 예산을 투입해 정체를 밝히려고 애썼지만 감염 경로와 원인 병원체를 찾지 못했다. 한탄바이러스가 발견된 이후 국내에선 백신제조까지 일사천리로 이뤄졌다. 1991년 녹십자는 고인과 공동연구를 유행성출혈열 예방 백신 ‘한타 박스’를 내놨다. 바이러스 발견자가 진단법과 예방 백신까지 개발한 최초 사례다. 지금도 휴전선 일대에 근무하는 군인과 주민은 이 주사를 맞는다. 고인은 한탄바이러스 분리와 백신 개발로 유력한 노벨상 수상자로 거론되기도 했다. 2019년 9월 연구데이터 분석기업 클래리베이터 애널리틱스가 선정한 ‘2021년 피인용 우수 연구자’ 16명 중 한 명으로 꼽혔기 때문이다. 당시 국내 기관 소속 연구자로는 다섯 번째 한국인으로는 네 번째였다. 클래리베이트의 피인용 우수 연구자는 1970년 이후 등록된 과학기술인용색인 SCI 논문 5200만여 건 중 최상위 0.01%에 속하는 2000회 이상 인용된 논문을 보유하면서 동시에 연구가 독창적이고 인류에 높은 공헌을 한 경우 선정된다. 노벨상 수상의 예측 지표 중 하나로 여겨진다. 고인은 또한 한국인이 사랑하는 근대 과학자였다. 지난 2016년 과학기술정보통신부 전신인 미래창조과학부와 한국과학창의재단 한국경제신문이 진행한 우리 생활을 변화시킨 근현대 대표 과학기술인’ 조사에서 한국이 낳은 세계적 물리학자인 고 故 이휘소 박사가 대한민국 최고 과학자에 이어 고인을 두 번째로 많이 꼽았다.<|end_of_text|>\n",
      "\n",
      "Assistant: 이 이호왕 고려대 명예교수는 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자이며, 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "한탄바이러스 발견 노벨상 유력 후보로 자주 거론 한국을 대표하는 의학자이자 미생물학자 이호왕 고려대 명예교수. 고려대의대 제공 한탄바이러스를 발견한 우리나라 대표 의과학자 이호왕 고려대 명예교수가 5일 숙환으로 별세했다. 향년 94세. 고인은 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자다. 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다. 1928년 함경남도 신흥에서 출생한 고인은 1973년 고대의대에 부임해 의과대학장을 지냈으며 1982년 세계보건기구 신증후출혈열연구협력센터 소장 2000년 대한민국학술원 회장 등을 역임했다. 1979년 미국 최고민간인공로훈장 1987년 인촌상 1992년 호암상 1995년 태국 프린스 마히돌상 2001년 일본 니케이 아시아상 2002년 과학기술훈장 창조장 2009년 서재필의학상 2018년 대한민국 과학기술유공자로 추대됐으며 2002년 미국 학술원 NAS 외국회원 2009년 일본 학사원 명예회원에 선정되며 국내외 학계에서 활발한 활동을 이어왔다. 고인의 빈소는 고려대 안암병원 장례식장 303호에 마련됐다. 발인은 7일 오전 11시 50분이고 장지는 서울추모공원이다. 고인은 1976년 3월 경기도 동두천 한탄강 유역에서 채집한 등줄쥐의 폐 조직에서 세계 최초로 유행성출혈열 병원체와 면역체를 발견한 것으로 널리 알려졌다. 고인은 이 병원체 바이러스를 발견장소의 이름을 따 명명했다. 그 유명한 한탄 바이러스 의 발견이었다. 고인이 병원체를 발견하기 전까지 이 유행성출혈열은 당시 정체불명의 괴질로 유명했다. 1916년 러시아 블라디보스토크에서 첫 환자가 보고된 뒤 2차 세계대전과 6·25전쟁을 거치며 수천 명의 희생자를 냈다. 당시 소련과 중국은 대대적인 인체실험까지 벌였고 미국은 노벨상 수상자 2명이 포함된 연구진 200여명과 막대한 예산을 투입해 정체를 밝히려고 애썼지만 감염 경로와 원인 병원체를 찾지 못했다. 한탄바이러스가 발견된 이후 국내에선 백신제조까지 일사천리로 이뤄졌다. 1991년 녹십자는 고인과 공동연구를 유행성출혈열 예방 백신 ‘한타 박스’를 내놨다. 바이러스 발견자가 진단법과 예방 백신까지 개발한 최초 사례다. 지금도 휴전선 일대에 근무하는 군인과 주민은 이 주사를 맞는다. 고인은 한탄바이러스 분리와 백신 개발로 유력한 노벨상 수상자로 거론되기도 했다. 2019년 9월 연구데이터 분석기업 클래리베이터 애널리틱스가 선정한 ‘2021년 피인용 우수 연구자’ 16명 중 한 명으로 꼽혔기 때문이다. 당시 국내 기관 소속 연구자로는 다섯 번째 한국인으로는 네 번째였다. 클래리베이트의 피인용 우수 연구자는 1970년 이후 등록된 과학기술인용색인 SCI 논문 5200만여 건 중 최상위 0.01%에 속하는 2000회 이상 인용된 논문을 보유하면서 동시에 연구가 독창적이고 인류에 높은 공헌을 한 경우 선정된다. 노벨상 수상의 예측 지표 중 하나로 여겨진다. 고인은 또한 한국인이 사랑하는 근대 과학자였다. 지난 2016년 과학기술정보통신부 전신인 미래창조과학부와 한국과학창의재단 한국경제신문이 진행한 우리 생활을 변화시킨 근현대 대표 과학기술인’ 조사에서 한국이 낳은 세계적 물리학자인 고 故 이휘소 박사가 대한민국 최고 과학자에 이어 고인을 두 번째로 많이 꼽았다.<|end_of_text|>\n",
      "\n",
      "Assistant: 이 이호왕 고려대 명예교수는 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자이며, 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다.<|end_of_text|>\n",
      "\n",
      "\n",
      "config.json: 100%|█████████████████████████████| 654/654 [00:00<00:00, 6.35MB/s]\n",
      "model.safetensors.index.json: 100%|█████████| 23.9k/23.9k [00:00<00:00, 143MB/s]\n",
      "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|     | 41.9M/4.98G [00:00<00:12, 380MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|     | 83.9M/4.98G [00:00<00:12, 392MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 136M/4.98G [00:00<00:11, 408MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 189M/4.98G [00:00<00:11, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 231M/4.98G [00:00<00:11, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 273M/4.98G [00:00<00:11, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▍     | 315M/4.98G [00:00<00:11, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 357M/4.98G [00:00<00:11, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 398M/4.98G [00:00<00:11, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 440M/4.98G [00:01<00:11, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 482M/4.98G [00:01<00:11, 404MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 524M/4.98G [00:01<00:10, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 566M/4.98G [00:01<00:10, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 608M/4.98G [00:01<00:10, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 650M/4.98G [00:01<00:10, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 692M/4.98G [00:01<00:10, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▉     | 734M/4.98G [00:01<00:10, 396MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 776M/4.98G [00:01<00:10, 393MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 818M/4.98G [00:02<00:10, 386MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|█     | 860M/4.98G [00:02<00:10, 390MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|█     | 902M/4.98G [00:02<00:10, 397MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|█▏    | 954M/4.98G [00:02<00:09, 407MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|█    | 1.01G/4.98G [00:02<00:09, 414MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.06G/4.98G [00:02<00:09, 417MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.10G/4.98G [00:02<00:09, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|█▏   | 1.14G/4.98G [00:02<00:09, 405MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.18G/4.98G [00:02<00:09, 401MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▏   | 1.23G/4.98G [00:03<00:09, 388MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▎   | 1.27G/4.98G [00:03<00:09, 373MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.31G/4.98G [00:03<00:09, 367MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.35G/4.98G [00:03<00:12, 284MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.39G/4.98G [00:03<00:11, 309MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▍   | 1.44G/4.98G [00:03<00:10, 334MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▍   | 1.48G/4.98G [00:03<00:09, 354MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.52G/4.98G [00:03<00:09, 370MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.56G/4.98G [00:04<00:08, 382MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.60G/4.98G [00:04<00:08, 391MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.65G/4.98G [00:04<00:08, 396MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.69G/4.98G [00:04<00:08, 400MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▋   | 1.73G/4.98G [00:04<00:08, 401MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.77G/4.98G [00:04<00:08, 382MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.81G/4.98G [00:04<00:08, 375MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.86G/4.98G [00:04<00:08, 373MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.90G/4.98G [00:04<00:08, 373MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.94G/4.98G [00:05<00:07, 382MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.98G/4.98G [00:05<00:07, 391MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.02G/4.98G [00:05<00:07, 398MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.07G/4.98G [00:05<00:07, 402MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.11G/4.98G [00:05<00:07, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 2.15G/4.98G [00:05<00:06, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.19G/4.98G [00:05<00:06, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|██▏  | 2.23G/4.98G [00:05<00:06, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 2.28G/4.98G [00:05<00:06, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.32G/4.98G [00:05<00:06, 413MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.36G/4.98G [00:06<00:06, 414MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 2.40G/4.98G [00:06<00:06, 414MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.44G/4.98G [00:06<00:06, 412MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 2.49G/4.98G [00:06<00:06, 414MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.53G/4.98G [00:06<00:05, 411MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.57G/4.98G [00:06<00:05, 405MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.61G/4.98G [00:06<00:05, 399MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|██▋  | 2.65G/4.98G [00:06<00:05, 398MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.69G/4.98G [00:06<00:05, 402MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  55%|██▋  | 2.74G/4.98G [00:06<00:05, 405MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.78G/4.98G [00:07<00:05, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.82G/4.98G [00:07<00:05, 406MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.86G/4.98G [00:07<00:05, 407MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.90G/4.98G [00:07<00:05, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.95G/4.98G [00:07<00:04, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  60%|███  | 2.99G/4.98G [00:07<00:04, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|███  | 3.03G/4.98G [00:07<00:04, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|███  | 3.07G/4.98G [00:07<00:04, 402MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.11G/4.98G [00:07<00:04, 388MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.16G/4.98G [00:08<00:04, 382MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 3.20G/4.98G [00:08<00:04, 375MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  65%|███▎ | 3.24G/4.98G [00:08<00:04, 381MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.28G/4.98G [00:08<00:04, 373MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.32G/4.98G [00:08<00:04, 376MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.37G/4.98G [00:08<00:04, 377MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.41G/4.98G [00:08<00:04, 382MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 3.45G/4.98G [00:08<00:03, 390MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|███▌ | 3.49G/4.98G [00:09<00:06, 240MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.52G/4.98G [00:09<00:12, 118MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  71%|██▊ | 3.55G/4.98G [00:10<00:14, 95.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.60G/4.98G [00:10<00:10, 127MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.64G/4.98G [00:10<00:08, 162MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.68G/4.98G [00:10<00:06, 198MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 3.72G/4.98G [00:10<00:07, 175MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.76G/4.98G [00:11<00:05, 212MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.81G/4.98G [00:11<00:04, 248MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.86G/4.98G [00:11<00:03, 290MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.91G/4.98G [00:11<00:03, 323MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.95G/4.98G [00:11<00:03, 339MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████ | 4.01G/4.98G [00:11<00:02, 365MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.06G/4.98G [00:11<00:02, 383MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.10G/4.98G [00:11<00:02, 392MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.14G/4.98G [00:11<00:02, 396MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.19G/4.98G [00:12<00:01, 405MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 4.25G/4.98G [00:12<00:01, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.29G/4.98G [00:12<00:01, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.33G/4.98G [00:12<00:01, 409MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.37G/4.98G [00:12<00:01, 408MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.41G/4.98G [00:12<00:01, 410MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 4.47G/4.98G [00:12<00:01, 416MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.52G/4.98G [00:12<00:01, 420MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.57G/4.98G [00:12<00:00, 424MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.62G/4.98G [00:13<00:00, 426MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.68G/4.98G [00:13<00:00, 426MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.73G/4.98G [00:13<00:00, 426MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.78G/4.98G [00:13<00:00, 428MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 4.83G/4.98G [00:13<00:00, 428MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.89G/4.98G [00:13<00:00, 424MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|█████| 4.98G/4.98G [00:13<00:00, 357MB/s]\u001b[A\n",
      "Downloading shards:  25%|██████▎                  | 1/4 [00:14<00:42, 14.04s/it]\n",
      "Downloading shards:  25%|██████▎                  | 1/4 [00:14<00:42, 14.05s/it]\u001b[A\n",
      "model-00002-of-00004.safetensors:   1%|     | 52.4M/5.00G [00:00<00:11, 431MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   2%|▏     | 105M/5.00G [00:00<00:11, 428MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 157M/5.00G [00:00<00:11, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   4%|▎     | 210M/5.00G [00:00<00:11, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 262M/5.00G [00:00<00:11, 427MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   6%|▍     | 315M/5.00G [00:00<00:10, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 367M/5.00G [00:00<00:10, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   8%|▌     | 419M/5.00G [00:00<00:10, 426MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 472M/5.00G [00:01<00:10, 426MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  10%|▋     | 524M/5.00G [00:01<00:10, 428MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 577M/5.00G [00:01<00:10, 428MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 629M/5.00G [00:01<00:10, 428MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 682M/5.00G [00:01<00:10, 431MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 734M/5.00G [00:01<00:09, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 786M/5.00G [00:01<00:09, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  17%|█     | 839M/5.00G [00:01<00:10, 409MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  18%|█     | 881M/5.00G [00:02<00:10, 382MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  19%|█     | 933M/5.00G [00:02<00:10, 396MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 986M/5.00G [00:02<00:09, 404MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.04G/5.00G [00:02<00:09, 414MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.09G/5.00G [00:02<00:09, 421MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.14G/5.00G [00:02<00:09, 425MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.20G/5.00G [00:02<00:08, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  25%|█▏   | 1.25G/5.00G [00:02<00:08, 431MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.30G/5.00G [00:03<00:08, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.35G/5.00G [00:03<00:08, 433MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.41G/5.00G [00:03<00:08, 435MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.46G/5.00G [00:03<00:08, 438MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  30%|█▌   | 1.51G/5.00G [00:03<00:07, 438MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.56G/5.00G [00:03<00:07, 439MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.61G/5.00G [00:03<00:07, 438MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.67G/5.00G [00:03<00:07, 435MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.72G/5.00G [00:04<00:07, 435MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  35%|█▊   | 1.77G/5.00G [00:04<00:07, 433MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.82G/5.00G [00:04<00:07, 433MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.88G/5.00G [00:04<00:07, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.93G/5.00G [00:04<00:07, 430MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  40%|█▉   | 1.98G/5.00G [00:04<00:07, 430MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.03G/5.00G [00:04<00:06, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.09G/5.00G [00:04<00:06, 432MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.14G/5.00G [00:05<00:06, 430MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.19G/5.00G [00:05<00:06, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  45%|██▏  | 2.24G/5.00G [00:05<00:06, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.30G/5.00G [00:05<00:06, 429MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.35G/5.00G [00:05<00:06, 424MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.40G/5.00G [00:05<00:06, 409MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.44G/5.00G [00:05<00:06, 397MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  50%|██▍  | 2.49G/5.00G [00:05<00:06, 386MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.53G/5.00G [00:05<00:06, 374MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.57G/5.00G [00:06<00:06, 368MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  52%|██▌  | 2.61G/5.00G [00:06<00:06, 364MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.65G/5.00G [00:06<00:06, 361MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.69G/5.00G [00:06<00:06, 356MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.74G/5.00G [00:06<00:06, 353MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.78G/5.00G [00:06<00:06, 351MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.82G/5.00G [00:06<00:06, 351MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.86G/5.00G [00:06<00:06, 350MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.90G/5.00G [00:07<00:06, 349MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.95G/5.00G [00:07<00:05, 349MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.99G/5.00G [00:07<00:05, 349MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.03G/5.00G [00:07<00:08, 232MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.08G/5.00G [00:07<00:06, 277MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.12G/5.00G [00:07<00:06, 304MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.17G/5.00G [00:07<00:05, 325MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.22G/5.00G [00:08<00:05, 355MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  65%|███▎ | 3.27G/5.00G [00:08<00:04, 377MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.32G/5.00G [00:08<00:04, 392MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.37G/5.00G [00:08<00:04, 393MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.42G/5.00G [00:08<00:03, 404MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.47G/5.00G [00:08<00:03, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  70%|███▌ | 3.51G/5.00G [00:08<00:03, 395MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 3.55G/5.00G [00:08<00:03, 379MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.60G/5.00G [00:09<00:03, 370MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.64G/5.00G [00:09<00:03, 365MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.68G/5.00G [00:09<00:03, 369MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  75%|███▋ | 3.73G/5.00G [00:09<00:03, 388MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.79G/5.00G [00:09<00:03, 402MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.84G/5.00G [00:09<00:02, 411MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.89G/5.00G [00:09<00:02, 419MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.94G/5.00G [00:09<00:02, 423MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  80%|███▉ | 4.00G/5.00G [00:10<00:02, 412MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.04G/5.00G [00:10<00:02, 413MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.08G/5.00G [00:10<00:02, 394MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.12G/5.00G [00:10<00:02, 381MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.16G/5.00G [00:10<00:02, 388MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.22G/5.00G [00:10<00:01, 399MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  85%|████▎| 4.26G/5.00G [00:10<00:02, 361MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.30G/5.00G [00:10<00:01, 375MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.34G/5.00G [00:10<00:01, 381MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 4.38G/5.00G [00:11<00:01, 353MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.42G/5.00G [00:11<00:01, 351MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.47G/5.00G [00:11<00:01, 355MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  90%|████▌| 4.52G/5.00G [00:11<00:01, 379MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 4.57G/5.00G [00:11<00:01, 394MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.62G/5.00G [00:11<00:00, 405MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.68G/5.00G [00:11<00:00, 409MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.72G/5.00G [00:11<00:00, 399MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  95%|████▊| 4.76G/5.00G [00:12<00:00, 383MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.80G/5.00G [00:12<00:00, 392MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 4.85G/5.00G [00:12<00:00, 406MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 4.91G/5.00G [00:12<00:00, 415MB/s]\u001b[A\n",
      "model-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:12<00:00, 397MB/s]\u001b[A\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:26<00:26, 13.20s/it]\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:26<00:26, 13.21s/it]\u001b[A\n",
      "model-00003-of-00004.safetensors:   1%|     | 41.9M/4.92G [00:00<00:12, 400MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   2%|     | 83.9M/4.92G [00:00<00:13, 347MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 136M/4.92G [00:00<00:12, 388MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   4%|▏     | 189M/4.92G [00:00<00:11, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 231M/4.92G [00:00<00:11, 406MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   6%|▎     | 273M/4.92G [00:00<00:11, 395MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   6%|▍     | 315M/4.92G [00:00<00:12, 383MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 357M/4.92G [00:00<00:12, 363MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 398M/4.92G [00:01<00:12, 371MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 440M/4.92G [00:01<00:12, 360MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 482M/4.92G [00:01<00:12, 346MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 524M/4.92G [00:01<00:12, 365MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 577M/4.92G [00:01<00:11, 386MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 629M/4.92G [00:01<00:10, 400MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  14%|▊     | 682M/4.92G [00:01<00:10, 409MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 734M/4.92G [00:01<00:10, 418MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 786M/4.92G [00:02<00:09, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  17%|█     | 839M/4.92G [00:02<00:09, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  18%|█     | 891M/4.92G [00:02<00:09, 425MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  19%|█▏    | 944M/4.92G [00:02<00:09, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 996M/4.92G [00:02<00:09, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  21%|█    | 1.05G/4.92G [00:02<00:08, 430MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.10G/4.92G [00:02<00:09, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.15G/4.92G [00:02<00:08, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  25%|█▏   | 1.21G/4.92G [00:02<00:08, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.26G/4.92G [00:03<00:08, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.31G/4.92G [00:03<00:08, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.36G/4.92G [00:03<00:08, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.42G/4.92G [00:03<00:08, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  30%|█▍   | 1.47G/4.92G [00:03<00:08, 414MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.51G/4.92G [00:03<00:08, 399MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.55G/4.92G [00:03<00:08, 402MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.60G/4.92G [00:03<00:08, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  34%|█▋   | 1.66G/4.92G [00:04<00:07, 414MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  35%|█▋   | 1.71G/4.92G [00:04<00:07, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  36%|█▊   | 1.76G/4.92G [00:04<00:07, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.81G/4.92G [00:04<00:07, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.87G/4.92G [00:04<00:07, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.92G/4.92G [00:04<00:07, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  40%|██   | 1.97G/4.92G [00:04<00:06, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  41%|██   | 2.02G/4.92G [00:04<00:06, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.08G/4.92G [00:05<00:06, 425MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.13G/4.92G [00:05<00:06, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.18G/4.92G [00:05<00:06, 413MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  45%|██▎  | 2.22G/4.92G [00:05<00:06, 413MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.26G/4.92G [00:05<00:06, 410MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.31G/4.92G [00:05<00:06, 407MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.36G/4.92G [00:05<00:06, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.41G/4.92G [00:05<00:06, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  50%|██▍  | 2.45G/4.92G [00:06<00:06, 389MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.50G/4.92G [00:06<00:06, 381MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.54G/4.92G [00:06<00:06, 388MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.59G/4.92G [00:06<00:05, 400MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.64G/4.92G [00:06<00:05, 411MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  55%|██▋  | 2.69G/4.92G [00:06<00:05, 418MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.75G/4.92G [00:06<00:05, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.80G/4.92G [00:06<00:04, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.85G/4.92G [00:06<00:04, 431MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:07<00:04, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  60%|███  | 2.96G/4.92G [00:07<00:04, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  61%|███  | 3.01G/4.92G [00:07<00:04, 425MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.06G/4.92G [00:07<00:04, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.11G/4.92G [00:07<00:04, 431MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.17G/4.92G [00:07<00:04, 433MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  65%|███▎ | 3.22G/4.92G [00:07<00:03, 430MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.27G/4.92G [00:07<00:03, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.32G/4.92G [00:08<00:03, 412MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.37G/4.92G [00:08<00:03, 389MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.41G/4.92G [00:08<00:03, 394MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  70%|███▌ | 3.45G/4.92G [00:08<00:03, 401MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.49G/4.92G [00:08<00:03, 386MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.53G/4.92G [00:08<00:03, 387MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.59G/4.92G [00:08<00:03, 400MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.64G/4.92G [00:08<00:03, 409MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  75%|███▊ | 3.69G/4.92G [00:08<00:02, 417MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.73G/4.92G [00:09<00:02, 417MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.79G/4.92G [00:09<00:02, 423MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.84G/4.92G [00:09<00:02, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.89G/4.92G [00:09<00:02, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  80%|████ | 3.94G/4.92G [00:09<00:02, 428MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  81%|████ | 4.00G/4.92G [00:09<00:02, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.05G/4.92G [00:10<00:03, 271MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.09G/4.92G [00:10<00:02, 298MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.14G/4.92G [00:10<00:02, 331MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  85%|████▎| 4.19G/4.92G [00:10<00:02, 356MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.24G/4.92G [00:10<00:01, 354MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.28G/4.92G [00:10<00:01, 365MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.33G/4.92G [00:10<00:01, 385MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 4.38G/4.92G [00:10<00:01, 398MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  90%|████▌| 4.44G/4.92G [00:10<00:01, 408MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  91%|████▌| 4.49G/4.92G [00:11<00:01, 416MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.54G/4.92G [00:11<00:00, 419MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.59G/4.92G [00:11<00:00, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 4.65G/4.92G [00:11<00:00, 421MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 4.70G/4.92G [00:11<00:00, 422MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.75G/4.92G [00:11<00:00, 424MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  98%|████▉| 4.80G/4.92G [00:11<00:00, 426MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.85G/4.92G [00:11<00:00, 427MB/s]\u001b[A\n",
      "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:12<00:00, 405MB/s]\u001b[A\n",
      "Downloading shards:  75%|██████████████████▊      | 3/4 [00:38<00:12, 12.71s/it]\n",
      "Downloading shards:  75%|██████████████████▊      | 3/4 [00:38<00:12, 12.73s/it]\u001b[A\n",
      "model-00004-of-00004.safetensors:   4%|▏    | 52.4M/1.17G [00:00<00:02, 440MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 105M/1.17G [00:00<00:02, 432MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  13%|▊     | 157M/1.17G [00:00<00:02, 427MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  18%|█     | 210M/1.17G [00:00<00:02, 427MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  22%|█▎    | 262M/1.17G [00:00<00:02, 431MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  27%|█▌    | 315M/1.17G [00:00<00:01, 430MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  31%|█▉    | 367M/1.17G [00:00<00:01, 426MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  36%|██▏   | 419M/1.17G [00:00<00:01, 429MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  40%|██▍   | 472M/1.17G [00:01<00:01, 430MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  45%|██▋   | 524M/1.17G [00:01<00:01, 427MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  49%|██▉   | 577M/1.17G [00:01<00:01, 427MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  54%|███▏  | 629M/1.17G [00:01<00:01, 426MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  58%|███▌  | 682M/1.17G [00:01<00:01, 429MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  63%|███▊  | 734M/1.17G [00:01<00:01, 425MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  67%|████  | 786M/1.17G [00:01<00:00, 429MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  72%|████▎ | 839M/1.17G [00:01<00:00, 429MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  76%|████▌ | 891M/1.17G [00:02<00:00, 430MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  81%|████▊ | 944M/1.17G [00:02<00:00, 431MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  85%|█████ | 996M/1.17G [00:02<00:00, 434MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  90%|████▍| 1.05G/1.17G [00:02<00:00, 431MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  94%|████▋| 1.10G/1.17G [00:02<00:00, 431MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:02<00:00, 427MB/s]\u001b[A\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [00:41<00:00, 10.39s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [00:41<00:00, 10.39s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [00:41<00:00, 10.40s/it]\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [00:41<00:00, 10.39s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:05<00:00,  1.30s/it]\n",
      "generation_config.json: 100%|██████████████████| 177/177 [00:00<00:00, 2.04MB/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.67s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.67s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:06<00:00,  1.67s/it]\n",
      "Generating train split: 14 examples [00:00, 908.15 examples/s]\n",
      "Generating train split: 14 examples [00:00, 1864.61 examples/s]\n",
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:18<00:00,  8.79s/it]\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.77it/s]\u001b[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:02<00:00,  1.25it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.3460123538970947, 'eval_runtime': 4.8452, 'eval_samples_per_second': 2.889, 'eval_steps_per_second': 0.826, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:23<00:00,  8.79s/it]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:03<00:00,  1.08it/s]\u001b[A\n",
      "                                                                                \u001b[A[rank0]:[2024-06-28 14:17:35,309] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.24443965599994044, 'preprocessing_with_comm': 0.0030276500001491513, 'state_converting': 0.21433546499997647, <Type.ALL: 'all'>: 0.4734955750000154})\n",
      "{'train_runtime': 37.9475, 'train_samples_per_second': 0.369, 'train_steps_per_second': 0.053, 'train_loss': 2.4105048179626465, 'epoch': 1.0}\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:37<00:00, 18.97s/it]\n"
     ]
    }
   ],
   "source": [
    "!ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 torchrun --nproc_per_node=4 \\\n",
    "../scripts/run_fsdp_qlora.py \\\n",
    "--config llama_3_8b_fsdp_qlora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441607e4-f93f-438e-8985-99a76233fe47",
   "metadata": {},
   "source": [
    "## 4. 베이스 모델과 훈련된 모델 머지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cebdb212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('meta-llama/Meta-Llama-3-8B',\n",
       " '/home/ec2-user/SageMaker/models/llama-3-8b-naver-news')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id, output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8acc4",
   "metadata": {},
   "source": [
    "### 모델 머지 및 로컬에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695a221de4894e81b3e36752b06b9ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41328c88b9724cc0b50eee694af841e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load PEFT model on CPU\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")  \n",
    "# Merge LoRA and base model and save\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(output_dir,safe_serialization=True, max_shard_size=\"2GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0ea42",
   "metadata": {},
   "source": [
    "### 머지된 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1a6607d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad27d0be30840b4af7f7066d7c4f209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb8a5c9b6654a7c9e4e973c58dc815b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer \n",
    "\n",
    "\n",
    "# Load Model with PEFT adapter\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  pretrained_model_name_or_path = output_dir,\n",
    "  torch_dtype=torch.float16,\n",
    "  quantization_config= {\"load_in_4bit\": True},\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908046b",
   "metadata": {},
   "source": [
    "## 5. 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5388b34",
   "metadata": {},
   "source": [
    "### 테스트 데이터 셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b1780c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/naver-news-summarization-ko/test_dataset.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ce7d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " [{'content': 'You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Please summarize the goals for journalist in this text:\\n\\n아이폰13프로맥스 120만원대에서 150만원대로 지난달 아이패드 재책정 이어 아이폰 가격도 올라 디지털데일리 백승은 기자 애플이 일본에서 아이폰 일부 모델 가격을 인상했다. 최근 엔화 가치가 크게 떨어지자 내린 조치다. 30일 애플 일본 웹사이트에 따르면 아이폰SE 아이폰13미니 아이폰13 아이폰13프로 아이폰13프로맥스 가격이 9 19% 상승했다. 가장 저렴한 아이폰SE의 경우 5만7800엔 약 55만원 에서 6만2800엔 약 59만원 으로 올랐다. 가장 고가 제품인 아이폰13프로맥스는 13만4800엔 약 128만원 에서 15만9800엔 약 152만원 으로 재책정됐다. 애플은 지난 6월 일본에서 판매 중인 아이패드 가격도 올렸다. 대상 제품은 아이패드 아이패드에어 아이패드프로 11인치 아이패드프로 12.9인치 아이패드미니다. 인상률이 가장 높은 제품은 아이패드로 기존 3만9800엔 약 37만원 에서 25% 오른 4만9800엔 약 47만원 이 됐다. 애플의 가격 인상 조치는 올해 초부터 나타난 엔저 효과에서 기인한 것으로 보인다. 엔저 효과란 국제 환시세에서 엔 값이 타국 화폐에 비해 낮아지는 현상을 말한다. 환율이 약세하면 수입물가가 오를 가능성이 있다. 이에 대비하기 위해 가격을 올린 것으로 분석된다. 한편 애플은 일본 스마트폰 시장에서 과반 이상 점유율을 차지하고 있다. 시장조사업체 스트래티지애널리틱스 SA 에 따르면 애플은 지난 1분기 일본 스마트폰 시장에서 56.8%를 기록하며 압도적인 1위를 기록했다.',\n",
       "   'role': 'user'}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "# Load our test dataset\n",
    "eval_dataset = load_dataset(\"json\", data_files=test_data_json, split=\"train\")\n",
    "rand_idx = randint(0, len(eval_dataset))\n",
    "messages = eval_dataset[rand_idx][\"messages\"][:2]\n",
    "rand_idx, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15b47b",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddaf71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Query:**\n",
      "Please summarize the goals for journalist in this text:\n",
      "\n",
      "아이폰13프로맥스 120만원대에서 150만원대로 지난달 아이패드 재책정 이어 아이폰 가격도 올라 디지털데일리 백승은 기자 애플이 일본에서 아이폰 일부 모델 가격을 인상했다. 최근 엔화 가치가 크게 떨어지자 내린 조치다. 30일 애플 일본 웹사이트에 따르면 아이폰SE 아이폰13미니 아이폰13 아이폰13프로 아이폰13프로맥스 가격이 9 19% 상승했다. 가장 저렴한 아이폰SE의 경우 5만7800엔 약 55만원 에서 6만2800엔 약 59만원 으로 올랐다. 가장 고가 제품인 아이폰13프로맥스는 13만4800엔 약 128만원 에서 15만9800엔 약 152만원 으로 재책정됐다. 애플은 지난 6월 일본에서 판매 중인 아이패드 가격도 올렸다. 대상 제품은 아이패드 아이패드에어 아이패드프로 11인치 아이패드프로 12.9인치 아이패드미니다. 인상률이 가장 높은 제품은 아이패드로 기존 3만9800엔 약 37만원 에서 25% 오른 4만9800엔 약 47만원 이 됐다. 애플의 가격 인상 조치는 올해 초부터 나타난 엔저 효과에서 기인한 것으로 보인다. 엔저 효과란 국제 환시세에서 엔 값이 타국 화폐에 비해 낮아지는 현상을 말한다. 환율이 약세하면 수입물가가 오를 가능성이 있다. 이에 대비하기 위해 가격을 올린 것으로 분석된다. 한편 애플은 일본 스마트폰 시장에서 과반 이상 점유율을 차지하고 있다. 시장조사업체 스트래티지애널리틱스 SA 에 따르면 애플은 지난 1분기 일본 스마트폰 시장에서 56.8%를 기록하며 압도적인 1위를 기록했다.\n",
      "\n",
      "**Original Answer:**\n",
      "애플이 일본에서 아이폰 일부 모델 가격을 인상하고 지난 6월 일본에서 판매 중인 아이패드 가격도 올린 가운데, 시장조사업체 스트래티지애널리틱스 SA 에 따르면 지난 1분기 일본 스마트폰 시장에서 압도적인 1위를 기록하며 압도적인 1위를 기록했다.\n",
      "\n",
      "**Generated Answer:**\n",
      "1. 아이폰13프로맥스 120만원대에서 150만원대로 지난달 아이패드 재책정 이어 아이폰 가격도 올라 디지털데일리 백승은 기자 애플이 일본에서 아이폰 일부 모델 가격을 인상했다. 최근 엔화 가치가 크게 떨어지자 내린 조치다. 30일 애플 일본 웹사이트에 따르면 아이폰SE 아이폰13미니 아이폰13 아이폰13프로 아이폰13프로맥스 가격이 9 19% 상승했다. 가장 저렴한 아이폰SE의 경우 5만7800엔 약 55만원 에서 6만2800엔 약 59만원 으로 올랐다. 가장 고가 제품인 아이폰13프로맥스는 13만4800엔 약 128만원 에서 15만9800엔 약 152만원 으로 재책정됐다. 애플은 지난 6월 일본에서 판매 중인 아이패드 가격도 올렸다. 대상 제품은 아이패드 아이패드에어 아이패드프로 11인치 아이패드프로 12.9인치 아이패드미니다. 인상률이 가장 높은 제품은 아이패드로 기존 3만9800엔 약 37만원 에서 25% 오른 4만9800엔 약 47만원 이 됐다. 애플의 가격 인상 조치는 올해 초부터 나타난 엔저 효과에서 기인한 것으로 보인다. 엔저 효과란 국제 환시세에서 엔 값이 타국 화폐에 비해 낮아지는 현상을 말한다. 환율이 약세하면 수입물가가 오를 가능성이 있다. 이에 대비하기 위해 가격을 올린 것으로 분석된다. 한편 애플은 일본 스마트폰 시장에서 과반 이상 점유율을 차지하고 있다. 시장조사업체 스트래티지애널리틱스 SA 에 따르면 애플은 지난 1분기 일본 스마트폰 시장에서 56.8%를 기록하며 압도적인 1위를 기록했다. 응답\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on sample \n",
    "input_ids = tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id= tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "\n",
    "print(f\"**Query:**\\n{eval_dataset[rand_idx]['messages'][1]['content']}\\n\")\n",
    "print(f\"**Original Answer:**\\n{eval_dataset[rand_idx]['messages'][2]['content']}\\n\")\n",
    "print(f\"**Generated Answer:**\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60aaa4-b654-49b3-bb87-34ad6a9f375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('pytorch_p310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
