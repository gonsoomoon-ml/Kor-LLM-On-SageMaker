{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# 로컬에서 훈련 하기\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06b5f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/SageMaker/.cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "!huggingface-cli login --token {HF_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdcebd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_DATASETS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_HOME'] = \"/home/ec2-user/SageMaker/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bce431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder:  ../data/naver-news-summarization-ko\n",
      "train_data_json:  ../data/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test/test_dataset.json\n",
      "full_train_data_json:  ../data/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "full_validation_data_json:  ../data/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "full_test_data_json:  ../data/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "%store -r data_folder\n",
    "%store -r train_data_json \n",
    "%store -r validation_data_json \n",
    "%store -r test_data_json \n",
    "%store -r full_train_data_json \n",
    "%store -r full_validation_data_json \n",
    "%store -r full_test_data_json\n",
    "\n",
    "\n",
    "print(\"data_folder: \", data_folder)\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)\n",
    "print(\"full_train_data_json: \", full_train_data_json)\n",
    "print(\"full_validation_data_json: \", full_validation_data_json)\n",
    "print(\"full_test_data_json: \", full_test_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f53c-d21d-4fca-b69d-6a85d966353c",
   "metadata": {},
   "source": [
    "## 2. 베이스 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d514e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
    "output_dir = \"/home/ec2-user/SageMaker/models/llama-3-8b-naver-news\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403f6b8",
   "metadata": {},
   "source": [
    "### Config YAML 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72d30120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_llama_3_8b_fsdp_qlora.yaml\n",
    "# script parameters\n",
    "model_id:  \"meta-llama/Meta-Llama-3-8B\" # Hugging Face model id\n",
    "###########################\n",
    "# small samples for Debug\n",
    "###########################\n",
    "# train_dataset_path: \"../data/naver-news-summarization-ko/train\"                      # path to dataset\n",
    "# validation_dataset_path: \"../data/naver-news-summarization-ko/validation\"                      # path to dataset\n",
    "# test_dataset_path: \"../data/naver-news-summarization-ko/test\"                      # path to dataset\n",
    "# per_device_train_batch_size: 1         # batch size per device during training\n",
    "# per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################\n",
    "# large samples for evaluation\n",
    "###########################\n",
    "train_dataset_path: \"../data/naver-news-summarization-ko/full_train\"                      # path to dataset\n",
    "validation_dataset_path: \"../data/naver-news-summarization-ko/full_validation\"                      # path to dataset\n",
    "test_dataset_path: \"../data/naver-news-summarization-ko/full_test\"                      # path to dataset\n",
    "per_device_train_batch_size: 16         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################\n",
    "max_seq_len:  2048              # max sequence length for model and packing of the dataset\n",
    "# training parameters\n",
    "output_dir: \"/home/ec2-user/SageMaker/models/llama-3-8b-naver-news\" # Temporary output directory for model checkpoints\n",
    "report_to: \"tensorboard\"               # report metrics to tensorboard\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap offload\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c851f75d",
   "metadata": {},
   "source": [
    "## 3. 훈련 Script 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-30 02:17:50,760] torch.distributed.run: [WARNING] \n",
      "[2024-06-30 02:17:50,760] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-06-30 02:17:50,760] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-06-30 02:17:50,760] torch.distributed.run: [WARNING] *****************************************\n",
      "/home/ec2-user/SageMaker/.cs/conda/envs/llama3_puy310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/SageMaker/.cs/conda/envs/llama3_puy310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/SageMaker/.cs/conda/envs/llama3_puy310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/SageMaker/.cs/conda/envs/llama3_puy310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "## script_args: \n",
      " ScriptArguments(train_dataset_path='../data/naver-news-summarization-ko/full_train', validation_dataset_path='../data/naver-news-summarization-ko/full_validation', model_id='meta-llama/Meta-Llama-3-8B', max_seq_length=512)\n",
      "## training_args: \n",
      " TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>, <FSDPOption.OFFLOAD: 'offload'>],\n",
      "fsdp_config={'backward_prefetch': 'backward_pre', 'forward_prefetch': 'false', 'use_orig_params': 'false', 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news/runs/Jun30_02-17-53_ip-172-16-48-49.ec2.internal,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=0.3,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/home/ec2-user/SageMaker/models/llama-3-8b-naver-news,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Generating train split: 1000 examples [00:00, 44532.61 examples/s]\n",
      "Generating train split: 1000 examples [00:00, 58367.72 examples/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map:  89%|███████████████████████▏  | 891/1000 [00:00<00:00, 8849.77 examples/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|█████████████████████████| 1000/1000 [00:00<00:00, 7905.71 examples/s]\n",
      "Map: 100%|█████████████████████████| 1000/1000 [00:00<00:00, 7859.93 examples/s]\n",
      "Map: 100%|█████████████████████████| 1000/1000 [00:00<00:00, 7489.44 examples/s]\n",
      "Map: 100%|████████████████████████| 1000/1000 [00:00<00:00, 10236.40 examples/s]\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "과거 아이폰 썼던 원주 씨 갤럭시S20 시리즈 사용하는 듯…착용 드레스도 인기 지난달 27일 정의선 현대차그룹 회장 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨의 하객룩 이 높은 관심을 받은 가운데 한 손에 들려있던 스마트폰도 주목 받고 있다. 한 때 원주 씨가 삼성전자가 아닌 경쟁사인 애플의 아이폰 을 쓴 적이 있기 때문이다. 이재용 삼성전자 부회장이 딸 원주 씨와 함께 지난달 27일 서울 중구 정동제일교회에서 열린 정의선 현대차그룹 회장 장녀 진희 씨의 결혼식에 참석하고 있다. 사진 뉴시스 3일 재계에 따르면 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐다. 유명 IT 유튜버 잇섭도 자신의 페이스북을 통해 이재용 부회장님 딸은 갤럭시S20 시리즈를 쓰는 듯하다 며 갤럭시S20 시리즈는 명기였다 고 평가했다. 갤럭시S20 시리즈는 지난 2020년 3월 출시된 스마트폰으로 갤럭시S20 과 갤럭시S20 플러스 갤럭시S20 울트라 등 3종으로 구성됐다. 갤럭시S20 울트라 는 1억800만 화소 갤럭시S20 플러스 와 갤럭시S20 는 6천400만 화소의 고화소 카메라를 탑재했다. 특히 갤럭시S20 울트라 는 최근 1년간 미국 소비자들 사이에서 가장 만족도 높은 제품에 올랐다. 실제로 미국 고객만족지수 ACSI 에 따르면 갤럭시S20 울트라 는 소비자 만족도 조사에서 100점 만점에 86점을 받아 1위에 올랐다. 이번 조사는 지난해 4월부터 올해 3월까지 무작위로 선택된 미국인 2만3천411명으로부터 이메일 답변을 받아 이뤄졌다. 갤럭시S20 시리즈는 출시 당시엔 큰 흥행을 하진 못했다. 당시 역대급 스펙이라는 평가를 받았지만 전작에 비해 20만원가량 높은 가격에 코로나19 사태까지 겹치면서 초반 판매량이 저조했다. 그러나 점차 판매량이 회복세를 보이면서 6개월 후에는 1천700만 대가 판매됐다. 이는 지난해 출시된 갤럭시S21 시리즈의 같은 기간 판매량 1천350만 대 보다 20% 많은 수치다. 삼성전자 갤럭시S20 갤럭시S20 갤럭시S20 울트라 사진 삼성전자 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 미국에선 아이폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다. 앞서 원주 씨는 몇 년 전 자신의 SNS에 애플 아이폰 을 사용하는 모습을 담은 사진을 올려 주목 받았으나 이후 삼성전자의 갤럭시S20 클라우드 블루 갤럭시Z플립3 등을 사용 중인 모습도 목격돼 눈길을 끌었다. 또 이번에는 원주 씨의 하객룩 도 높은 관심을 받았다. 이날 결혼식 하객으로 등장한 원주 씨가 착용한 옷은 이탈리아 명품 브랜드 베르사체 의 2022 봄·여름 컬렉션 베르사체 인서트 실크 미니원피스 로 가격은 294만원이다. 슬리브리스 형태와 함께 화려한 원단의 실크 원단이 포함된 A라인 미니원피스로 국내 다수 판매 채널에서 품절되기도 했다. 원주 씨가 공식 행사에 참석한 것은 고 故 이건희 회장의 장례식 이후 1년 6개월 만이다. 원주 씨는 용산국제학교를 나와 미국 명문 기숙학교인 초트 로즈메리 홀에 다니다 최근 졸업했다. 이날 결혼식에선 부친 이재용 부회장과 제네시스 G90에서 하차해 우산을 나눠쓰고 다정한 모습을 연출했다. 누리꾼들은 뭘 입어도 부티가 난다 과하지 않고 예쁘다 아빠와 딸의 다정한 모습이 보기 좋다 등의 반응을 보였다.<|end_of_text|>\n",
      "\n",
      "Assistant: 지난 재계에 따르면 지난달 27일 정의선 현대차그룹 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐고 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 스마트폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다.<|end_of_text|>\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "세종 뉴스1 김기남 기자 정황근 농림축산식품부 장관 왼쪽 이 1일 오전 단순가공식품 부가가치세 면제 시행 상황을 점검하며 된장 고추장 등 장류 판매 코너를 둘러보고 있다.<|end_of_text|>\n",
      "\n",
      "Assistant: 정황색근 농림축산식품부 장관이 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하기 위해, 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하고, 관련 업무를 한 정황근 장관은 농림축산식품부 장관 왼쪽 왼쪽에서 농림축산식품부와 장류 판매 코너를 둘러보며 상황을 점검하는 정황근 장관을 살피고 있다.<|end_of_text|>\n",
      "Map: 100%|████████████████████████| 1000/1000 [00:00<00:00, 10056.84 examples/s]\n",
      "Map: 100%|█████████████████████████| 1000/1000 [00:00<00:00, 7733.92 examples/s]\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "과거 아이폰 썼던 원주 씨 갤럭시S20 시리즈 사용하는 듯…착용 드레스도 인기 지난달 27일 정의선 현대차그룹 회장 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨의 하객룩 이 높은 관심을 받은 가운데 한 손에 들려있던 스마트폰도 주목 받고 있다. 한 때 원주 씨가 삼성전자가 아닌 경쟁사인 애플의 아이폰 을 쓴 적이 있기 때문이다. 이재용 삼성전자 부회장이 딸 원주 씨와 함께 지난달 27일 서울 중구 정동제일교회에서 열린 정의선 현대차그룹 회장 장녀 진희 씨의 결혼식에 참석하고 있다. 사진 뉴시스 3일 재계에 따르면 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐다. 유명 IT 유튜버 잇섭도 자신의 페이스북을 통해 이재용 부회장님 딸은 갤럭시S20 시리즈를 쓰는 듯하다 며 갤럭시S20 시리즈는 명기였다 고 평가했다. 갤럭시S20 시리즈는 지난 2020년 3월 출시된 스마트폰으로 갤럭시S20 과 갤럭시S20 플러스 갤럭시S20 울트라 등 3종으로 구성됐다. 갤럭시S20 울트라 는 1억800만 화소 갤럭시S20 플러스 와 갤럭시S20 는 6천400만 화소의 고화소 카메라를 탑재했다. 특히 갤럭시S20 울트라 는 최근 1년간 미국 소비자들 사이에서 가장 만족도 높은 제품에 올랐다. 실제로 미국 고객만족지수 ACSI 에 따르면 갤럭시S20 울트라 는 소비자 만족도 조사에서 100점 만점에 86점을 받아 1위에 올랐다. 이번 조사는 지난해 4월부터 올해 3월까지 무작위로 선택된 미국인 2만3천411명으로부터 이메일 답변을 받아 이뤄졌다. 갤럭시S20 시리즈는 출시 당시엔 큰 흥행을 하진 못했다. 당시 역대급 스펙이라는 평가를 받았지만 전작에 비해 20만원가량 높은 가격에 코로나19 사태까지 겹치면서 초반 판매량이 저조했다. 그러나 점차 판매량이 회복세를 보이면서 6개월 후에는 1천700만 대가 판매됐다. 이는 지난해 출시된 갤럭시S21 시리즈의 같은 기간 판매량 1천350만 대 보다 20% 많은 수치다. 삼성전자 갤럭시S20 갤럭시S20 갤럭시S20 울트라 사진 삼성전자 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 미국에선 아이폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다. 앞서 원주 씨는 몇 년 전 자신의 SNS에 애플 아이폰 을 사용하는 모습을 담은 사진을 올려 주목 받았으나 이후 삼성전자의 갤럭시S20 클라우드 블루 갤럭시Z플립3 등을 사용 중인 모습도 목격돼 눈길을 끌었다. 또 이번에는 원주 씨의 하객룩 도 높은 관심을 받았다. 이날 결혼식 하객으로 등장한 원주 씨가 착용한 옷은 이탈리아 명품 브랜드 베르사체 의 2022 봄·여름 컬렉션 베르사체 인서트 실크 미니원피스 로 가격은 294만원이다. 슬리브리스 형태와 함께 화려한 원단의 실크 원단이 포함된 A라인 미니원피스로 국내 다수 판매 채널에서 품절되기도 했다. 원주 씨가 공식 행사에 참석한 것은 고 故 이건희 회장의 장례식 이후 1년 6개월 만이다. 원주 씨는 용산국제학교를 나와 미국 명문 기숙학교인 초트 로즈메리 홀에 다니다 최근 졸업했다. 이날 결혼식에선 부친 이재용 부회장과 제네시스 G90에서 하차해 우산을 나눠쓰고 다정한 모습을 연출했다. 누리꾼들은 뭘 입어도 부티가 난다 과하지 않고 예쁘다 아빠와 딸의 다정한 모습이 보기 좋다 등의 반응을 보였다.<|end_of_text|>\n",
      "\n",
      "Assistant: 지난 재계에 따르면 지난달 27일 정의선 현대차그룹 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐고 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 스마트폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "과거 아이폰 썼던 원주 씨 갤럭시S20 시리즈 사용하는 듯…착용 드레스도 인기 지난달 27일 정의선 현대차그룹 회장 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨의 하객룩 이 높은 관심을 받은 가운데 한 손에 들려있던 스마트폰도 주목 받고 있다. 한 때 원주 씨가 삼성전자가 아닌 경쟁사인 애플의 아이폰 을 쓴 적이 있기 때문이다. 이재용 삼성전자 부회장이 딸 원주 씨와 함께 지난달 27일 서울 중구 정동제일교회에서 열린 정의선 현대차그룹 회장 장녀 진희 씨의 결혼식에 참석하고 있다. 사진 뉴시스 3일 재계에 따르면 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐다. 유명 IT 유튜버 잇섭도 자신의 페이스북을 통해 이재용 부회장님 딸은 갤럭시S20 시리즈를 쓰는 듯하다 며 갤럭시S20 시리즈는 명기였다 고 평가했다. 갤럭시S20 시리즈는 지난 2020년 3월 출시된 스마트폰으로 갤럭시S20 과 갤럭시S20 플러스 갤럭시S20 울트라 등 3종으로 구성됐다. 갤럭시S20 울트라 는 1억800만 화소 갤럭시S20 플러스 와 갤럭시S20 는 6천400만 화소의 고화소 카메라를 탑재했다. 특히 갤럭시S20 울트라 는 최근 1년간 미국 소비자들 사이에서 가장 만족도 높은 제품에 올랐다. 실제로 미국 고객만족지수 ACSI 에 따르면 갤럭시S20 울트라 는 소비자 만족도 조사에서 100점 만점에 86점을 받아 1위에 올랐다. 이번 조사는 지난해 4월부터 올해 3월까지 무작위로 선택된 미국인 2만3천411명으로부터 이메일 답변을 받아 이뤄졌다. 갤럭시S20 시리즈는 출시 당시엔 큰 흥행을 하진 못했다. 당시 역대급 스펙이라는 평가를 받았지만 전작에 비해 20만원가량 높은 가격에 코로나19 사태까지 겹치면서 초반 판매량이 저조했다. 그러나 점차 판매량이 회복세를 보이면서 6개월 후에는 1천700만 대가 판매됐다. 이는 지난해 출시된 갤럭시S21 시리즈의 같은 기간 판매량 1천350만 대 보다 20% 많은 수치다. 삼성전자 갤럭시S20 갤럭시S20 갤럭시S20 울트라 사진 삼성전자 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 미국에선 아이폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다. 앞서 원주 씨는 몇 년 전 자신의 SNS에 애플 아이폰 을 사용하는 모습을 담은 사진을 올려 주목 받았으나 이후 삼성전자의 갤럭시S20 클라우드 블루 갤럭시Z플립3 등을 사용 중인 모습도 목격돼 눈길을 끌었다. 또 이번에는 원주 씨의 하객룩 도 높은 관심을 받았다. 이날 결혼식 하객으로 등장한 원주 씨가 착용한 옷은 이탈리아 명품 브랜드 베르사체 의 2022 봄·여름 컬렉션 베르사체 인서트 실크 미니원피스 로 가격은 294만원이다. 슬리브리스 형태와 함께 화려한 원단의 실크 원단이 포함된 A라인 미니원피스로 국내 다수 판매 채널에서 품절되기도 했다. 원주 씨가 공식 행사에 참석한 것은 고 故 이건희 회장의 장례식 이후 1년 6개월 만이다. 원주 씨는 용산국제학교를 나와 미국 명문 기숙학교인 초트 로즈메리 홀에 다니다 최근 졸업했다. 이날 결혼식에선 부친 이재용 부회장과 제네시스 G90에서 하차해 우산을 나눠쓰고 다정한 모습을 연출했다. 누리꾼들은 뭘 입어도 부티가 난다 과하지 않고 예쁘다 아빠와 딸의 다정한 모습이 보기 좋다 등의 반응을 보였다.<|end_of_text|>\n",
      "\n",
      "Assistant: 지난 재계에 따르면 지난달 27일 정의선 현대차그룹 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐고 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 스마트폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "과거 아이폰 썼던 원주 씨 갤럭시S20 시리즈 사용하는 듯…착용 드레스도 인기 지난달 27일 정의선 현대차그룹 회장 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨의 하객룩 이 높은 관심을 받은 가운데 한 손에 들려있던 스마트폰도 주목 받고 있다. 한 때 원주 씨가 삼성전자가 아닌 경쟁사인 애플의 아이폰 을 쓴 적이 있기 때문이다. 이재용 삼성전자 부회장이 딸 원주 씨와 함께 지난달 27일 서울 중구 정동제일교회에서 열린 정의선 현대차그룹 회장 장녀 진희 씨의 결혼식에 참석하고 있다. 사진 뉴시스 3일 재계에 따르면 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐다. 유명 IT 유튜버 잇섭도 자신의 페이스북을 통해 이재용 부회장님 딸은 갤럭시S20 시리즈를 쓰는 듯하다 며 갤럭시S20 시리즈는 명기였다 고 평가했다. 갤럭시S20 시리즈는 지난 2020년 3월 출시된 스마트폰으로 갤럭시S20 과 갤럭시S20 플러스 갤럭시S20 울트라 등 3종으로 구성됐다. 갤럭시S20 울트라 는 1억800만 화소 갤럭시S20 플러스 와 갤럭시S20 는 6천400만 화소의 고화소 카메라를 탑재했다. 특히 갤럭시S20 울트라 는 최근 1년간 미국 소비자들 사이에서 가장 만족도 높은 제품에 올랐다. 실제로 미국 고객만족지수 ACSI 에 따르면 갤럭시S20 울트라 는 소비자 만족도 조사에서 100점 만점에 86점을 받아 1위에 올랐다. 이번 조사는 지난해 4월부터 올해 3월까지 무작위로 선택된 미국인 2만3천411명으로부터 이메일 답변을 받아 이뤄졌다. 갤럭시S20 시리즈는 출시 당시엔 큰 흥행을 하진 못했다. 당시 역대급 스펙이라는 평가를 받았지만 전작에 비해 20만원가량 높은 가격에 코로나19 사태까지 겹치면서 초반 판매량이 저조했다. 그러나 점차 판매량이 회복세를 보이면서 6개월 후에는 1천700만 대가 판매됐다. 이는 지난해 출시된 갤럭시S21 시리즈의 같은 기간 판매량 1천350만 대 보다 20% 많은 수치다. 삼성전자 갤럭시S20 갤럭시S20 갤럭시S20 울트라 사진 삼성전자 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 미국에선 아이폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다. 앞서 원주 씨는 몇 년 전 자신의 SNS에 애플 아이폰 을 사용하는 모습을 담은 사진을 올려 주목 받았으나 이후 삼성전자의 갤럭시S20 클라우드 블루 갤럭시Z플립3 등을 사용 중인 모습도 목격돼 눈길을 끌었다. 또 이번에는 원주 씨의 하객룩 도 높은 관심을 받았다. 이날 결혼식 하객으로 등장한 원주 씨가 착용한 옷은 이탈리아 명품 브랜드 베르사체 의 2022 봄·여름 컬렉션 베르사체 인서트 실크 미니원피스 로 가격은 294만원이다. 슬리브리스 형태와 함께 화려한 원단의 실크 원단이 포함된 A라인 미니원피스로 국내 다수 판매 채널에서 품절되기도 했다. 원주 씨가 공식 행사에 참석한 것은 고 故 이건희 회장의 장례식 이후 1년 6개월 만이다. 원주 씨는 용산국제학교를 나와 미국 명문 기숙학교인 초트 로즈메리 홀에 다니다 최근 졸업했다. 이날 결혼식에선 부친 이재용 부회장과 제네시스 G90에서 하차해 우산을 나눠쓰고 다정한 모습을 연출했다. 누리꾼들은 뭘 입어도 부티가 난다 과하지 않고 예쁘다 아빠와 딸의 다정한 모습이 보기 좋다 등의 반응을 보였다.<|end_of_text|>\n",
      "\n",
      "Assistant: 지난 재계에 따르면 지난달 27일 정의선 현대차그룹 장녀 결혼식에 참석한 이재용 삼성전자 부회장의 딸 원주 씨가 쥐고 있던 흰색 스마트폰은 갤럭시S20 시리즈로 추정됐고 이처럼 원주 씨가 갤럭시S20 시리즈를 사용하는 것으로 알려지자 일부 누리꾼들은 나랑 같은 폰이다 갤럭시S20 이 전설이긴 했다 스마트폰 쓰는 거 다 걸렸는데 한국에선 예의를 지키는 듯하다 등의 반응이 이어졌다.<|end_of_text|>\n",
      "\n",
      "\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "세종 뉴스1 김기남 기자 정황근 농림축산식품부 장관 왼쪽 이 1일 오전 단순가공식품 부가가치세 면제 시행 상황을 점검하며 된장 고추장 등 장류 판매 코너를 둘러보고 있다.<|end_of_text|>\n",
      "\n",
      "Assistant: 정황색근 농림축산식품부 장관이 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하기 위해, 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하고, 관련 업무를 한 정황근 장관은 농림축산식품부 장관 왼쪽 왼쪽에서 농림축산식품부와 장류 판매 코너를 둘러보며 상황을 점검하는 정황근 장관을 살피고 있다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "세종 뉴스1 김기남 기자 정황근 농림축산식품부 장관 왼쪽 이 1일 오전 단순가공식품 부가가치세 면제 시행 상황을 점검하며 된장 고추장 등 장류 판매 코너를 둘러보고 있다.<|end_of_text|>\n",
      "\n",
      "Assistant: 정황색근 농림축산식품부 장관이 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하기 위해, 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하고, 관련 업무를 한 정황근 장관은 농림축산식품부 장관 왼쪽 왼쪽에서 농림축산식품부와 장류 판매 코너를 둘러보며 상황을 점검하는 정황근 장관을 살피고 있다.<|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "\n",
      "세종 뉴스1 김기남 기자 정황근 농림축산식품부 장관 왼쪽 이 1일 오전 단순가공식품 부가가치세 면제 시행 상황을 점검하며 된장 고추장 등 장류 판매 코너를 둘러보고 있다.<|end_of_text|>\n",
      "\n",
      "Assistant: 정황색근 농림축산식품부 장관이 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하기 위해, 1일 오전 단순가공식품 부가가치세 면제 시행 상황에 대해 점검을 하고, 관련 업무를 한 정황근 장관은 농림축산식품부 장관 왼쪽 왼쪽에서 농림축산식품부와 장류 판매 코너를 둘러보며 상황을 점검하는 정황근 장관을 살피고 있다.<|end_of_text|>\n",
      "\n",
      "\n",
      "Downloading shards: 100%|██████████████████████| 4/4 [00:00<00:00, 17137.09it/s]\n",
      "Downloading shards: 100%|██████████████████████| 4/4 [00:00<00:00, 16895.48it/s]\n",
      "Downloading shards: 100%|██████████████████████| 4/4 [00:00<00:00, 16194.22it/s]\n",
      "Downloading shards: 100%|██████████████████████| 4/4 [00:00<00:00, 16594.67it/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.23s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.23s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:04<00:00,  1.24s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:05<00:00,  1.26s/it]\n",
      "Generating train split: 1600 examples [00:00, 3057.30 examples/s]\n",
      "Generating train split: 1545 examples [00:00, 3935.85 examples/s]\n",
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n",
      "{'loss': 2.2701, 'grad_norm': 0.341796875, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "100%|███████████████████████████████████████████| 12/12 [04:10<00:00, 20.57s/it]\n",
      "  0%|                                                   | 0/387 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▏                                          | 2/387 [00:01<03:27,  1.86it/s]\u001b[A\n",
      "  1%|▎                                          | 3/387 [00:02<04:55,  1.30it/s]\u001b[A\n",
      "  1%|▍                                          | 4/387 [00:03<05:40,  1.13it/s]\u001b[A\n",
      "  1%|▌                                          | 5/387 [00:04<06:05,  1.04it/s]\u001b[A\n",
      "  2%|▋                                          | 6/387 [00:05<06:21,  1.00s/it]\u001b[A\n",
      "  2%|▊                                          | 7/387 [00:06<06:31,  1.03s/it]\u001b[A\n",
      "  2%|▉                                          | 8/387 [00:07<06:38,  1.05s/it]\u001b[A\n",
      "  2%|█                                          | 9/387 [00:08<06:40,  1.06s/it]\u001b[A\n",
      "  3%|█                                         | 10/387 [00:09<06:42,  1.07s/it]\u001b[A\n",
      "  3%|█▏                                        | 11/387 [00:10<06:43,  1.07s/it]\u001b[A\n",
      "  3%|█▎                                        | 12/387 [00:11<06:43,  1.08s/it]\u001b[A\n",
      "  3%|█▍                                        | 13/387 [00:13<06:45,  1.08s/it]\u001b[A\n",
      "  4%|█▌                                        | 14/387 [00:14<06:45,  1.09s/it]\u001b[A\n",
      "  4%|█▋                                        | 15/387 [00:15<06:44,  1.09s/it]\u001b[A\n",
      "  4%|█▋                                        | 16/387 [00:16<06:43,  1.09s/it]\u001b[A\n",
      "  4%|█▊                                        | 17/387 [00:17<06:43,  1.09s/it]\u001b[A\n",
      "  5%|█▉                                        | 18/387 [00:18<06:41,  1.09s/it]\u001b[A\n",
      "  5%|██                                        | 19/387 [00:19<06:40,  1.09s/it]\u001b[A\n",
      "  5%|██▏                                       | 20/387 [00:20<06:40,  1.09s/it]\u001b[A\n",
      "  5%|██▎                                       | 21/387 [00:21<06:38,  1.09s/it]\u001b[A\n",
      "  6%|██▍                                       | 22/387 [00:22<06:38,  1.09s/it]\u001b[A\n",
      "  6%|██▍                                       | 23/387 [00:23<06:39,  1.10s/it]\u001b[A\n",
      "  6%|██▌                                       | 24/387 [00:25<06:38,  1.10s/it]\u001b[A\n",
      "  6%|██▋                                       | 25/387 [00:26<06:38,  1.10s/it]\u001b[A\n",
      "  7%|██▊                                       | 26/387 [00:27<06:35,  1.10s/it]\u001b[A\n",
      "  7%|██▉                                       | 27/387 [00:28<06:34,  1.10s/it]\u001b[A\n",
      "  7%|███                                       | 28/387 [00:29<06:33,  1.10s/it]\u001b[A\n",
      "  7%|███▏                                      | 29/387 [00:30<06:32,  1.10s/it]\u001b[A\n",
      "  8%|███▎                                      | 30/387 [00:31<06:29,  1.09s/it]\u001b[A\n",
      "  8%|███▎                                      | 31/387 [00:32<06:29,  1.09s/it]\u001b[A\n",
      "  8%|███▍                                      | 32/387 [00:33<06:27,  1.09s/it]\u001b[A\n",
      "  9%|███▌                                      | 33/387 [00:34<06:27,  1.09s/it]\u001b[A\n",
      "  9%|███▋                                      | 34/387 [00:36<06:25,  1.09s/it]\u001b[A\n",
      "  9%|███▊                                      | 35/387 [00:37<06:25,  1.10s/it]\u001b[A\n",
      "  9%|███▉                                      | 36/387 [00:38<06:25,  1.10s/it]\u001b[A\n",
      " 10%|████                                      | 37/387 [00:39<06:23,  1.10s/it]\u001b[A\n",
      " 10%|████                                      | 38/387 [00:40<06:22,  1.09s/it]\u001b[A\n",
      " 10%|████▏                                     | 39/387 [00:41<06:20,  1.09s/it]\u001b[A\n",
      " 10%|████▎                                     | 40/387 [00:42<06:19,  1.09s/it]\u001b[A\n",
      " 11%|████▍                                     | 41/387 [00:43<06:19,  1.10s/it]\u001b[A\n",
      " 11%|████▌                                     | 42/387 [00:44<06:19,  1.10s/it]\u001b[A\n",
      " 11%|████▋                                     | 43/387 [00:45<06:18,  1.10s/it]\u001b[A\n",
      " 11%|████▊                                     | 44/387 [00:47<06:16,  1.10s/it]\u001b[A\n",
      " 12%|████▉                                     | 45/387 [00:48<06:16,  1.10s/it]\u001b[A\n",
      " 12%|████▉                                     | 46/387 [00:49<06:14,  1.10s/it]\u001b[A\n",
      " 12%|█████                                     | 47/387 [00:50<06:13,  1.10s/it]\u001b[A\n",
      " 12%|█████▏                                    | 48/387 [00:51<06:12,  1.10s/it]\u001b[A\n",
      " 13%|█████▎                                    | 49/387 [00:52<06:10,  1.10s/it]\u001b[A\n",
      " 13%|█████▍                                    | 50/387 [00:53<06:08,  1.09s/it]\u001b[A\n",
      " 13%|█████▌                                    | 51/387 [00:54<06:06,  1.09s/it]\u001b[A\n",
      " 13%|█████▋                                    | 52/387 [00:55<06:04,  1.09s/it]\u001b[A\n",
      " 14%|█████▊                                    | 53/387 [00:56<06:03,  1.09s/it]\u001b[A\n",
      " 14%|█████▊                                    | 54/387 [00:57<06:03,  1.09s/it]\u001b[A\n",
      " 14%|█████▉                                    | 55/387 [00:59<06:02,  1.09s/it]\u001b[A\n",
      " 14%|██████                                    | 56/387 [01:00<06:00,  1.09s/it]\u001b[A\n",
      " 15%|██████▏                                   | 57/387 [01:01<06:00,  1.09s/it]\u001b[A\n",
      " 15%|██████▎                                   | 58/387 [01:02<05:59,  1.09s/it]\u001b[A\n",
      " 15%|██████▍                                   | 59/387 [01:03<05:58,  1.09s/it]\u001b[A\n",
      " 16%|██████▌                                   | 60/387 [01:04<05:56,  1.09s/it]\u001b[A\n",
      " 16%|██████▌                                   | 61/387 [01:05<05:55,  1.09s/it]\u001b[A\n",
      " 16%|██████▋                                   | 62/387 [01:06<05:56,  1.10s/it]\u001b[A\n",
      " 16%|██████▊                                   | 63/387 [01:07<05:55,  1.10s/it]\u001b[A\n",
      " 17%|██████▉                                   | 64/387 [01:08<05:55,  1.10s/it]\u001b[A\n",
      " 17%|███████                                   | 65/387 [01:09<05:54,  1.10s/it]\u001b[A\n",
      " 17%|███████▏                                  | 66/387 [01:11<05:51,  1.10s/it]\u001b[A\n",
      " 17%|███████▎                                  | 67/387 [01:12<05:49,  1.09s/it]\u001b[A\n",
      " 18%|███████▍                                  | 68/387 [01:13<05:46,  1.09s/it]\u001b[A\n",
      " 18%|███████▍                                  | 69/387 [01:14<05:45,  1.09s/it]\u001b[A\n",
      " 18%|███████▌                                  | 70/387 [01:15<05:44,  1.09s/it]\u001b[A\n",
      " 18%|███████▋                                  | 71/387 [01:16<05:43,  1.09s/it]\u001b[A\n",
      " 19%|███████▊                                  | 72/387 [01:17<05:41,  1.09s/it]\u001b[A\n",
      " 19%|███████▉                                  | 73/387 [01:18<05:40,  1.09s/it]\u001b[A\n",
      " 19%|████████                                  | 74/387 [01:19<05:40,  1.09s/it]\u001b[A\n",
      " 19%|████████▏                                 | 75/387 [01:20<05:38,  1.09s/it]\u001b[A\n",
      " 20%|████████▏                                 | 76/387 [01:21<05:37,  1.09s/it]\u001b[A\n",
      " 20%|████████▎                                 | 77/387 [01:23<05:36,  1.09s/it]\u001b[A\n",
      " 20%|████████▍                                 | 78/387 [01:24<05:35,  1.09s/it]\u001b[A\n",
      " 20%|████████▌                                 | 79/387 [01:25<05:34,  1.09s/it]\u001b[A\n",
      " 21%|████████▋                                 | 80/387 [01:26<05:34,  1.09s/it]\u001b[A\n",
      " 21%|████████▊                                 | 81/387 [01:27<05:33,  1.09s/it]\u001b[A\n",
      " 21%|████████▉                                 | 82/387 [01:28<05:32,  1.09s/it]\u001b[A\n",
      " 21%|█████████                                 | 83/387 [01:29<05:31,  1.09s/it]\u001b[A\n",
      " 22%|█████████                                 | 84/387 [01:30<05:31,  1.09s/it]\u001b[A\n",
      " 22%|█████████▏                                | 85/387 [01:31<05:29,  1.09s/it]\u001b[A\n",
      " 22%|█████████▎                                | 86/387 [01:32<05:28,  1.09s/it]\u001b[A\n",
      " 22%|█████████▍                                | 87/387 [01:33<05:27,  1.09s/it]\u001b[A\n",
      " 23%|█████████▌                                | 88/387 [01:35<05:25,  1.09s/it]\u001b[A\n",
      " 23%|█████████▋                                | 89/387 [01:36<05:24,  1.09s/it]\u001b[A\n",
      " 23%|█████████▊                                | 90/387 [01:37<05:22,  1.09s/it]\u001b[A\n",
      " 24%|█████████▉                                | 91/387 [01:38<05:21,  1.09s/it]\u001b[A\n",
      " 24%|█████████▉                                | 92/387 [01:39<05:20,  1.09s/it]\u001b[A\n",
      " 24%|██████████                                | 93/387 [01:40<05:19,  1.09s/it]\u001b[A\n",
      " 24%|██████████▏                               | 94/387 [01:41<05:18,  1.09s/it]\u001b[A\n",
      " 25%|██████████▎                               | 95/387 [01:42<05:18,  1.09s/it]\u001b[A\n",
      " 25%|██████████▍                               | 96/387 [01:43<05:18,  1.09s/it]\u001b[A\n",
      " 25%|██████████▌                               | 97/387 [01:44<05:17,  1.10s/it]\u001b[A\n",
      " 25%|██████████▋                               | 98/387 [01:45<05:16,  1.09s/it]\u001b[A\n",
      " 26%|██████████▋                               | 99/387 [01:47<05:14,  1.09s/it]\u001b[A\n",
      " 26%|██████████▌                              | 100/387 [01:48<05:12,  1.09s/it]\u001b[A\n",
      " 26%|██████████▋                              | 101/387 [01:49<05:11,  1.09s/it]\u001b[A\n",
      " 26%|██████████▊                              | 102/387 [01:50<05:10,  1.09s/it]\u001b[A\n",
      " 27%|██████████▉                              | 103/387 [01:51<05:09,  1.09s/it]\u001b[A\n",
      " 27%|███████████                              | 104/387 [01:52<05:08,  1.09s/it]\u001b[A\n",
      " 27%|███████████                              | 105/387 [01:53<05:06,  1.09s/it]\u001b[A\n",
      " 27%|███████████▏                             | 106/387 [01:54<05:05,  1.09s/it]\u001b[A\n",
      " 28%|███████████▎                             | 107/387 [01:55<05:04,  1.09s/it]\u001b[A\n",
      " 28%|███████████▍                             | 108/387 [01:56<05:03,  1.09s/it]\u001b[A\n",
      " 28%|███████████▌                             | 109/387 [01:57<05:02,  1.09s/it]\u001b[A\n",
      " 28%|███████████▋                             | 110/387 [01:58<05:01,  1.09s/it]\u001b[A\n",
      " 29%|███████████▊                             | 111/387 [02:00<05:00,  1.09s/it]\u001b[A\n",
      " 29%|███████████▊                             | 112/387 [02:01<04:58,  1.09s/it]\u001b[A\n",
      " 29%|███████████▉                             | 113/387 [02:02<04:57,  1.09s/it]\u001b[A\n",
      " 29%|████████████                             | 114/387 [02:03<04:56,  1.09s/it]\u001b[A\n",
      " 30%|████████████▏                            | 115/387 [02:04<04:55,  1.08s/it]\u001b[A\n",
      " 30%|████████████▎                            | 116/387 [02:05<04:54,  1.09s/it]\u001b[A\n",
      " 30%|████████████▍                            | 117/387 [02:06<04:53,  1.09s/it]\u001b[A\n",
      " 30%|████████████▌                            | 118/387 [02:07<04:53,  1.09s/it]\u001b[A\n",
      " 31%|████████████▌                            | 119/387 [02:08<04:52,  1.09s/it]\u001b[A\n",
      " 31%|████████████▋                            | 120/387 [02:09<04:51,  1.09s/it]\u001b[A\n",
      " 31%|████████████▊                            | 121/387 [02:10<04:50,  1.09s/it]\u001b[A\n",
      " 32%|████████████▉                            | 122/387 [02:12<04:49,  1.09s/it]\u001b[A\n",
      " 32%|█████████████                            | 123/387 [02:13<04:47,  1.09s/it]\u001b[A\n",
      " 32%|█████████████▏                           | 124/387 [02:14<04:46,  1.09s/it]\u001b[A\n",
      " 32%|█████████████▏                           | 125/387 [02:15<04:46,  1.09s/it]\u001b[A\n",
      " 33%|█████████████▎                           | 126/387 [02:16<04:45,  1.09s/it]\u001b[A\n",
      " 33%|█████████████▍                           | 127/387 [02:17<04:43,  1.09s/it]\u001b[A\n",
      " 33%|█████████████▌                           | 128/387 [02:18<04:42,  1.09s/it]\u001b[A\n",
      " 33%|█████████████▋                           | 129/387 [02:19<04:40,  1.09s/it]\u001b[A\n",
      " 34%|█████████████▊                           | 130/387 [02:20<04:39,  1.09s/it]\u001b[A\n",
      " 34%|█████████████▉                           | 131/387 [02:21<04:38,  1.09s/it]\u001b[A\n",
      " 34%|█████████████▉                           | 132/387 [02:22<04:37,  1.09s/it]\u001b[A\n",
      " 34%|██████████████                           | 133/387 [02:24<04:36,  1.09s/it]\u001b[A\n",
      " 35%|██████████████▏                          | 134/387 [02:25<04:35,  1.09s/it]\u001b[A\n",
      " 35%|██████████████▎                          | 135/387 [02:26<04:34,  1.09s/it]\u001b[A\n",
      " 35%|██████████████▍                          | 136/387 [02:27<04:34,  1.09s/it]\u001b[A\n",
      " 35%|██████████████▌                          | 137/387 [02:28<04:32,  1.09s/it]\u001b[A\n",
      " 36%|██████████████▌                          | 138/387 [02:29<04:30,  1.09s/it]\u001b[A\n",
      " 36%|██████████████▋                          | 139/387 [02:30<04:30,  1.09s/it]\u001b[A\n",
      " 36%|██████████████▊                          | 140/387 [02:31<04:29,  1.09s/it]\u001b[A\n",
      " 36%|██████████████▉                          | 141/387 [02:32<04:28,  1.09s/it]\u001b[A\n",
      " 37%|███████████████                          | 142/387 [02:33<04:27,  1.09s/it]\u001b[A\n",
      " 37%|███████████████▏                         | 143/387 [02:34<04:26,  1.09s/it]\u001b[A\n",
      " 37%|███████████████▎                         | 144/387 [02:36<04:25,  1.09s/it]\u001b[A\n",
      " 37%|███████████████▎                         | 145/387 [02:37<04:24,  1.09s/it]\u001b[A\n",
      " 38%|███████████████▍                         | 146/387 [02:38<04:23,  1.09s/it]\u001b[A\n",
      " 38%|███████████████▌                         | 147/387 [02:39<04:22,  1.09s/it]\u001b[A\n",
      " 38%|███████████████▋                         | 148/387 [02:40<04:20,  1.09s/it]\u001b[A\n",
      " 39%|███████████████▊                         | 149/387 [02:41<04:19,  1.09s/it]\u001b[A\n",
      " 39%|███████████████▉                         | 150/387 [02:42<04:18,  1.09s/it]\u001b[A\n",
      " 39%|███████████████▉                         | 151/387 [02:43<04:17,  1.09s/it]\u001b[A\n",
      " 39%|████████████████                         | 152/387 [02:44<04:15,  1.09s/it]\u001b[A\n",
      " 40%|████████████████▏                        | 153/387 [02:45<04:14,  1.09s/it]\u001b[A\n",
      " 40%|████████████████▎                        | 154/387 [02:46<04:13,  1.09s/it]\u001b[A\n",
      " 40%|████████████████▍                        | 155/387 [02:48<04:11,  1.09s/it]\u001b[A\n",
      " 40%|████████████████▌                        | 156/387 [02:49<04:10,  1.08s/it]\u001b[A\n",
      " 41%|████████████████▋                        | 157/387 [02:50<04:09,  1.08s/it]\u001b[A\n",
      " 41%|████████████████▋                        | 158/387 [02:51<04:08,  1.09s/it]\u001b[A\n",
      " 41%|████████████████▊                        | 159/387 [02:52<04:07,  1.09s/it]\u001b[A\n",
      " 41%|████████████████▉                        | 160/387 [02:53<04:06,  1.09s/it]\u001b[A\n",
      " 42%|█████████████████                        | 161/387 [02:54<04:06,  1.09s/it]\u001b[A\n",
      " 42%|█████████████████▏                       | 162/387 [02:55<04:05,  1.09s/it]\u001b[A\n",
      " 42%|█████████████████▎                       | 163/387 [02:56<04:04,  1.09s/it]\u001b[A\n",
      " 42%|█████████████████▎                       | 164/387 [02:57<04:04,  1.10s/it]\u001b[A\n",
      " 43%|█████████████████▍                       | 165/387 [02:58<04:04,  1.10s/it]\u001b[A\n",
      " 43%|█████████████████▌                       | 166/387 [03:00<04:02,  1.10s/it]\u001b[A\n",
      " 43%|█████████████████▋                       | 167/387 [03:01<04:02,  1.10s/it]\u001b[A\n",
      " 43%|█████████████████▊                       | 168/387 [03:02<04:01,  1.10s/it]\u001b[A\n",
      " 44%|█████████████████▉                       | 169/387 [03:03<03:59,  1.10s/it]\u001b[A\n",
      " 44%|██████████████████                       | 170/387 [03:04<03:58,  1.10s/it]\u001b[A\n",
      " 44%|██████████████████                       | 171/387 [03:05<03:56,  1.10s/it]\u001b[A\n",
      " 44%|██████████████████▏                      | 172/387 [03:06<03:54,  1.09s/it]\u001b[A\n",
      " 45%|██████████████████▎                      | 173/387 [03:07<03:54,  1.10s/it]\u001b[A\n",
      " 45%|██████████████████▍                      | 174/387 [03:08<03:53,  1.10s/it]\u001b[A\n",
      " 45%|██████████████████▌                      | 175/387 [03:09<03:51,  1.09s/it]\u001b[A\n",
      " 45%|██████████████████▋                      | 176/387 [03:10<03:50,  1.09s/it]\u001b[A\n",
      " 46%|██████████████████▊                      | 177/387 [03:12<03:48,  1.09s/it]\u001b[A\n",
      " 46%|██████████████████▊                      | 178/387 [03:13<03:47,  1.09s/it]\u001b[A\n",
      " 46%|██████████████████▉                      | 179/387 [03:14<03:48,  1.10s/it]\u001b[A\n",
      " 47%|███████████████████                      | 180/387 [03:15<03:47,  1.10s/it]\u001b[A\n",
      " 47%|███████████████████▏                     | 181/387 [03:16<03:46,  1.10s/it]\u001b[A\n",
      " 47%|███████████████████▎                     | 182/387 [03:17<03:45,  1.10s/it]\u001b[A\n",
      " 47%|███████████████████▍                     | 183/387 [03:18<03:45,  1.10s/it]\u001b[A\n",
      " 48%|███████████████████▍                     | 184/387 [03:19<03:44,  1.11s/it]\u001b[A\n",
      " 48%|███████████████████▌                     | 185/387 [03:20<03:43,  1.10s/it]\u001b[A\n",
      " 48%|███████████████████▋                     | 186/387 [03:21<03:41,  1.10s/it]\u001b[A\n",
      " 48%|███████████████████▊                     | 187/387 [03:23<03:40,  1.10s/it]\u001b[A\n",
      " 49%|███████████████████▉                     | 188/387 [03:24<03:38,  1.10s/it]\u001b[A\n",
      " 49%|████████████████████                     | 189/387 [03:25<03:37,  1.10s/it]\u001b[A\n",
      " 49%|████████████████████▏                    | 190/387 [03:26<03:36,  1.10s/it]\u001b[A\n",
      " 49%|████████████████████▏                    | 191/387 [03:27<03:35,  1.10s/it]\u001b[A\n",
      " 50%|████████████████████▎                    | 192/387 [03:28<03:33,  1.09s/it]\u001b[A\n",
      " 50%|████████████████████▍                    | 193/387 [03:29<03:32,  1.09s/it]\u001b[A\n",
      " 50%|████████████████████▌                    | 194/387 [03:30<03:31,  1.09s/it]\u001b[A\n",
      " 50%|████████████████████▋                    | 195/387 [03:31<03:29,  1.09s/it]\u001b[A\n",
      " 51%|████████████████████▊                    | 196/387 [03:32<03:29,  1.10s/it]\u001b[A\n",
      " 51%|████████████████████▊                    | 197/387 [03:34<03:28,  1.10s/it]\u001b[A\n",
      " 51%|████████████████████▉                    | 198/387 [03:35<03:26,  1.09s/it]\u001b[A\n",
      " 51%|█████████████████████                    | 199/387 [03:36<03:25,  1.09s/it]\u001b[A\n",
      " 52%|█████████████████████▏                   | 200/387 [03:37<03:24,  1.09s/it]\u001b[A\n",
      " 52%|█████████████████████▎                   | 201/387 [03:38<03:23,  1.09s/it]\u001b[A\n",
      " 52%|█████████████████████▍                   | 202/387 [03:39<03:23,  1.10s/it]\u001b[A\n",
      " 52%|█████████████████████▌                   | 203/387 [03:40<03:22,  1.10s/it]\u001b[A\n",
      " 53%|█████████████████████▌                   | 204/387 [03:41<03:20,  1.10s/it]\u001b[A\n",
      " 53%|█████████████████████▋                   | 205/387 [03:42<03:19,  1.10s/it]\u001b[A\n",
      " 53%|█████████████████████▊                   | 206/387 [03:43<03:18,  1.10s/it]\u001b[A\n",
      " 53%|█████████████████████▉                   | 207/387 [03:44<03:16,  1.09s/it]\u001b[A\n",
      " 54%|██████████████████████                   | 208/387 [03:46<03:15,  1.09s/it]\u001b[A\n",
      " 54%|██████████████████████▏                  | 209/387 [03:47<03:14,  1.10s/it]\u001b[A\n",
      " 54%|██████████████████████▏                  | 210/387 [03:48<03:14,  1.10s/it]\u001b[A\n",
      " 55%|██████████████████████▎                  | 211/387 [03:49<03:12,  1.09s/it]\u001b[A\n",
      " 55%|██████████████████████▍                  | 212/387 [03:50<03:11,  1.09s/it]\u001b[A\n",
      " 55%|██████████████████████▌                  | 213/387 [03:51<03:10,  1.09s/it]\u001b[A\n",
      " 55%|██████████████████████▋                  | 214/387 [03:52<03:09,  1.09s/it]\u001b[A\n",
      " 56%|██████████████████████▊                  | 215/387 [03:53<03:07,  1.09s/it]\u001b[A\n",
      " 56%|██████████████████████▉                  | 216/387 [03:54<03:06,  1.09s/it]\u001b[A\n",
      " 56%|██████████████████████▉                  | 217/387 [03:55<03:05,  1.09s/it]\u001b[A\n",
      " 56%|███████████████████████                  | 218/387 [03:57<03:04,  1.09s/it]\u001b[A\n",
      " 57%|███████████████████████▏                 | 219/387 [03:58<03:03,  1.09s/it]\u001b[A\n",
      " 57%|███████████████████████▎                 | 220/387 [03:59<03:01,  1.09s/it]\u001b[A\n",
      " 57%|███████████████████████▍                 | 221/387 [04:00<03:00,  1.09s/it]\u001b[A\n",
      " 57%|███████████████████████▌                 | 222/387 [04:01<02:59,  1.09s/it]\u001b[A\n",
      " 58%|███████████████████████▋                 | 223/387 [04:02<02:58,  1.09s/it]\u001b[A\n",
      " 58%|███████████████████████▋                 | 224/387 [04:03<02:57,  1.09s/it]\u001b[A\n",
      " 58%|███████████████████████▊                 | 225/387 [04:04<02:56,  1.09s/it]\u001b[A\n",
      " 58%|███████████████████████▉                 | 226/387 [04:05<02:55,  1.09s/it]\u001b[A\n",
      " 59%|████████████████████████                 | 227/387 [04:06<02:54,  1.09s/it]\u001b[A\n",
      " 59%|████████████████████████▏                | 228/387 [04:07<02:53,  1.09s/it]\u001b[A\n",
      " 59%|████████████████████████▎                | 229/387 [04:09<02:53,  1.10s/it]\u001b[A\n",
      " 59%|████████████████████████▎                | 230/387 [04:10<02:52,  1.10s/it]\u001b[A\n",
      " 60%|████████████████████████▍                | 231/387 [04:11<02:51,  1.10s/it]\u001b[A\n",
      " 60%|████████████████████████▌                | 232/387 [04:12<02:50,  1.10s/it]\u001b[A\n",
      " 60%|████████████████████████▋                | 233/387 [04:13<02:48,  1.10s/it]\u001b[A\n",
      " 60%|████████████████████████▊                | 234/387 [04:14<02:47,  1.10s/it]\u001b[A\n",
      " 61%|████████████████████████▉                | 235/387 [04:15<02:46,  1.09s/it]\u001b[A\n",
      " 61%|█████████████████████████                | 236/387 [04:16<02:44,  1.09s/it]\u001b[A\n",
      " 61%|█████████████████████████                | 237/387 [04:17<02:44,  1.09s/it]\u001b[A\n",
      " 61%|█████████████████████████▏               | 238/387 [04:18<02:42,  1.09s/it]\u001b[A\n",
      " 62%|█████████████████████████▎               | 239/387 [04:19<02:41,  1.09s/it]\u001b[A\n",
      " 62%|█████████████████████████▍               | 240/387 [04:21<02:40,  1.09s/it]\u001b[A\n",
      " 62%|█████████████████████████▌               | 241/387 [04:22<02:39,  1.09s/it]\u001b[A\n",
      " 63%|█████████████████████████▋               | 242/387 [04:23<02:38,  1.10s/it]\u001b[A\n",
      " 63%|█████████████████████████▋               | 243/387 [04:24<02:38,  1.10s/it]\u001b[A\n",
      " 63%|█████████████████████████▊               | 244/387 [04:25<02:36,  1.10s/it]\u001b[A\n",
      " 63%|█████████████████████████▉               | 245/387 [04:26<02:35,  1.10s/it]\u001b[A\n",
      " 64%|██████████████████████████               | 246/387 [04:27<02:34,  1.10s/it]\u001b[A\n",
      " 64%|██████████████████████████▏              | 247/387 [04:28<02:33,  1.10s/it]\u001b[A\n",
      " 64%|██████████████████████████▎              | 248/387 [04:29<02:32,  1.10s/it]\u001b[A\n",
      " 64%|██████████████████████████▍              | 249/387 [04:30<02:31,  1.10s/it]\u001b[A\n",
      " 65%|██████████████████████████▍              | 250/387 [04:32<02:30,  1.10s/it]\u001b[A\n",
      " 65%|██████████████████████████▌              | 251/387 [04:33<02:29,  1.10s/it]\u001b[A\n",
      " 65%|██████████████████████████▋              | 252/387 [04:34<02:28,  1.10s/it]\u001b[A\n",
      " 65%|██████████████████████████▊              | 253/387 [04:35<02:27,  1.10s/it]\u001b[A\n",
      " 66%|██████████████████████████▉              | 254/387 [04:36<02:26,  1.10s/it]\u001b[A\n",
      " 66%|███████████████████████████              | 255/387 [04:37<02:25,  1.10s/it]\u001b[A\n",
      " 66%|███████████████████████████              | 256/387 [04:38<02:24,  1.10s/it]\u001b[A\n",
      " 66%|███████████████████████████▏             | 257/387 [04:39<02:22,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████▎             | 258/387 [04:40<02:21,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████▍             | 259/387 [04:41<02:20,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████▌             | 260/387 [04:43<02:19,  1.10s/it]\u001b[A\n",
      " 67%|███████████████████████████▋             | 261/387 [04:44<02:18,  1.10s/it]\u001b[A\n",
      " 68%|███████████████████████████▊             | 262/387 [04:45<02:17,  1.10s/it]\u001b[A\n",
      " 68%|███████████████████████████▊             | 263/387 [04:46<02:16,  1.10s/it]\u001b[A\n",
      " 68%|███████████████████████████▉             | 264/387 [04:47<02:15,  1.10s/it]\u001b[A\n",
      " 68%|████████████████████████████             | 265/387 [04:48<02:13,  1.10s/it]\u001b[A\n",
      " 69%|████████████████████████████▏            | 266/387 [04:49<02:12,  1.09s/it]\u001b[A\n",
      " 69%|████████████████████████████▎            | 267/387 [04:50<02:11,  1.09s/it]\u001b[A\n",
      " 69%|████████████████████████████▍            | 268/387 [04:51<02:10,  1.09s/it]\u001b[A\n",
      " 70%|████████████████████████████▍            | 269/387 [04:52<02:08,  1.09s/it]\u001b[A\n",
      " 70%|████████████████████████████▌            | 270/387 [04:53<02:07,  1.09s/it]\u001b[A\n",
      " 70%|████████████████████████████▋            | 271/387 [04:55<02:06,  1.09s/it]\u001b[A\n",
      " 70%|████████████████████████████▊            | 272/387 [04:56<02:05,  1.09s/it]\u001b[A\n",
      " 71%|████████████████████████████▉            | 273/387 [04:57<02:04,  1.09s/it]\u001b[A\n",
      " 71%|█████████████████████████████            | 274/387 [04:58<02:03,  1.09s/it]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 275/387 [04:59<02:02,  1.09s/it]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 276/387 [05:00<02:01,  1.09s/it]\u001b[A\n",
      " 72%|█████████████████████████████▎           | 277/387 [05:01<02:00,  1.09s/it]\u001b[A\n",
      " 72%|█████████████████████████████▍           | 278/387 [05:02<01:59,  1.09s/it]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 279/387 [05:03<01:57,  1.09s/it]\u001b[A\n",
      " 72%|█████████████████████████████▋           | 280/387 [05:04<01:56,  1.09s/it]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 281/387 [05:05<01:55,  1.09s/it]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 282/387 [05:07<01:54,  1.09s/it]\u001b[A\n",
      " 73%|█████████████████████████████▉           | 283/387 [05:08<01:53,  1.09s/it]\u001b[A\n",
      " 73%|██████████████████████████████           | 284/387 [05:09<01:52,  1.09s/it]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 285/387 [05:10<01:51,  1.09s/it]\u001b[A\n",
      " 74%|██████████████████████████████▎          | 286/387 [05:11<01:50,  1.09s/it]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 287/387 [05:12<01:48,  1.09s/it]\u001b[A\n",
      " 74%|██████████████████████████████▌          | 288/387 [05:13<01:47,  1.09s/it]\u001b[A\n",
      " 75%|██████████████████████████████▌          | 289/387 [05:14<01:46,  1.09s/it]\u001b[A\n",
      " 75%|██████████████████████████████▋          | 290/387 [05:15<01:45,  1.09s/it]\u001b[A\n",
      " 75%|██████████████████████████████▊          | 291/387 [05:16<01:44,  1.09s/it]\u001b[A\n",
      " 75%|██████████████████████████████▉          | 292/387 [05:17<01:43,  1.09s/it]\u001b[A\n",
      " 76%|███████████████████████████████          | 293/387 [05:19<01:42,  1.09s/it]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 294/387 [05:20<01:41,  1.09s/it]\u001b[A\n",
      " 76%|███████████████████████████████▎         | 295/387 [05:21<01:40,  1.09s/it]\u001b[A\n",
      " 76%|███████████████████████████████▎         | 296/387 [05:22<01:39,  1.09s/it]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 297/387 [05:23<01:38,  1.09s/it]\u001b[A\n",
      " 77%|███████████████████████████████▌         | 298/387 [05:24<01:37,  1.10s/it]\u001b[A\n",
      " 77%|███████████████████████████████▋         | 299/387 [05:25<01:36,  1.10s/it]\u001b[A\n",
      " 78%|███████████████████████████████▊         | 300/387 [05:26<01:35,  1.10s/it]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 301/387 [05:27<01:34,  1.10s/it]\u001b[A\n",
      " 78%|███████████████████████████████▉         | 302/387 [05:28<01:33,  1.10s/it]\u001b[A\n",
      " 78%|████████████████████████████████         | 303/387 [05:30<01:32,  1.10s/it]\u001b[A\n",
      " 79%|████████████████████████████████▏        | 304/387 [05:31<01:31,  1.10s/it]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 305/387 [05:32<01:30,  1.10s/it]\u001b[A\n",
      " 79%|████████████████████████████████▍        | 306/387 [05:33<01:29,  1.10s/it]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 307/387 [05:34<01:28,  1.10s/it]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 308/387 [05:35<01:27,  1.10s/it]\u001b[A\n",
      " 80%|████████████████████████████████▋        | 309/387 [05:36<01:25,  1.10s/it]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 310/387 [05:37<01:24,  1.10s/it]\u001b[A\n",
      " 80%|████████████████████████████████▉        | 311/387 [05:38<01:23,  1.10s/it]\u001b[A\n",
      " 81%|█████████████████████████████████        | 312/387 [05:39<01:22,  1.10s/it]\u001b[A\n",
      " 81%|█████████████████████████████████▏       | 313/387 [05:41<01:21,  1.10s/it]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 314/387 [05:42<01:20,  1.10s/it]\u001b[A\n",
      " 81%|█████████████████████████████████▎       | 315/387 [05:43<01:18,  1.10s/it]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 316/387 [05:44<01:17,  1.09s/it]\u001b[A\n",
      " 82%|█████████████████████████████████▌       | 317/387 [05:45<01:16,  1.09s/it]\u001b[A\n",
      " 82%|█████████████████████████████████▋       | 318/387 [05:46<01:15,  1.09s/it]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 319/387 [05:47<01:14,  1.09s/it]\u001b[A\n",
      " 83%|█████████████████████████████████▉       | 320/387 [05:48<01:13,  1.09s/it]\u001b[A\n",
      " 83%|██████████████████████████████████       | 321/387 [05:49<01:11,  1.09s/it]\u001b[A\n",
      " 83%|██████████████████████████████████       | 322/387 [05:50<01:10,  1.09s/it]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 323/387 [05:51<01:10,  1.09s/it]\u001b[A\n",
      " 84%|██████████████████████████████████▎      | 324/387 [05:53<01:08,  1.09s/it]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 325/387 [05:54<01:07,  1.09s/it]\u001b[A\n",
      " 84%|██████████████████████████████████▌      | 326/387 [05:55<01:06,  1.09s/it]\u001b[A\n",
      " 84%|██████████████████████████████████▋      | 327/387 [05:56<01:05,  1.10s/it]\u001b[A\n",
      " 85%|██████████████████████████████████▋      | 328/387 [05:57<01:04,  1.10s/it]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 329/387 [05:58<01:03,  1.10s/it]\u001b[A\n",
      " 85%|██████████████████████████████████▉      | 330/387 [05:59<01:02,  1.10s/it]\u001b[A\n",
      " 86%|███████████████████████████████████      | 331/387 [06:00<01:01,  1.10s/it]\u001b[A\n",
      " 86%|███████████████████████████████████▏     | 332/387 [06:01<01:00,  1.10s/it]\u001b[A\n",
      " 86%|███████████████████████████████████▎     | 333/387 [06:02<00:59,  1.10s/it]\u001b[A\n",
      " 86%|███████████████████████████████████▍     | 334/387 [06:04<00:58,  1.10s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▍     | 335/387 [06:05<00:57,  1.10s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 336/387 [06:06<00:55,  1.09s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 337/387 [06:07<00:54,  1.10s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▊     | 338/387 [06:08<00:53,  1.10s/it]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 339/387 [06:09<00:52,  1.10s/it]\u001b[A\n",
      " 88%|████████████████████████████████████     | 340/387 [06:10<00:51,  1.10s/it]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 341/387 [06:11<00:50,  1.09s/it]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 342/387 [06:12<00:49,  1.09s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▎    | 343/387 [06:13<00:47,  1.09s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▍    | 344/387 [06:14<00:46,  1.09s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▌    | 345/387 [06:16<00:45,  1.09s/it]\u001b[A\n",
      " 89%|████████████████████████████████████▋    | 346/387 [06:17<00:44,  1.09s/it]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 347/387 [06:18<00:43,  1.09s/it]\u001b[A\n",
      " 90%|████████████████████████████████████▊    | 348/387 [06:19<00:42,  1.09s/it]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 349/387 [06:20<00:41,  1.09s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████    | 350/387 [06:21<00:40,  1.09s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▏   | 351/387 [06:22<00:39,  1.09s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 352/387 [06:23<00:38,  1.09s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▍   | 353/387 [06:24<00:36,  1.09s/it]\u001b[A\n",
      " 91%|█████████████████████████████████████▌   | 354/387 [06:25<00:35,  1.09s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 355/387 [06:26<00:34,  1.09s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████▋   | 356/387 [06:27<00:33,  1.09s/it]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 357/387 [06:29<00:32,  1.09s/it]\u001b[A\n",
      " 93%|█████████████████████████████████████▉   | 358/387 [06:30<00:31,  1.09s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 359/387 [06:31<00:30,  1.09s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 360/387 [06:32<00:29,  1.09s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████▏  | 361/387 [06:33<00:28,  1.09s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████▎  | 362/387 [06:34<00:27,  1.09s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████▍  | 363/387 [06:35<00:26,  1.09s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 364/387 [06:36<00:25,  1.09s/it]\u001b[A\n",
      " 94%|██████████████████████████████████████▋  | 365/387 [06:37<00:24,  1.09s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 366/387 [06:38<00:22,  1.09s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 367/387 [06:39<00:21,  1.09s/it]\u001b[A\n",
      " 95%|██████████████████████████████████████▉  | 368/387 [06:41<00:20,  1.09s/it]\u001b[A\n",
      " 95%|███████████████████████████████████████  | 369/387 [06:42<00:19,  1.09s/it]\u001b[A\n",
      " 96%|███████████████████████████████████████▏ | 370/387 [06:43<00:18,  1.09s/it]\u001b[A\n",
      " 96%|███████████████████████████████████████▎ | 371/387 [06:44<00:17,  1.09s/it]\u001b[A\n",
      " 96%|███████████████████████████████████████▍ | 372/387 [06:45<00:16,  1.09s/it]\u001b[A\n",
      " 96%|███████████████████████████████████████▌ | 373/387 [06:46<00:15,  1.10s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▌ | 374/387 [06:47<00:14,  1.10s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 375/387 [06:48<00:13,  1.10s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▊ | 376/387 [06:49<00:12,  1.10s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 377/387 [06:50<00:10,  1.09s/it]\u001b[A\n",
      " 98%|████████████████████████████████████████ | 378/387 [06:52<00:09,  1.09s/it]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 379/387 [06:53<00:08,  1.09s/it]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 380/387 [06:54<00:07,  1.09s/it]\u001b[A\n",
      " 98%|████████████████████████████████████████▎| 381/387 [06:55<00:06,  1.09s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 382/387 [06:56<00:05,  1.09s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▌| 383/387 [06:57<00:04,  1.09s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 384/387 [06:58<00:03,  1.09s/it]\u001b[A\n",
      " 99%|████████████████████████████████████████▊| 385/387 [06:59<00:02,  1.09s/it]\u001b[A\n",
      "100%|████████████████████████████████████████▉| 386/387 [07:00<00:01,  1.09s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.0376877784729004, 'eval_runtime': 423.2936, 'eval_samples_per_second': 3.65, 'eval_steps_per_second': 0.914, 'epoch': 0.96}\n",
      "100%|███████████████████████████████████████████| 12/12 [11:13<00:00, 20.57s/it]\n",
      "100%|█████████████████████████████████████████| 387/387 [07:01<00:00,  1.09s/it]\u001b[A\n",
      "                                                                                \u001b[A[rank0]:[2024-06-30 02:29:34,501] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.23855582099349704, 'preprocessing_with_comm': 0.0026307549997000024, 'state_converting': 0.2083166080119554, <Type.ALL: 'all'>: 0.4608237159991404})\n",
      "{'train_runtime': 688.1047, 'train_samples_per_second': 2.325, 'train_steps_per_second': 0.017, 'train_loss': 2.2310734589894614, 'epoch': 0.96}\n",
      "100%|███████████████████████████████████████████| 12/12 [11:28<00:00, 57.34s/it]\n"
     ]
    }
   ],
   "source": [
    "!ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 torchrun --nproc_per_node=4 \\\n",
    "../scripts/local_run_fsdp_qlora.py \\\n",
    "--config local_llama_3_8b_fsdp_qlora.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441607e4-f93f-438e-8985-99a76233fe47",
   "metadata": {},
   "source": [
    "## 4. 베이스 모델과 훈련된 모델 머지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cebdb212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('meta-llama/Meta-Llama-3-8B',\n",
       " '/home/ec2-user/SageMaker/models/llama-3-8b-naver-news')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id, output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8acc4",
   "metadata": {},
   "source": [
    "### 모델 머지 및 로컬에 저장\n",
    "- 약 2분 걸림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 7731.44it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  2.00it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Load PEFT model on CPU\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")  \n",
    "# Merge LoRA and base model and save\n",
    "merged_model = model.merge_and_unload()\n",
    "merged_model.save_pretrained(output_dir,safe_serialization=True, max_shard_size=\"2GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d0e3827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device, merged_model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0ea42",
   "metadata": {},
   "source": [
    "### 머지된 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a6607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [00:00<00:00, 8108.85it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer \n",
    "\n",
    "\n",
    "# Load Model with PEFT adapter\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "  pretrained_model_name_or_path = output_dir,\n",
    "  torch_dtype=torch.float16,\n",
    "  quantization_config= {\"load_in_4bit\": True},\n",
    "  device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de5b126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6908046b",
   "metadata": {},
   "source": [
    "## 5. 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5388b34",
   "metadata": {},
   "source": [
    "### 테스트 데이터 셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eacd377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_idx:  75\n",
      "messages: \n",
      " [{'content': 'You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.', 'role': 'system'}, {'content': 'Please summarize the goals for journalist in this text:\\n\\n한국 건설사 수주 기대감 높아 성공시 제2 중동 붐 전망까지 삼성물산·현대건설 컨소시엄 10억달러 규모 터널공사 수주 이미지출처 연합뉴스 사우디아라비아의 실세 무함마드 빈살만 제1왕위 계승자 왕세자 가 사우디를 개방적이고 온건한 이슬람 국가로 바꾸겠다고 선언했다. 국제유가 상승으로 사우디 아라비아의 국부가 늘면서 대규모 인프라 투자로 이어지자 한국 건설사들의 수주 기대감이 높아지고 있다. 대표적인 것이 네옴시티 로 사우디 실권자인 무함마드 빈 살만 왕세자가 주도하는 이 프로젝트는 총 사업비만 무려 5000억달러 약 640조원 에 달하는 세계 최대 규모 인프라 사업이다. 이미 물밑에서 수주 경쟁이 치열한 이 사업은 한국 건설사들이 대규모 수주에 성공할 경우 제 2의 중동 붐 을 일으킬 것이란 전망까지 나온다. 1일 증권업계 및 건설업계에 의하면 사우디발 인프라 건설 훈풍으로 국내 건설사들의 수주 기대감이 커지고 있다. 사우디는 2016년 발표한 비전 2030 에 의해 국가전략을 수행하고 있는데 이는 석유에 의존해온 경제를 첨단 제조업 중심으로 전환하기 위한 프로젝트로 네옴시티도 이 중 하나다. 이미 사우디는 비공개로 입찰을 진행 국내에선 삼성물산과 현대건설이 컨소시엄을 구성해 네옴시티 더 라인 의 터널 공사를 수주한 것으로 알려졌다. 수주액은 약 10억달러 약 1조3000억원 규모다. 미래 먹거리로 로봇 및 자율주행과 같은 스마트 시티 를 추진하고 있는 현대차도 수주 가능성이 높은 것으로 알려졌다. 이에삼성엔지니어링 현대건설 대우건설 GS건설 DL이앤씨 등 해외 인프라 건설 사업 대형 5개사는 주택을 제외한 신규 수주 달성치를 높여잡았다. 현재 발주시장 확대에 근거해 이들 5개사는 2023년에는 신규 수주 금액이 합산 32조원으로 20%이상 성장 가능할 것으로 전망된다. 최대규모 인프라 사업인 네옴시티를 제외하고서라도 향후 해외건설시장 규모는 점점 더 커질 전망이다. 네옴시티 수주전을 차치하고서라도 건설사들의 수주 기대감을 높이는 부분이다. 글로벌시장조사업체 IHS 마킷에 따르면 지난해 해외건설시장 규모는 10조9000억달러 약 1경4002조8500억원 으로 전년대비 10.7% 증가했다. 올해는 전년대비 5.5% 증가한 11조5000억달러로 예상된다. 해외 건설시장은 원자재 가격 상승과 러시아 우크라이나 사태에도 불구하고 견고한 성장세를 이어나가고 있는 셈이다. 내년 해외 건설 시장 규모는 12조1000억달러 2025년엔 13조8000억달러로 연 평균 4.8%씩 증가할 것으로 예상된다. 박세라 신영증권 연구원은 중동 산유국을 중심으로 한 제 3차 발주웨이브는 이제 시작됐다 며 이에 올해 대형 5개사의 주택을 제외한 신규 수주 목표금액은 27조원으로 전년 23조원 대비 16% 상향제시한 바 있다 고 밝혔다.', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "from random import randint\n",
    "\n",
    "def get_message_from_dataset(sample_dataset_json_file):\n",
    "    # Load our test dataset\n",
    "    full_test_dataset = load_dataset(\"json\", data_files=sample_dataset_json_file, split=\"train\")\n",
    "\n",
    "    # Test on sample \n",
    "    rand_idx = randint(0, len(full_test_dataset)-1)\n",
    "    rand_idx = 75\n",
    "    print(\"rand_idx: \", rand_idx)\n",
    "    messages = full_test_dataset[rand_idx][\"messages\"][:2]\n",
    "    # messages = test_dataset[rand_idx][\"text\"][:2]\n",
    "    print(\"messages: \\n\", messages)\n",
    "\n",
    "    return messages, full_test_dataset, rand_idx\n",
    "\n",
    "messages, full_test_dataset, rand_idx = get_message_from_dataset(sample_dataset_json_file = full_test_data_json)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15b47b",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddaf71a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Query:**\n",
      "Please summarize the goals for journalist in this text:\n",
      "\n",
      "한국 건설사 수주 기대감 높아 성공시 제2 중동 붐 전망까지 삼성물산·현대건설 컨소시엄 10억달러 규모 터널공사 수주 이미지출처 연합뉴스 사우디아라비아의 실세 무함마드 빈살만 제1왕위 계승자 왕세자 가 사우디를 개방적이고 온건한 이슬람 국가로 바꾸겠다고 선언했다. 국제유가 상승으로 사우디 아라비아의 국부가 늘면서 대규모 인프라 투자로 이어지자 한국 건설사들의 수주 기대감이 높아지고 있다. 대표적인 것이 네옴시티 로 사우디 실권자인 무함마드 빈 살만 왕세자가 주도하는 이 프로젝트는 총 사업비만 무려 5000억달러 약 640조원 에 달하는 세계 최대 규모 인프라 사업이다. 이미 물밑에서 수주 경쟁이 치열한 이 사업은 한국 건설사들이 대규모 수주에 성공할 경우 제 2의 중동 붐 을 일으킬 것이란 전망까지 나온다. 1일 증권업계 및 건설업계에 의하면 사우디발 인프라 건설 훈풍으로 국내 건설사들의 수주 기대감이 커지고 있다. 사우디는 2016년 발표한 비전 2030 에 의해 국가전략을 수행하고 있는데 이는 석유에 의존해온 경제를 첨단 제조업 중심으로 전환하기 위한 프로젝트로 네옴시티도 이 중 하나다. 이미 사우디는 비공개로 입찰을 진행 국내에선 삼성물산과 현대건설이 컨소시엄을 구성해 네옴시티 더 라인 의 터널 공사를 수주한 것으로 알려졌다. 수주액은 약 10억달러 약 1조3000억원 규모다. 미래 먹거리로 로봇 및 자율주행과 같은 스마트 시티 를 추진하고 있는 현대차도 수주 가능성이 높은 것으로 알려졌다. 이에삼성엔지니어링 현대건설 대우건설 GS건설 DL이앤씨 등 해외 인프라 건설 사업 대형 5개사는 주택을 제외한 신규 수주 달성치를 높여잡았다. 현재 발주시장 확대에 근거해 이들 5개사는 2023년에는 신규 수주 금액이 합산 32조원으로 20%이상 성장 가능할 것으로 전망된다. 최대규모 인프라 사업인 네옴시티를 제외하고서라도 향후 해외건설시장 규모는 점점 더 커질 전망이다. 네옴시티 수주전을 차치하고서라도 건설사들의 수주 기대감을 높이는 부분이다. 글로벌시장조사업체 IHS 마킷에 따르면 지난해 해외건설시장 규모는 10조9000억달러 약 1경4002조8500억원 으로 전년대비 10.7% 증가했다. 올해는 전년대비 5.5% 증가한 11조5000억달러로 예상된다. 해외 건설시장은 원자재 가격 상승과 러시아 우크라이나 사태에도 불구하고 견고한 성장세를 이어나가고 있는 셈이다. 내년 해외 건설 시장 규모는 12조1000억달러 2025년엔 13조8000억달러로 연 평균 4.8%씩 증가할 것으로 예상된다. 박세라 신영증권 연구원은 중동 산유국을 중심으로 한 제 3차 발주웨이브는 이제 시작됐다 며 이에 올해 대형 5개사의 주택을 제외한 신규 수주 목표금액은 27조원으로 전년 23조원 대비 16% 상향제시한 바 있다 고 밝혔다.\n",
      "\n",
      "**Original Answer:**\n",
      "국제우디아라비아의 실세 무함마드 빈살만 제1왕위 계승자 왕세자가 사우디를 개방적이고 온건한 이슬람 국가로 바꾸겠다고 선언하고, 총 사업비만 무려 5000억달러 약 640조원 에 달하는 세계 최대 인프라 사업 네옴시티를 사우디 실권자인 무함마드 빈 살만 왕세자가 주도하는 것으로 이미 물밑에서 수주 경쟁이 치열한 이 사업은 한국 건설사들이 대규모 수주에 성공할 경우 제 2의 중동 붐을 일으킬 것이란 전망까지 나온다.\n",
      "\n",
      "**Generated Answer:**\n",
      "2023년 4월 6일 한국 건설사 수주 기대감 높아 성공시 제2 중동 붐 전망까지 삼성물산·현대건설 컨소시엄 10억달러 규모 터널공사 수주 국제유가 상승으로 사우디 아라비아의 국부가 늘면서 대규모 인프라 투자로 이어지자 한국 건설사들의 수주 기대감이 높아지고 있다. 대표적인 것이 네옴시티 로 사우디 실권자인 무함마드 빈 살만 왕세자가 주도하는 이 프로젝트는 총 사업비만 무려 5000억달러 약 640조원 에 달하는 세계 최대 규모 인프라 사업이다. 이미 물밑에서 수주 경쟁이 치열한 이 사업은 한국 건설사들이 대규모 수주에 성공할 경우 제 2의 중동 붐 을 일으킬 것이란 전망까지 나온다. 1일 증권업계 및 건설업계에 의하면 사우디발 인프라 건설 훈풍으로 국내 건설사들의 수주 기대감이 커지고 있다. 사우디는 2016년 발표한 비전 2030 에 의해 국가전략을 수행하고 있는데 이는 석유에 의존해온 경제를 첨단 제조업 중심으로 전환하기 위한 프로젝트로 네옴시티도 이 중 하나다. 이미 사우디는 비공개로 입찰을 진행 국내에선 삼성물산과 현대건설이 컨소시엄을 구성해 네옴시티 더 라인 의 터널 공사를 수주한 것으로 알려졌다. 수주액은 약 10억달러 약 1조3000억원 규모다. 미래 먹거리로 로봇 및 자율주행과 같은 스마트 시티 를 추진하고 있는 현대차도 수주 가능성이 높은 것으로 알려졌다. 이에삼성엔지니어링 현대건설 대우건설 GS건설 DL이앤씨 등 해외 인프라 건설 사업 대형 5개사는 주택을 제외한 신규 수주 달성치를 높여잡았다. 현재 발주시장 확대에 근거해 이들 5개사는 2023년에는 신규 수주 금액이 합산 32조원\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_response(messages, model, tokenizer, full_test_dataset, rand_idx):\n",
    "    input_ids = tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id= tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "\n",
    "    print(f\"**Query:**\\n{full_test_dataset[rand_idx]['messages'][1]['content']}\\n\")\n",
    "    # print(f\"**Query:**\\n{test_dataset[rand_idx]['text'][1]['content']}\\n\")\n",
    "    # print(f\"**Original Answer:**\\n{test_dataset[rand_idx]['text'][2]['content']}\\n\")\n",
    "    print(f\"**Original Answer:**\\n{full_test_dataset[rand_idx]['messages'][2]['content']}\\n\")\n",
    "    print(f\"**Generated Answer:**\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n",
    "\n",
    "generate_response(messages, model, tokenizer, full_test_dataset, rand_idx)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7138dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llama3_puy310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
