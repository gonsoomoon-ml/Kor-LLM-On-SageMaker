{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# 데이터셋 준비하기\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b5f4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "\n",
    "!huggingface-cli login --token {HF_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcebd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_DATASETS_CACHE'] = \"/home/ec2-user/SageMaker/.cache\" \n",
    "os.environ['HF_HOME'] = \"/home/ec2-user/SageMaker/.cache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4b722-f752-4687-8fbe-12855566892c",
   "metadata": {},
   "source": [
    "## 2. 데이터 셋 준비\n",
    "### 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3710c3d-71bb-47b1-97eb-a72ef6dcfd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 22194\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 2466\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['date', 'category', 'press', 'title', 'document', 'link', 'summary'],\n",
       "        num_rows: 2740\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"daekeun-ml/naver-news-summarization-ko\"\n",
    "\n",
    "# dataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\n",
    "dataset = load_dataset(huggingface_dataset_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94062514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '2022-07-03 17:14:37',\n",
       " 'category': 'economy',\n",
       " 'press': 'YTN ',\n",
       " 'title': '추경호 중기 수출지원 총력 무역금융 40조 확대',\n",
       " 'document': '앵커 정부가 올해 하반기 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 했습니다. 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했습니다. 류환홍 기자가 보도합니다. 기자 수출은 최고의 실적을 보였지만 수입액이 급증하면서 올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록했습니다. 정부가 수출확대에 총력을 기울이기로 한 것은 원자재 가격 상승 등 대외 리스크가 가중되는 상황에서 수출 증가세 지속이야말로 한국경제의 회복을 위한 열쇠라고 본 것입니다. 추경호 경제부총리 겸 기획재정부 장관 정부는 우리 경제의 성장엔진인 수출이 높은 증가세를 지속할 수 있도록 총력을 다하겠습니다. 우선 물류 부담 증가 원자재 가격 상승 등 가중되고 있는 대외 리스크에 대해 적극 대응하겠습니다. 특히 중소기업과 중견기업 수출 지원을 위해 무역금융 규모를 연초 목표보다 40조 원 늘린 301조 원까지 확대하고 물류비 부담을 줄이기 위한 대책도 마련했습니다. 이창양 산업통상자원부 장관 국제 해상운임이 안정될 때까지 월 4척 이상의 임시선박을 지속 투입하는 한편 중소기업 전용 선복 적재 용량 도 현재보다 주당 50TEU 늘려 공급하겠습니다. 하반기에 우리 기업들의 수출 기회를 늘리기 위해 2 500여 개 수출기업을 대상으로 해외 전시회 참가를 지원하는 등 마케팅 지원도 벌이기로 했습니다. 정부는 또 이달 중으로 반도체를 비롯한 첨단 산업 육성 전략을 마련해 수출 증가세를 뒷받침하고 에너지 소비를 줄이기 위한 효율화 방안을 마련해 무역수지 개선에 나서기로 했습니다. YTN 류환홍입니다.',\n",
       " 'link': 'https://n.news.naver.com/mnews/article/052/0001759333?sid=101',\n",
       " 'summary': '올해 상반기 우리나라 무역수지는 역대 최악인 103억 달러 적자를 기록한 가운데, 정부가 하반기에 우리 경제의 버팀목인 수출 확대를 위해 총력을 기울이기로 결정한 가운데, 특히 수출 중소기업의 물류난 해소를 위해 무역금융 규모를 40조 원 이상 확대하고 물류비 지원과 임시선박 투입 등을 추진하기로 했다.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96451467-4fc0-49af-bedf-040850c11fbb",
   "metadata": {},
   "source": [
    "## 3. 데이터셋 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eda452",
   "metadata": {},
   "source": [
    "### Chat Message 형태 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1181ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def format_instruction(system_prompt: str, article: str, summary: str):\n",
    "    message = [\n",
    "            {\n",
    "                'content': system_prompt,\n",
    "                'role': 'system'\n",
    "            },\n",
    "            {\n",
    "                'content': f'Please summarize the goals for journalist in this text:\\n\\n{article}',\n",
    "                'role': 'user'\n",
    "            },\n",
    "            {\n",
    "                'content': f'{summary}',\n",
    "                'role': 'assistant'\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    return message # json.dumps(message, indent=2) # json.dumps(message, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# 사용 예시\n",
    "# system_prompt = \"You are an AI assistant specialized in news articles. Your role is to provide accurate summaries and insights. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\"\n",
    "# article = \"Within three days, the intertwined cup nest of grasses was complete, featuring a canopy of overhanging grasses to conceal it. And decades later, it served as Rinkert's portal to the past inside the California Academy of Sciences. Information gleaned from such nests, woven long ago from species in plant communities called transitional habitat, could help restore the shoreline in the future. Transitional habitat has nearly disappeared from the San Francisco Bay, and scientists need a clearer picture of its original species composition—which was never properly documented. With that insight, conservation research groups like the San Francisco Bay Bird Observatory can help guide best practices when restoring the native habitat that has long served as critical refuge for imperiled birds and animals as adjacent marshes flood more with rising sea levels. \\\"We can't ask restoration ecologists to plant nonnative species or to just take their best guess and throw things out there,\\\" says Rinkert.\"\n",
    "# summary = \"Scientists are studying nests hoping to learn about transitional habitats that could help restore the shoreline of San Francisco Bay.\"\n",
    "\n",
    "# print(format_instruction(system_prompt, article, summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a4269",
   "metadata": {},
   "source": [
    "### Chat Message 형태로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fede492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'category', 'press', 'title', 'document', 'link', 'summary']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add system message to each conversation\n",
    "columns_to_remove = list(dataset[\"train\"].features)\n",
    "columns_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5a43e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "    system_prompt = \"You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\"\n",
    "\n",
    "    return {\n",
    "        \"messages\": format_instruction(system_prompt, data_point[\"document\"],data_point[\"summary\"])\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(columns_to_remove)\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390bfdf",
   "metadata": {},
   "source": [
    "##### 전체 데이터 셋에서 일부 데티터 추출 (짧은 실습을 위해서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75ddc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_debug_samples = 10\n",
    "test_num_debug_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0edb7874",
   "metadata": {},
   "outputs": [],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "\n",
    "dataset[\"train\"] = process_dataset(dataset[\"train\"].select(range(train_num_debug_samples)))\n",
    "dataset[\"test\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f033fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 1000 rows from the training split\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select([i for i in range(train_num_debug_samples)])\n",
    "\n",
    "# Select 100 rows from the test and validation splits\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select([i for i in range(test_num_debug_samples)])\n",
    "validation_dataset = dataset['validation'].shuffle(seed=42).select([i for i in range(test_num_debug_samples)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6deeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['messages'],\n",
       "     num_rows: 10\n",
       " }))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset,test_dataset,validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7197aa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'Please summarize the goals for journalist in this text:\\n\\n한탄바이러스 발견 노벨상 유력 후보로 자주 거론 한국을 대표하는 의학자이자 미생물학자 이호왕 고려대 명예교수. 고려대의대 제공 한탄바이러스를 발견한 우리나라 대표 의과학자 이호왕 고려대 명예교수가 5일 숙환으로 별세했다. 향년 94세. 고인은 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자다. 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다. 1928년 함경남도 신흥에서 출생한 고인은 1973년 고대의대에 부임해 의과대학장을 지냈으며 1982년 세계보건기구 신증후출혈열연구협력센터 소장 2000년 대한민국학술원 회장 등을 역임했다. 1979년 미국 최고민간인공로훈장 1987년 인촌상 1992년 호암상 1995년 태국 프린스 마히돌상 2001년 일본 니케이 아시아상 2002년 과학기술훈장 창조장 2009년 서재필의학상 2018년 대한민국 과학기술유공자로 추대됐으며 2002년 미국 학술원 NAS 외국회원 2009년 일본 학사원 명예회원에 선정되며 국내외 학계에서 활발한 활동을 이어왔다. 고인의 빈소는 고려대 안암병원 장례식장 303호에 마련됐다. 발인은 7일 오전 11시 50분이고 장지는 서울추모공원이다. 고인은 1976년 3월 경기도 동두천 한탄강 유역에서 채집한 등줄쥐의 폐 조직에서 세계 최초로 유행성출혈열 병원체와 면역체를 발견한 것으로 널리 알려졌다. 고인은 이 병원체 바이러스를 발견장소의 이름을 따 명명했다. 그 유명한 한탄 바이러스 의 발견이었다. 고인이 병원체를 발견하기 전까지 이 유행성출혈열은 당시 정체불명의 괴질로 유명했다. 1916년 러시아 블라디보스토크에서 첫 환자가 보고된 뒤 2차 세계대전과 6·25전쟁을 거치며 수천 명의 희생자를 냈다. 당시 소련과 중국은 대대적인 인체실험까지 벌였고 미국은 노벨상 수상자 2명이 포함된 연구진 200여명과 막대한 예산을 투입해 정체를 밝히려고 애썼지만 감염 경로와 원인 병원체를 찾지 못했다. 한탄바이러스가 발견된 이후 국내에선 백신제조까지 일사천리로 이뤄졌다. 1991년 녹십자는 고인과 공동연구를 유행성출혈열 예방 백신 ‘한타 박스’를 내놨다. 바이러스 발견자가 진단법과 예방 백신까지 개발한 최초 사례다. 지금도 휴전선 일대에 근무하는 군인과 주민은 이 주사를 맞는다. 고인은 한탄바이러스 분리와 백신 개발로 유력한 노벨상 수상자로 거론되기도 했다. 2019년 9월 연구데이터 분석기업 클래리베이터 애널리틱스가 선정한 ‘2021년 피인용 우수 연구자’ 16명 중 한 명으로 꼽혔기 때문이다. 당시 국내 기관 소속 연구자로는 다섯 번째 한국인으로는 네 번째였다. 클래리베이트의 피인용 우수 연구자는 1970년 이후 등록된 과학기술인용색인 SCI 논문 5200만여 건 중 최상위 0.01%에 속하는 2000회 이상 인용된 논문을 보유하면서 동시에 연구가 독창적이고 인류에 높은 공헌을 한 경우 선정된다. 노벨상 수상의 예측 지표 중 하나로 여겨진다. 고인은 또한 한국인이 사랑하는 근대 과학자였다. 지난 2016년 과학기술정보통신부 전신인 미래창조과학부와 한국과학창의재단 한국경제신문이 진행한 우리 생활을 변화시킨 근현대 대표 과학기술인’ 조사에서 한국이 낳은 세계적 물리학자인 고 故 이휘소 박사가 대한민국 최고 과학자에 이어 고인을 두 번째로 많이 꼽았다.',\n",
       "   'role': 'user'},\n",
       "  {'content': '이 이호왕 고려대 명예교수는 바이러스의 병원체와 진단법 백신까지 모두 개발한 한국을 대표하는 의학자이자 미생물학자이며, 신증후군출혈열 병원체인 한탄바이러스와 서울바이러스를 세계 최초로 발견하고 예방백신 및 진단법을 개발해 세계 의학발전에 기여한 것으로 평가된다.',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dda7e7",
   "metadata": {},
   "source": [
    "## 4. 데이터 셋을 JSON 으로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8af3619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_json:  ../data/naver-news-summarization-ko/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dataset_name = huggingface_dataset_name.split(\"/\")[1]\n",
    "data_folder = os.path.join(\"../data/\",dataset_name)\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "train_data_json = os.path.join(data_folder, \"train_dataset.json\")\n",
    "validation_data_json = os.path.join(data_folder, \"validation_dataset.json\")\n",
    "test_data_json = os.path.join(data_folder, \"test_dataset.json\")\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e88d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35daf6b0be1f4370825a6d7386d2b874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2309bb23792442a18cef3f45dfe497f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eef19d2422467b9181b88bbd85d511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "29075"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save datasets to disk \n",
    "train_dataset.to_json(train_data_json, orient=\"records\", force_ascii=False)\n",
    "validation_dataset.to_json(validation_data_json, orient=\"records\", force_ascii=False)\n",
    "test_dataset.to_json(test_data_json, orient=\"records\", force_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c521c6f",
   "metadata": {},
   "source": [
    "### 다음 노트북에서 사용하기 위해 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70fb035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_folder' (str)\n",
      "Stored 'train_data_json' (str)\n",
      "Stored 'validation_data_json' (str)\n",
      "Stored 'test_data_json' (str)\n"
     ]
    }
   ],
   "source": [
    "%store data_folder\n",
    "%store train_data_json \n",
    "%store validation_data_json \n",
    "%store test_data_json \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5c4cc",
   "metadata": {},
   "source": [
    "## 5. Option: 데이터 셋을 ChatTemplate 형태로 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165e725",
   "metadata": {},
   "source": [
    "### Chat Template 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea4ba09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{% if message['role'] == 'system' %}{{ message['content'] }}{% elif message['role'] == 'user' %}{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}{% elif message['role'] == 'assistant' %}{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '\\n\\nAssistant: ' }}{% endif %}\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLAMA_3_CHAT_TEMPLATE = (\n",
    "    \"{% for message in messages %}\"\n",
    "        \"{% if message['role'] == 'system' %}\"\n",
    "            \"{{ message['content'] }}\"\n",
    "        \"{% elif message['role'] == 'user' %}\"\n",
    "            \"{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}\"\n",
    "        \"{% elif message['role'] == 'assistant' %}\"\n",
    "            \"{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}\"\n",
    "        \"{% endif %}\"\n",
    "    \"{% endfor %}\"\n",
    "    \"{% if add_generation_prompt %}\"\n",
    "    \"{{ '\\n\\nAssistant: ' }}\"\n",
    "    \"{% endif %}\"\n",
    ")\n",
    "LLAMA_3_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfcc19",
   "metadata": {},
   "source": [
    "### Chat Template 으로 변형하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54451f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec7e201fd2d42c4af5e571befb9e196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce051816c60b482b896d920297a7a2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9aaa4e24f54c369a10dfbb5d4001ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea2bd7b7ece4ac8a3883f09b0b712ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225bf3d0efb6411aaac0a617f330526b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer        \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n",
    "\n",
    "# template dataset\n",
    "def template_dataset(examples):\n",
    "    return{\"text\":  tokenizer.apply_chat_template(examples[\"messages\"], tokenize=False)}\n",
    "\n",
    "train_dataset = train_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
    "test_dataset = test_dataset.map(template_dataset, remove_columns=[\"messages\"])\n",
    "validation_dataset = validation_dataset.map(template_dataset, remove_columns=[\"messages\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fc1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0d955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "380fc688",
   "metadata": {},
   "source": [
    "### 변형된 Chat Message 형태 예시 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print random sample\n",
    "import random\n",
    "\n",
    "for index in random.sample(range(len(train_dataset)), 1):\n",
    "    print(\"index: \", index)\n",
    "    # index = 5343\n",
    "    print(train_dataset[index][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60aaa4-b654-49b3-bb87-34ad6a9f375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('pytorch_p310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
