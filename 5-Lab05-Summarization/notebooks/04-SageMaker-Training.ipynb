{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker 에서 Llama 3 파인 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "!huggingface-cli login --token {HF_TOKEN}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder:  ../data/naver-news-summarization-ko\n",
      "train_data_json:  ../data/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test/test_dataset.json\n",
      "full_train_data_json:  ../data/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "full_validation_data_json:  ../data/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "full_test_data_json:  ../data/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "%store -r data_folder\n",
    "%store -r train_data_json \n",
    "%store -r validation_data_json \n",
    "%store -r test_data_json \n",
    "%store -r full_train_data_json \n",
    "%store -r full_validation_data_json \n",
    "%store -r full_test_data_json\n",
    "\n",
    "\n",
    "print(\"data_folder: \", data_folder)\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)\n",
    "print(\"full_train_data_json: \", full_train_data_json)\n",
    "print(\"full_validation_data_json: \", full_validation_data_json)\n",
    "print(\"full_test_data_json: \", full_test_data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 기본 변수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/SageMaker/.xdg/config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::057716757052:role/gen_ai_gsmoon\n",
      "sagemaker bucket: sagemaker-us-east-1-057716757052\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 데이터 셋 경로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "\n",
      "input_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def create_s3_path(sess,is_full, data_folder,train_data_json,validation_data_json,test_data_json,verbose=True  ):\n",
    "    dataset_name = data_folder.split('/')[-1]\n",
    "    # save train_dataset to s3 using our SageMaker session\n",
    "    input_path = f's3://{sess.default_bucket()}/datasets/{dataset_name}'\n",
    "    print(\"input_path: \\n\", input_path)\n",
    "\n",
    "    trian_file_name = train_data_json.split('/')[-1]\n",
    "    validation_file_name = validation_data_json.split('/')[-1]\n",
    "    test_file_name = test_data_json.split('/')[-1]\n",
    "\n",
    "    if is_full:\n",
    "        train_dataset_s3_path = f\"{input_path}/full_train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/full_validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/full_test/{test_file_name}\"\n",
    "    else:\n",
    "        train_dataset_s3_path = f\"{input_path}/train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/test/{test_file_name}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"train_dataset_s3_path: \\n\", train_dataset_s3_path)\n",
    "        print(\"validation_dataset_s3_path: \\n\", validation_dataset_s3_path)\n",
    "        print(\"test_dataset_s3_path: \\n\", test_dataset_s3_path)\n",
    "\n",
    "    return train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path\n",
    "\n",
    "train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = False,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=train_data_json,\n",
    "                                                                            validation_data_json=validation_data_json,\n",
    "                                                                            test_data_json=test_data_json)    \n",
    "print(\"\")\n",
    "full_train_dataset_s3_path, full_validation_dataset_s3_path, full_test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = True,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=full_train_data_json,\n",
    "                                                                            validation_data_json=full_validation_data_json,\n",
    "                                                                            test_data_json=full_test_data_json)    \n",
    "\n",
    "# full_train_data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이타를 S3 에 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_prefix_name(s3_path, verbose=True):\n",
    "    file_name = s3_path.split('/')[-1]\n",
    "    file_name = '/' + file_name\n",
    "    desired_s3_uri = s3_path.split(file_name)[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"file_name: \", file_name)\n",
    "        print(\"desired_s3_uri: \", desired_s3_uri)\n",
    "    return desired_s3_uri\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "def upload_data_s3(desired_s3_uri, file_name, verbose=True):\n",
    "    # upload the model yaml file to s3\n",
    "    \n",
    "    file_s3_path = S3Uploader.upload(local_path=file_name, desired_s3_uri=desired_s3_uri)\n",
    "\n",
    "    print(f\"{file_name} is uploaded to:\")\n",
    "    print(file_s3_path)\n",
    "\n",
    "    return file_s3_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug 용 작은 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train\n",
      "../data/naver-news-summarization-ko/train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation\n",
      "../data/naver-news-summarization-ko/validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test\n",
      "../data/naver-news-summarization-ko/test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "train_desired_s3_uri = get_s3_prefix_name(train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=train_desired_s3_uri, file_name=train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "validation_desired_s3_uri = get_s3_prefix_name(validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=validation_desired_s3_uri, file_name=validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "test_desired_s3_uri = get_s3_prefix_name(test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=test_desired_s3_uri, file_name=test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가용 큰 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train\n",
      "../data/naver-news-summarization-ko/full_train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation\n",
      "../data/naver-news-summarization-ko/full_validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test\n",
      "../data/naver-news-summarization-ko/full_test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "full_train_desired_s3_uri = get_s3_prefix_name(full_train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=full_train_desired_s3_uri, file_name=full_train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "full_validation_desired_s3_uri = get_s3_prefix_name(full_validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_validation_desired_s3_uri, file_name=full_validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "full_test_desired_s3_uri = get_s3_prefix_name(full_test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_test_desired_s3_uri, file_name=full_test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 업로드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-30 10:01:56    2.5 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml\n",
      "2024-06-30 13:24:16    8.4 MiB datasets/naver-news-summarization-ko/full_test/test_dataset.json\n",
      "2024-06-30 13:24:14   68.0 MiB datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "2024-06-30 13:24:16    7.6 MiB datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "2024-06-30 13:24:13   33.4 KiB datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "2024-06-30 13:24:13   28.1 KiB datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "2024-06-30 13:24:13   26.1 KiB datasets/naver-news-summarization-ko/validation/validation_dataset.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {input_path}  --recursive --human-readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! aws s3 rm {input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! aws s3 cp {train_data_json} {train_dataset_s3_path}\n",
    "# ! aws s3 cp {validation_data_json} {validation_dataset_s3_path}\n",
    "# ! aws s3 cp {test_data_json} {test_dataset_s3_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 훈련 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 설정 파일 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sm_llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile sm_llama_3_8b_fsdp_qlora.yaml\n",
    "# script parameters\n",
    "model_id:  \"meta-llama/Meta-Llama-3-8B\" # Hugging Face model id\n",
    "max_seq_len:  2048              # max sequence length for model and packing of the dataset\n",
    "# sagemaker specific parameters\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\" # path to where SageMaker saves train dataset\n",
    "validation_dataset_path: \"/opt/ml/input/data/validation/\" # path to where SageMaker saves train dataset\n",
    "test_dataset_path: \"/opt/ml/input/data/test/\"   # path to where SageMaker saves test dataset\n",
    "# output_dir: \"/opt/ml/model\"            # path to where SageMaker will upload the model \n",
    "output_dir: \"/tmp/llama3\"            # path to where SageMaker will upload the model \n",
    "# training parameters\n",
    "report_to: \"tensorboard\"               # report metrics to tensorboard\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "###########################             \n",
    "# For Debug\n",
    "###########################             \n",
    "# num_train_epochs: 1                    # number of training epochs\n",
    "# per_device_train_batch_size: 1         # batch size per device during training\n",
    "# per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "# For evaluation\n",
    "###########################             \n",
    "num_train_epochs: 3                    # number of training epochs\n",
    "per_device_train_batch_size: 16         # batch size per device during training\n",
    "per_device_eval_batch_size: 8          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap offload\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설정 파일을 S3 에 업로드\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_llama_3_8b_fsdp_qlora.yaml is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_desired_s3_uri = f\"{input_path}/config\"\n",
    "config_model_name = \"sm_llama_3_8b_fsdp_qlora.yaml\"\n",
    "train_config_s3_path = upload_data_s3(desired_s3_uri=config_desired_s3_uri, file_name=config_model_name, verbose=True)\n",
    "\n",
    "\n",
    "# from sagemaker.s3 import S3Uploader\n",
    "\n",
    "# # upload the model yaml file to s3\n",
    "# model_yaml = \"sm_llama_3_8b_fsdp_qlora.yaml\"\n",
    "# train_config_s3_path = S3Uploader.upload(local_path=model_yaml, desired_s3_uri=f\"{input_path}/config\")\n",
    "\n",
    "# print(f\"Training config uploaded to:\")\n",
    "# print(train_config_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 입력 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug 데이터 샘플 실행\n",
    "- run_debug_sample = False 조절 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json',\n",
       " 'validation': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json',\n",
       " 'config': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# run_debug_sample = True\n",
    "run_debug_sample = False\n",
    "if run_debug_sample:\n",
    "  local_data = {\n",
    "    'train': f'file://{train_data_json}',\n",
    "    'validation': f'file://{validation_data_json}',\n",
    "    'config': f'file://{config_model_name}'\n",
    "    }\n",
    "\n",
    "  s3_data = {\n",
    "    'train': train_dataset_s3_path,\n",
    "    'validation': validation_dataset_s3_path,\n",
    "    'config': train_config_s3_path\n",
    "    }  \n",
    "else:\n",
    "  local_data = {\n",
    "    'train': f'file://{train_data_json}',\n",
    "    'validation': f'file://{validation_data_json}',\n",
    "    'config': f'file://{config_model_name}'\n",
    "    }\n",
    "  s3_data = {\n",
    "    'train': full_train_dataset_s3_path,\n",
    "    'validation': full_validation_dataset_s3_path,\n",
    "    'config': train_config_s3_path\n",
    "    }  \n",
    "s3_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clolud 모드 및 Local 사용\n",
    "- 현재 로컬 모드는 에러 발행. 확인 중 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cloud mode is set with ml.g5.48xlarge and 1 of instance_count\n",
      "dataset: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json', 'validation': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json', 'config': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml'}\n"
     ]
    }
   ],
   "source": [
    "# USE_LOCAL_MODE = True\n",
    "USE_LOCAL_MODE = False\n",
    "\n",
    "import torch\n",
    "\n",
    "if USE_LOCAL_MODE:\n",
    "    instance_type = 'local_gpu' if torch.cuda.is_available() else 'local'\n",
    "    instance_count = 1\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    # data = local_data \n",
    "    data = s3_data\n",
    "    nKeepAliveSeconds = None # Warmpool feature\n",
    "    print(\"## Local mode is set\")\n",
    "else:\n",
    "    # instance_type = 'ml.g5.12xlarge'\n",
    "    instance_type = 'ml.g5.48xlarge'\n",
    "    # instance_type = 'ml.p4d.24xlarge'\n",
    "    instance_count = 1\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    data = s3_data\n",
    "    nKeepAliveSeconds = 3600 # Warmpool feature, 1 hour\n",
    "    print(f\"## Cloud mode is set with {instance_type} and {instance_count} of instance_count\")\n",
    "print(\"dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 Estimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/llama3_puy310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "import time\n",
    "# define Training Job Name \n",
    "job_name = f'llama3-8b-naver-news-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "# chkpt_s3_path = f's3://{sess.default_bucket()}/{s3_prefix}/native/checkpoints'\n",
    "\n",
    "# create the Estimator\n",
    "os.environ['USE_SHORT_LIVED_CREDENTIALS']=\"1\" \n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'sm_run_fsdp_qlora_llama3.py',      # train script\n",
    "    source_dir           = '../scripts',  # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type,  # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 500,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36.0',          # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1.0',           # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  {\n",
    "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost\n",
    "    keep_alive_period_in_seconds = nKeepAliveSeconds,     # warm pool \n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},   # enables torchrun\n",
    "    environment  = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "        \"HF_TOKEN\": HF_TOKEN,       # huggingface token to access gated models, e.g. llama 3\n",
    "        \"ACCELERATE_USE_FSDP\": \"1\",             # enable FSDP\n",
    "        \"FSDP_CPU_RAM_EFFICIENT_LOADING\": \"1\"   # enable CPU RAM efficient loading\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit(data, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-30 13:24:21 Starting - Starting the training job...\n",
      "2024-06-30 13:24:36 Downloading - Downloading the training image\n",
      "2024-06-30 13:24:36 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-06-30 13:24:37,701 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-06-30 13:24:37,766 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-30 13:24:37,778 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-06-30 13:24:37,780 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\n",
      "2024-06-30 13:24:37,780 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-06-30 13:24:39,408 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Collecting transformers==4.40.0 (from -r requirements.txt (line 1))\n",
      "Downloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.6/137.6 kB 8.6 MB/s eta 0:00:00\n",
      "Collecting datasets==2.18.0 (from -r requirements.txt (line 2))\n",
      "Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==0.29.3 (from -r requirements.txt (line 3))\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.1)\n",
      "Collecting bitsandbytes==0.43.1 (from -r requirements.txt (line 5))\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting huggingface_hub==0.22.2 (from -r requirements.txt (line 6))\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting trl==0.8.6 (from -r requirements.txt (line 7))\n",
      "Downloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting peft==0.10.0 (from -r requirements.txt (line 8))\n",
      "Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting torch==2.1.1 (from -r requirements.txt (line 9))\n",
      "Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.40.0->-r requirements.txt (line 1))\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (4.66.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (2.1.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r requirements.txt (line 2)) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.9.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3->-r requirements.txt (line 3)) (5.9.5)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.22.2->-r requirements.txt (line 6)) (4.8.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.6->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (2.1.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->-r requirements.txt (line 9))\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (13.6.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (1.6.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.1->-r requirements.txt (line 9)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (0.1.0)\n",
      "Downloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.0/9.0 MB 80.3 MB/s eta 0:00:00\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.5/510.5 kB 40.7 MB/s eta 0:00:00\n",
      "Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 297.6/297.6 kB 29.5 MB/s eta 0:00:00\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 16.9 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 388.9/388.9 kB 37.7 MB/s eta 0:00:00\n",
      "Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 245.2/245.2 kB 31.1 MB/s eta 0:00:00\n",
      "Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.1/199.1 kB 25.2 MB/s eta 0:00:00\n",
      "Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 670.2/670.2 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 80.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 59.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 54.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 1.9 MB/s eta 0:00:00\n",
      "Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 33.2 MB/s eta 0:00:00\n",
      "Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 17.1 MB/s eta 0:00:00\n",
      "Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 10.8 MB/s eta 0:00:00\n",
      "Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 87.0 MB/s eta 0:00:00\n",
      "Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
      "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.3/21.3 MB 63.5 MB/s eta 0:00:00\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, datasets, bitsandbytes, accelerate, trl, peft\n",
      "Attempting uninstall: huggingface_hub\n",
      "Found existing installation: huggingface-hub 0.20.3\n",
      "Uninstalling huggingface-hub-0.20.3:\n",
      "Successfully uninstalled huggingface-hub-0.20.3\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.15.1\n",
      "Uninstalling tokenizers-0.15.1:\n",
      "Successfully uninstalled tokenizers-0.15.1\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.36.0\n",
      "Uninstalling transformers-4.36.0:\n",
      "Successfully uninstalled transformers-4.36.0\n",
      "Attempting uninstall: torch\n",
      "Found existing installation: torch 2.1.0\n",
      "Uninstalling torch-2.1.0:\n",
      "Successfully uninstalled torch-2.1.0\n",
      "Attempting uninstall: datasets\n",
      "Found existing installation: datasets 2.15.0\n",
      "Uninstalling datasets-2.15.0:\n",
      "Successfully uninstalled datasets-2.15.0\n",
      "Attempting uninstall: bitsandbytes\n",
      "Found existing installation: bitsandbytes 0.42.0\n",
      "Uninstalling bitsandbytes-0.42.0:\n",
      "Successfully uninstalled bitsandbytes-0.42.0\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.25.0\n",
      "Uninstalling accelerate-0.25.0:\n",
      "Successfully uninstalled accelerate-0.25.0\n",
      "Attempting uninstall: trl\n",
      "Found existing installation: trl 0.7.4\n",
      "Uninstalling trl-0.7.4:\n",
      "Successfully uninstalled trl-0.7.4\n",
      "Attempting uninstall: peft\n",
      "Found existing installation: peft 0.7.1\n",
      "Uninstalling peft-0.7.1:\n",
      "Successfully uninstalled peft-0.7.1\n",
      "Successfully installed accelerate-0.29.3 bitsandbytes-0.43.1 datasets-2.18.0 huggingface_hub-0.22.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 peft-0.10.0 tokenizers-0.19.1 torch-2.1.1 transformers-4.40.0 trl-0.8.6\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.1.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "2024-06-30 13:26:10,375 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-06-30 13:26:10,375 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-06-30 13:26:10,460 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-30 13:26:10,539 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-30 13:26:10,552 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\n",
      "2024-06-30 13:26:10,617 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-06-30 13:26:10,632 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.48xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sm_run_fsdp_qlora_llama3\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 192,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.48xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.48xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sm_run_fsdp_qlora_llama3.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"config\":\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"}\n",
      "SM_USER_ENTRY_POINT=sm_run_fsdp_qlora_llama3.py\n",
      "SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.48xlarge\",\"sagemaker_torch_distributed_enabled\":true}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"config\",\"train\",\"validation\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.48xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=sm_run_fsdp_qlora_llama3\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=192\n",
      "SM_NUM_GPUS=8\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.48xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.48xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config\":\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342/source/sourcedir.tar.gz\",\"module_name\":\"sm_run_fsdp_qlora_llama3\",\"network_interface_name\":\"eth0\",\"num_cpus\":192,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.48xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.48xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sm_run_fsdp_qlora_llama3.py\"}\n",
      "SM_USER_ARGS=[\"--config\",\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_CONFIG=/opt/ml/input/data/config\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "SM_HP_CONFIG=/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "torchrun --nnodes 1 --nproc_per_node 8 sm_run_fsdp_qlora_llama3.py --config /opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\n",
      "[2024-06-30 13:26:12,100] torch.distributed.run: [WARNING] \n",
      "[2024-06-30 13:26:12,100] torch.distributed.run: [WARNING] *****************************************\n",
      "[2024-06-30 13:26:12,100] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "[2024-06-30 13:26:12,100] torch.distributed.run: [WARNING] *****************************************\n",
      "## script_args: \n",
      " ScriptArguments(train_dataset_path='/opt/ml/input/data/train/', validation_dataset_path='/opt/ml/input/data/validation/', model_id='meta-llama/Meta-Llama-3-8B', max_seq_length=512)\n",
      "## training_args:\n",
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>, <FSDPOption.OFFLOAD: 'offload'>],\n",
      "fsdp_config={'backward_prefetch': 'backward_pre', 'forward_prefetch': 'false', 'use_orig_params': 'false', 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0002,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/llama3/runs/Jun30_13-26-17_algo-1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=0.3,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/tmp/llama3,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/llama3,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=True,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.03,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 3288 examples [00:00, 32708.78 examples/s]\n",
      "Generating train split: 9737 examples [00:00, 36568.68 examples/s]\n",
      "Generating train split: 16317 examples [00:00, 39674.74 examples/s]\n",
      "Generating train split: 22194 examples [00:00, 40900.02 examples/s]\n",
      "Generating train split: 22194 examples [00:00, 39514.64 examples/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 2466 examples [00:00, 38424.10 examples/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/22194 [00:00<?, ? examples/s]\n",
      "Map:   3%|▎         | 747/22194 [00:00<00:02, 7394.73 examples/s]\n",
      "Map:   3%|▎         | 732/22194 [00:00<00:02, 7246.12 examples/s]\n",
      "Map:   3%|▎         | 731/22194 [00:00<00:02, 7238.27 examples/s]\n",
      "Map:   3%|▎         | 752/22194 [00:00<00:02, 7458.11 examples/s]\n",
      "Map:   3%|▎         | 741/22194 [00:00<00:02, 7337.29 examples/s]\n",
      "Map:   3%|▎         | 756/22194 [00:00<00:02, 7501.51 examples/s]\n",
      "Map:   3%|▎         | 744/22194 [00:00<00:02, 7369.98 examples/s]\n",
      "Map:   3%|▎         | 754/22194 [00:00<00:02, 7480.42 examples/s]\n",
      "Map:   7%|▋         | 1632/22194 [00:00<00:02, 8237.55 examples/s]\n",
      "Map:   7%|▋         | 1607/22194 [00:00<00:02, 8124.02 examples/s]\n",
      "Map:   7%|▋         | 1603/22194 [00:00<00:02, 8099.72 examples/s]\n",
      "Map:   7%|▋         | 1637/22194 [00:00<00:02, 8272.29 examples/s]\n",
      "Map:   7%|▋         | 1609/22194 [00:00<00:02, 8119.25 examples/s]\n",
      "Map:   7%|▋         | 1630/22194 [00:00<00:02, 8224.72 examples/s]\n",
      "Map:   7%|▋         | 1624/22194 [00:00<00:02, 8204.07 examples/s]\n",
      "Map:   7%|▋         | 1627/22194 [00:00<00:02, 8210.74 examples/s]\n",
      "Map:  12%|█▏        | 2586/22194 [00:00<00:02, 8826.43 examples/s]\n",
      "Map:  11%|█▏        | 2533/22194 [00:00<00:02, 8634.96 examples/s]\n",
      "Map:  11%|█▏        | 2525/22194 [00:00<00:02, 8605.11 examples/s]\n",
      "Map:  12%|█▏        | 2584/22194 [00:00<00:02, 8813.30 examples/s]\n",
      "Map:  11%|█▏        | 2544/22194 [00:00<00:02, 8675.71 examples/s]\n",
      "Map:  12%|█▏        | 2578/22194 [00:00<00:02, 8794.88 examples/s]\n",
      "Map:  12%|█▏        | 2556/22194 [00:00<00:02, 8707.55 examples/s]\n",
      "Map:  12%|█▏        | 2565/22194 [00:00<00:02, 8738.25 examples/s]\n",
      "Map:  16%|█▌        | 3533/22194 [00:00<00:02, 9072.66 examples/s]\n",
      "Map:  16%|█▌        | 3507/22194 [00:00<00:02, 8913.48 examples/s]\n",
      "Map:  16%|█▌        | 3509/22194 [00:00<00:02, 8908.54 examples/s]\n",
      "Map:  16%|█▌        | 3534/22194 [00:00<00:02, 9081.52 examples/s]\n",
      "Map:  16%|█▌        | 3512/22194 [00:00<00:02, 8954.84 examples/s]#015Map:  16%|█▌        | 3530/22194 [00:00<00:02, 9078.45 examples/s]\n",
      "Map:  16%|█▌        | 3512/22194 [00:00<00:02, 8982.87 examples/s]\n",
      "Map:  16%|█▌        | 3509/22194 [00:00<00:02, 8989.73 examples/s]\n",
      "Map:  20%|██        | 4519/22194 [00:00<00:01, 9132.26 examples/s]\n",
      "Map:  20%|██        | 4502/22194 [00:00<00:01, 8989.98 examples/s]\n",
      "Map:  20%|██        | 4505/22194 [00:00<00:01, 8965.97 examples/s]\n",
      "Map:  20%|██        | 4517/22194 [00:00<00:01, 9119.75 examples/s]\n",
      "Map:  20%|██        | 4515/22194 [00:00<00:01, 9121.03 examples/s]\n",
      "Map:  20%|██        | 4506/22194 [00:00<00:01, 9000.54 examples/s]\n",
      "Map:  20%|██        | 4505/22194 [00:00<00:01, 9017.51 examples/s]\n",
      "Map:  20%|██        | 4509/22194 [00:00<00:01, 9046.61 examples/s]\n",
      "Map:  25%|██▍       | 5530/22194 [00:00<00:01, 9261.56 examples/s]\n",
      "Map:  25%|██▍       | 5504/22194 [00:00<00:01, 9086.51 examples/s]\n",
      "Map:  25%|██▍       | 5503/22194 [00:00<00:01, 9050.63 examples/s]\n",
      "Map:  25%|██▍       | 5518/22194 [00:00<00:01, 9225.35 examples/s]\n",
      "Map:  25%|██▍       | 5520/22194 [00:00<00:01, 9246.51 examples/s]\n",
      "Map:  25%|██▍       | 5509/22194 [00:00<00:01, 9093.67 examples/s]\n",
      "Map:  25%|██▍       | 5510/22194 [00:00<00:01, 9119.23 examples/s]\n",
      "Map:  25%|██▍       | 5511/22194 [00:00<00:01, 9152.13 examples/s]\n",
      "Map:  29%|██▉       | 6517/22194 [00:00<00:01, 9324.59 examples/s]\n",
      "Map:  29%|██▉       | 6509/22194 [00:00<00:01, 9155.00 examples/s]\n",
      "Map:  29%|██▉       | 6508/22194 [00:00<00:01, 9127.78 examples/s]\n",
      "Map:  29%|██▉       | 6516/22194 [00:00<00:01, 9281.95 examples/s]\n",
      "Map:  29%|██▉       | 6515/22194 [00:00<00:01, 9318.78 examples/s]\n",
      "Map:  29%|██▉       | 6504/22194 [00:00<00:01, 9149.42 examples/s]\n",
      "Map:  29%|██▉       | 6507/22194 [00:00<00:01, 9191.56 examples/s]\n",
      "Map:  29%|██▉       | 6510/22194 [00:00<00:01, 9211.09 examples/s]\n",
      "Map:  34%|███▍      | 7521/22194 [00:00<00:01, 9264.62 examples/s]\n",
      "Map:  34%|███▍      | 7507/22194 [00:00<00:01, 9139.70 examples/s]\n",
      "Map:  34%|███▍      | 7509/22194 [00:00<00:01, 9083.40 examples/s]\n",
      "Map:  34%|███▍      | 7515/22194 [00:00<00:01, 9214.29 examples/s]\n",
      "Map:  34%|███▍      | 7518/22194 [00:00<00:01, 9272.75 examples/s]\n",
      "Map:  34%|███▍      | 7506/22194 [00:00<00:01, 9109.18 examples/s]\n",
      "Map:  34%|███▍      | 7511/22194 [00:00<00:01, 9148.13 examples/s]\n",
      "Map:  34%|███▍      | 7512/22194 [00:00<00:01, 9162.35 examples/s]\n",
      "Map:  38%|███▊      | 8517/22194 [00:00<00:01, 9304.37 examples/s]\n",
      "Map:  38%|███▊      | 8505/22194 [00:00<00:01, 9194.34 examples/s]\n",
      "Map:  38%|███▊      | 8503/22194 [00:00<00:01, 9136.57 examples/s]\n",
      "Map:  38%|███▊      | 8511/22194 [00:00<00:01, 9253.43 examples/s]\n",
      "Map:  38%|███▊      | 8519/22194 [00:00<00:01, 9355.08 examples/s]\n",
      "Map:  38%|███▊      | 8499/22194 [00:00<00:01, 9137.32 examples/s]\n",
      "Map:  38%|███▊      | 8508/22194 [00:00<00:01, 9213.28 examples/s]\n",
      "Map:  38%|███▊      | 8508/22194 [00:00<00:01, 9196.07 examples/s]\n",
      "Map:  43%|████▎     | 9523/22194 [00:01<00:01, 9355.01 examples/s]\n",
      "Map:  43%|████▎     | 9510/22194 [00:01<00:01, 9237.24 examples/s]\n",
      "Map:  43%|████▎     | 9516/22194 [00:01<00:01, 9310.32 examples/s]\n",
      "Map:  43%|████▎     | 9507/22194 [00:01<00:01, 9176.46 examples/s]\n",
      "Map:  43%|████▎     | 9519/22194 [00:01<00:01, 9409.33 examples/s]\n",
      "Map:  42%|████▏     | 9423/22194 [00:01<00:01, 9165.45 examples/s]\n",
      "Map:  43%|████▎     | 9511/22194 [00:01<00:01, 9277.99 examples/s]\n",
      "Map:  43%|████▎     | 9518/22194 [00:01<00:01, 9267.21 examples/s]\n",
      "Map:  47%|████▋     | 10519/22194 [00:01<00:01, 9387.81 examples/s]\n",
      "Map:  47%|████▋     | 10504/22194 [00:01<00:01, 9265.89 examples/s]\n",
      "Map:  47%|████▋     | 10520/22194 [00:01<00:01, 9351.04 examples/s]\n",
      "Map:  47%|████▋     | 10504/22194 [00:01<00:01, 9197.46 examples/s]\n",
      "Map:  47%|████▋     | 10519/22194 [00:01<00:01, 9430.74 examples/s]\n",
      "Map:  47%|████▋     | 10342/22194 [00:01<00:01, 9169.61 examples/s]\n",
      "Map:  47%|████▋     | 10515/22194 [00:01<00:01, 9306.50 examples/s]\n",
      "Map:  47%|████▋     | 10507/22194 [00:01<00:01, 9278.39 examples/s]\n",
      "Map:  52%|█████▏    | 11517/22194 [00:01<00:01, 9402.43 examples/s]\n",
      "Map:  52%|█████▏    | 11503/22194 [00:01<00:01, 9259.54 examples/s]\n",
      "Map:  51%|█████     | 11265/22194 [00:01<00:01, 9186.81 examples/s]\n",
      "Map:  52%|█████▏    | 11515/22194 [00:01<00:01, 9365.92 examples/s]\n",
      "Map:  52%|█████▏    | 11517/22194 [00:01<00:01, 9447.70 examples/s]\n",
      "Map:  52%|█████▏    | 11509/22194 [00:01<00:01, 9222.82 examples/s]\n",
      "Map:  52%|█████▏    | 11513/22194 [00:01<00:01, 9336.39 examples/s]\n",
      "Map:  52%|█████▏    | 11512/22194 [00:01<00:01, 9309.88 examples/s]\n",
      "Map:  56%|█████▋    | 12522/22194 [00:01<00:01, 9414.73 examples/s]\n",
      "Map:  56%|█████▋    | 12506/22194 [00:01<00:01, 9251.99 examples/s]\n",
      "Map:  55%|█████▍    | 12189/22194 [00:01<00:01, 9201.10 examples/s]\n",
      "Map:  56%|█████▋    | 12524/22194 [00:01<00:01, 9402.21 examples/s]\n",
      "Map:  56%|█████▋    | 12523/22194 [00:01<00:01, 9473.67 examples/s]\n",
      "Map:  56%|█████▋    | 12508/22194 [00:01<00:01, 9236.42 examples/s]\n",
      "Map:  56%|█████▋    | 12521/22194 [00:01<00:01, 9386.70 examples/s]\n",
      "Map:  56%|█████▋    | 12509/22194 [00:01<00:01, 9316.56 examples/s]\n",
      "Map:  61%|██████    | 13517/22194 [00:01<00:00, 9434.16 examples/s]\n",
      "Map:  61%|██████    | 13512/22194 [00:01<00:00, 9293.82 examples/s]\n",
      "Map:  59%|█████▉    | 13119/22194 [00:01<00:00, 9228.52 examples/s]\n",
      "Map:  61%|██████    | 13516/22194 [00:01<00:00, 9418.68 examples/s]\n",
      "Map:  61%|██████    | 13519/22194 [00:01<00:00, 9498.00 examples/s]\n",
      "Map:  61%|██████    | 13506/22194 [00:01<00:00, 9263.00 examples/s]\n",
      "Map:  61%|██████    | 13508/22194 [00:01<00:00, 9381.02 examples/s]\n",
      "Map:  61%|██████    | 13506/22194 [00:01<00:00, 9338.06 examples/s]\n",
      "Map:  65%|██████▌   | 14520/22194 [00:01<00:00, 9390.80 examples/s]\n",
      "Map:  65%|██████▌   | 14511/22194 [00:01<00:00, 9309.94 examples/s]\n",
      "Map:  65%|██████▌   | 14518/22194 [00:01<00:00, 9469.80 examples/s]\n",
      "Map:  65%|██████▌   | 14517/22194 [00:01<00:00, 9354.97 examples/s]\n",
      "Map:  65%|██████▌   | 14510/22194 [00:01<00:00, 9215.19 examples/s]\n",
      "Map:  65%|██████▌   | 14514/22194 [00:01<00:00, 9328.96 examples/s]\n",
      "Map:  65%|██████▌   | 14506/22194 [00:01<00:00, 9288.20 examples/s]\n",
      "Map:  66%|██████▌   | 14549/22194 [00:01<00:00, 9343.04 examples/s]\n",
      "Map:  70%|██████▉   | 15520/22194 [00:01<00:00, 9413.84 examples/s]\n",
      "Map:  70%|██████▉   | 15511/22194 [00:01<00:00, 9357.06 examples/s]\n",
      "Map:  70%|██████▉   | 15524/22194 [00:01<00:00, 9491.41 examples/s]\n",
      "Map:  70%|██████▉   | 15517/22194 [00:01<00:00, 9373.47 examples/s]\n",
      "Map:  70%|██████▉   | 15508/22194 [00:01<00:00, 9246.58 examples/s]\n",
      "Map:  70%|██████▉   | 15520/22194 [00:01<00:00, 9374.98 examples/s]\n",
      "Map:  70%|██████▉   | 15508/22194 [00:01<00:00, 9325.46 examples/s]\n",
      "Map:  70%|██████▉   | 15508/22194 [00:01<00:00, 9305.63 examples/s]\n",
      "Map:  74%|███████▍  | 16521/22194 [00:01<00:00, 9438.73 examples/s]\n",
      "Map:  74%|███████▍  | 16511/22194 [00:01<00:00, 9339.30 examples/s]\n",
      "Map:  74%|███████▍  | 16522/22194 [00:01<00:00, 9497.66 examples/s]\n",
      "Map:  74%|███████▍  | 16516/22194 [00:01<00:00, 9392.52 examples/s]\n",
      "Map:  74%|███████▍  | 16504/22194 [00:01<00:00, 9261.25 examples/s]\n",
      "Map:  74%|███████▍  | 16519/22194 [00:01<00:00, 9406.76 examples/s]\n",
      "Map:  74%|███████▍  | 16511/22194 [00:01<00:00, 9335.42 examples/s]\n",
      "Map:  74%|███████▍  | 16505/22194 [00:01<00:00, 9326.87 examples/s]\n",
      "Map:  79%|███████▉  | 17518/22194 [00:01<00:00, 9435.26 examples/s]\n",
      "Map:  79%|███████▉  | 17511/22194 [00:01<00:00, 9268.96 examples/s]\n",
      "Map:  79%|███████▉  | 17520/22194 [00:01<00:00, 9494.46 examples/s]\n",
      "Map:  79%|███████▉  | 17519/22194 [00:01<00:00, 9406.99 examples/s]\n",
      "Map:  79%|███████▉  | 17507/22194 [00:01<00:00, 9274.48 examples/s]\n",
      "Map:  79%|███████▉  | 17514/22194 [00:01<00:00, 9401.65 examples/s]\n",
      "Map:  79%|███████▉  | 17518/22194 [00:01<00:00, 9353.63 examples/s]\n",
      "Map:  79%|███████▉  | 17508/22194 [00:01<00:00, 9340.11 examples/s]\n",
      "Map:  83%|████████▎ | 18514/22194 [00:01<00:00, 9403.42 examples/s]\n",
      "Map:  83%|████████▎ | 18508/22194 [00:02<00:00, 9246.32 examples/s]\n",
      "Map:  83%|████████▎ | 18521/22194 [00:01<00:00, 9500.17 examples/s]\n",
      "Map:  83%|████████▎ | 18515/22194 [00:02<00:00, 9402.57 examples/s]\n",
      "Map:  83%|████████▎ | 18503/22194 [00:02<00:00, 9262.87 examples/s]\n",
      "Map:  83%|████████▎ | 18516/22194 [00:02<00:00, 9395.45 examples/s]\n",
      "Map:  83%|████████▎ | 18505/22194 [00:02<00:00, 9334.40 examples/s]\n",
      "Map:  83%|████████▎ | 18507/22194 [00:02<00:00, 9331.38 examples/s]\n",
      "Map:  88%|████████▊ | 19521/22194 [00:02<00:00, 9432.99 examples/s]\n",
      "Map:  88%|████████▊ | 19507/22194 [00:02<00:00, 9264.58 examples/s]\n",
      "Map:  88%|████████▊ | 19526/22194 [00:02<00:00, 9517.71 examples/s]\n",
      "Map:  88%|████████▊ | 19515/22194 [00:02<00:00, 9400.93 examples/s]\n",
      "Map:  88%|████████▊ | 19506/22194 [00:02<00:00, 9274.30 examples/s]\n",
      "Map:  88%|████████▊ | 19513/22194 [00:02<00:00, 9397.27 examples/s]\n",
      "Map:  88%|████████▊ | 19504/22194 [00:02<00:00, 9317.75 examples/s]\n",
      "Map:  88%|████████▊ | 19513/22194 [00:02<00:00, 9365.68 examples/s]\n",
      "Map:  92%|█████████▏| 20528/22194 [00:02<00:00, 9413.80 examples/s]\n",
      "Map:  92%|█████████▏| 20526/22194 [00:02<00:00, 9530.28 examples/s]\n",
      "Map:  92%|█████████▏| 20512/22194 [00:02<00:00, 9252.19 examples/s]\n",
      "Map:  92%|█████████▏| 20515/22194 [00:02<00:00, 9335.52 examples/s]\n",
      "Map:  92%|█████████▏| 20506/22194 [00:02<00:00, 9224.15 examples/s]\n",
      "Map:  92%|█████████▏| 20511/22194 [00:02<00:00, 9338.78 examples/s]\n",
      "Map:  92%|█████████▏| 20506/22194 [00:02<00:00, 9260.41 examples/s]\n",
      "Map:  92%|█████████▏| 20513/22194 [00:02<00:00, 9319.20 examples/s]\n",
      "Map:  97%|█████████▋| 21529/22194 [00:02<00:00, 9456.21 examples/s]\n",
      "Map:  97%|█████████▋| 21521/22194 [00:02<00:00, 9544.09 examples/s]\n",
      "Map:  97%|█████████▋| 21504/22194 [00:02<00:00, 9250.67 examples/s]\n",
      "Map:  97%|█████████▋| 21517/22194 [00:02<00:00, 9361.75 examples/s]\n",
      "Map:  97%|█████████▋| 21513/22194 [00:02<00:00, 9248.62 examples/s]\n",
      "Map:  97%|█████████▋| 21517/22194 [00:02<00:00, 9346.50 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9290.63 examples/s]\n",
      "Map:  97%|█████████▋| 21511/22194 [00:02<00:00, 9323.07 examples/s]\n",
      "Map:  97%|█████████▋| 21512/22194 [00:02<00:00, 9270.82 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9343.52 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9141.49 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9249.18 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9110.28 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9213.55 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9196.63 examples/s]\n",
      "Map: 100%|██████████| 22194/22194 [00:02<00:00, 9142.18 examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:   0%|          | 0/2466 [00:00<?, ? examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9238.86 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9073.20 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 8935.63 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9007.71 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9050.10 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9192.85 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9071.61 examples/s]\n",
      "Map:  41%|████      | 1000/2466 [00:00<00:00, 9068.61 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9302.10 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9122.63 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9115.58 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9278.21 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9117.44 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9166.24 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9288.16 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9151.05 examples/s]\n",
      "Map:  81%|████████  | 2000/2466 [00:00<00:00, 9198.73 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9158.44 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9081.57 examples/s]\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9119.11 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9180.64 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 8979.95 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9000.55 examples/s]\n",
      "Map: 100%|██████████| 2466/2466 [00:00<00:00, 9041.82 examples/s]\n",
      "NCCL version 2.18.1+cuda12.1\n",
      "algo-1:78:211 [2] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:77:215 [1] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:80:217 [4] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:81:210 [5] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:82:212 [6] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:76:213 [0] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:79:216 [3] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "algo-1:83:214 [7] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>\n",
      "You are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\n",
      "Human: Please summarize the goals for journalist in this text:\n",
      "세종 뉴스1 김기남 기자 김동구 환경부 물통합정책관이 5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고 있다.<|end_of_text|>\n",
      "Assistant: 5일동구 환경부 물통합정책관이  5일 오전 정부세종청사에서 버려지던 유출지하수를 탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델을 설명하고  다용도 복합 활용모델을 설명하고   버려지던 유출지하수를 탄소중립 핵심 수자원으로  탄소중립 핵심 수자원으로 활용하는 다용도 복합 활용모델도 설명하고                                                                                                                                                                                                                                                                                                                                                                                                                                                 <|end_of_text|>\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.23s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.19s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.24s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.23s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.24s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.23s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.24s/it]\n",
      "Downloading shards:  25%|██▌       | 1/4 [00:20<01:00, 20.24s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.07s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.06s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  50%|█████     | 2/4 [00:35<00:34, 17.08s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.94s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.93s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.93s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.94s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.95s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.96s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.95s/it]\n",
      "Downloading shards:  75%|███████▌  | 3/4 [00:49<00:15, 15.96s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.10s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.34s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.09s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.34s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.10s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.34s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.10s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.34s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.10s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.35s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.11s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.34s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.11s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.35s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 11.11s/it]\n",
      "Downloading shards: 100%|██████████| 4/4 [00:53<00:00, 13.35s/it]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.61s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.77s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.74s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.74s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.86s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.80s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.81s/it]\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.86s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.76s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.78s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.70s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.69s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.69s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.74s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.72s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.72s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.21s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:05<00:05,  2.75s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.63s/it]#015Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.63s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:07<00:02,  2.64s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.66s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.65s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.65s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:08<00:02,  2.66s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.75s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.75s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.09s/it]\n",
      "#015Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.75s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.09s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.78s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.13s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.77s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.11s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.77s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  1.79s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:08<00:00,  2.14s/it]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 1 examples [00:00,  2.33 examples/s]\n",
      "Generating train split: 1000 examples [00:00, 2292.38 examples/s]\n",
      "Generating train split: 1973 examples [00:01, 2215.55 examples/s]\n",
      "Generating train split: 2730 examples [00:01, 3067.07 examples/s]\n",
      "Generating train split: 3623 examples [00:01, 4057.77 examples/s]\n",
      "Generating train split: 4617 examples [00:01, 2909.71 examples/s]\n",
      "Generating train split: 5623 examples [00:01, 3816.66 examples/s]\n",
      "Generating train split: 6648 examples [00:02, 2961.05 examples/s]\n",
      "Generating train split: 7624 examples [00:02, 3677.21 examples/s]\n",
      "Generating train split: 8623 examples [00:03, 2291.12 examples/s]\n",
      "Generating train split: 9623 examples [00:03, 2973.08 examples/s]\n",
      "Generating train split: 10626 examples [00:03, 2619.45 examples/s]\n",
      "Generating train split: 11618 examples [00:03, 3274.32 examples/s]\n",
      "Generating train split: 12623 examples [00:04, 2754.65 examples/s]\n",
      "Generating train split: 13606 examples [00:04, 3449.41 examples/s]\n",
      "Generating train split: 14608 examples [00:05, 2861.43 examples/s]\n",
      "Generating train split: 15609 examples [00:05, 3521.51 examples/s]\n",
      "Generating train split: 16608 examples [00:05, 2846.67 examples/s]\n",
      "Generating train split: 17604 examples [00:05, 3551.68 examples/s]\n",
      "Generating train split: 18611 examples [00:06, 2885.35 examples/s]\n",
      "Generating train split: 19615 examples [00:06, 3546.65 examples/s]\n",
      "Generating train split: 20623 examples [00:06, 2879.91 examples/s]\n",
      "Generating train split: 21614 examples [00:07, 3578.24 examples/s]\n",
      "Generating train split: 22495 examples [00:07, 2799.51 examples/s]\n",
      "Generating train split: 23593 examples [00:08, 2588.96 examples/s]\n",
      "Generating train split: 24040 examples [00:08, 2289.84 examples/s]\n",
      "Generating train split: 25000 examples [00:08, 3014.53 examples/s]\n",
      "Generating train split: 25548 examples [00:08, 2365.69 examples/s]\n",
      "Generating train split: 26428 examples [00:09, 3022.83 examples/s]\n",
      "Generating train split: 27503 examples [00:09, 2651.89 examples/s]\n",
      "Generating train split: 28047 examples [00:09, 2968.08 examples/s]\n",
      "Generating train split: 29000 examples [00:09, 3807.56 examples/s]\n",
      "Generating train split: 30000 examples [00:10, 2890.66 examples/s]\n",
      "Generating train split: 31000 examples [00:10, 3690.52 examples/s]\n",
      "Generating train split: 31816 examples [00:10, 2889.72 examples/s]\n",
      "Generating train split: 32624 examples [00:10, 3518.64 examples/s]\n",
      "Generating train split: 33401 examples [00:11, 2738.44 examples/s]\n",
      "Generating train split: 34453 examples [00:11, 3523.76 examples/s]\n",
      "Generating train split: 35233 examples [00:11, 4035.34 examples/s]\n",
      "Generating train split: 35233 examples [00:11, 3027.72 examples/s]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 1 examples [00:00,  2.82 examples/s]\n",
      "Generating train split: 1000 examples [00:00, 2589.90 examples/s]\n",
      "Generating train split: 1974 examples [00:00, 2341.86 examples/s]\n",
      "Generating train split: 2636 examples [00:01, 3020.76 examples/s]\n",
      "Generating train split: 3620 examples [00:01, 4202.16 examples/s]\n",
      "Generating train split: 3963 examples [00:01, 3173.28 examples/s]\n",
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n",
      "0%|          | 0/414 [00:00<?, ?it/s]\n",
      "0%|          | 1/414 [00:28<3:17:53, 28.75s/it]\n",
      "0%|          | 2/414 [00:52<2:57:09, 25.80s/it]\n",
      "1%|          | 3/414 [01:16<2:49:58, 24.81s/it]\n",
      "1%|          | 4/414 [01:39<2:46:23, 24.35s/it]\n",
      "1%|          | 5/414 [02:03<2:44:22, 24.11s/it]\n",
      "1%|▏         | 6/414 [02:27<2:42:58, 23.97s/it]\n",
      "2%|▏         | 7/414 [02:50<2:41:51, 23.86s/it]\n",
      "2%|▏         | 8/414 [03:14<2:41:27, 23.86s/it]\n",
      "2%|▏         | 9/414 [03:38<2:40:44, 23.81s/it]\n",
      "2%|▏         | 10/414 [04:02<2:40:06, 23.78s/it]\n",
      "{'loss': 2.2591, 'grad_norm': 0.2578125, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "2%|▏         | 10/414 [04:02<2:40:06, 23.78s/it]\n",
      "3%|▎         | 11/414 [04:25<2:39:31, 23.75s/it]\n",
      "3%|▎         | 12/414 [04:49<2:38:50, 23.71s/it]\n",
      "3%|▎         | 13/414 [05:12<2:38:17, 23.68s/it]\n",
      "3%|▎         | 14/414 [05:36<2:37:44, 23.66s/it]\n",
      "4%|▎         | 15/414 [06:00<2:37:18, 23.66s/it]\n",
      "4%|▍         | 16/414 [06:23<2:36:57, 23.66s/it]\n",
      "4%|▍         | 17/414 [06:47<2:36:38, 23.67s/it]\n",
      "4%|▍         | 18/414 [07:11<2:36:15, 23.68s/it]\n",
      "5%|▍         | 19/414 [07:34<2:35:47, 23.67s/it]\n",
      "5%|▍         | 20/414 [07:58<2:35:51, 23.74s/it]\n",
      "{'loss': 2.0201, 'grad_norm': 0.087890625, 'learning_rate': 0.0002, 'epoch': 0.14}\n",
      "5%|▍         | 20/414 [07:58<2:35:51, 23.74s/it]\n",
      "5%|▌         | 21/414 [08:22<2:35:11, 23.69s/it]\n",
      "5%|▌         | 22/414 [08:46<2:34:43, 23.68s/it]\n",
      "6%|▌         | 23/414 [09:09<2:34:16, 23.67s/it]\n",
      "6%|▌         | 24/414 [09:33<2:33:49, 23.67s/it]\n",
      "6%|▌         | 25/414 [09:57<2:33:31, 23.68s/it]\n",
      "6%|▋         | 26/414 [10:20<2:33:06, 23.68s/it]\n",
      "7%|▋         | 27/414 [10:44<2:32:38, 23.67s/it]\n",
      "7%|▋         | 28/414 [11:08<2:32:12, 23.66s/it]\n",
      "7%|▋         | 29/414 [11:31<2:31:41, 23.64s/it]\n",
      "7%|▋         | 30/414 [11:55<2:31:13, 23.63s/it]\n",
      "{'loss': 1.9719, 'grad_norm': 0.1015625, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "7%|▋         | 30/414 [11:55<2:31:13, 23.63s/it]\n",
      "7%|▋         | 31/414 [12:18<2:30:46, 23.62s/it]\n",
      "8%|▊         | 32/414 [12:42<2:30:31, 23.64s/it]\n",
      "8%|▊         | 33/414 [13:06<2:30:42, 23.73s/it]\n",
      "8%|▊         | 34/414 [13:30<2:30:08, 23.71s/it]\n",
      "8%|▊         | 35/414 [13:53<2:29:39, 23.69s/it]\n",
      "9%|▊         | 36/414 [14:17<2:29:05, 23.67s/it]\n",
      "9%|▉         | 37/414 [14:41<2:28:42, 23.67s/it]\n",
      "9%|▉         | 38/414 [15:04<2:28:13, 23.65s/it]\n",
      "9%|▉         | 39/414 [15:28<2:27:49, 23.65s/it]\n",
      "10%|▉         | 40/414 [15:51<2:27:20, 23.64s/it]\n",
      "{'loss': 1.9328, 'grad_norm': 0.1494140625, 'learning_rate': 0.0002, 'epoch': 0.29}\n",
      "10%|▉         | 40/414 [15:51<2:27:20, 23.64s/it]\n",
      "10%|▉         | 41/414 [16:15<2:26:55, 23.64s/it]\n",
      "10%|█         | 42/414 [16:39<2:26:36, 23.65s/it]\n",
      "10%|█         | 43/414 [17:02<2:26:11, 23.64s/it]\n",
      "11%|█         | 44/414 [17:26<2:25:46, 23.64s/it]\n",
      "11%|█         | 45/414 [17:50<2:25:48, 23.71s/it]\n",
      "11%|█         | 46/414 [18:13<2:25:13, 23.68s/it]\n",
      "11%|█▏        | 47/414 [18:37<2:24:41, 23.66s/it]\n",
      "12%|█▏        | 48/414 [19:01<2:24:08, 23.63s/it]\n",
      "12%|█▏        | 49/414 [19:24<2:23:44, 23.63s/it]\n",
      "12%|█▏        | 50/414 [19:48<2:23:28, 23.65s/it]\n",
      "{'loss': 1.9061, 'grad_norm': 0.10595703125, 'learning_rate': 0.0002, 'epoch': 0.36}\n",
      "12%|█▏        | 50/414 [19:48<2:23:28, 23.65s/it]\n",
      "12%|█▏        | 51/414 [20:12<2:23:04, 23.65s/it]\n",
      "13%|█▎        | 52/414 [20:35<2:22:45, 23.66s/it]\n",
      "13%|█▎        | 53/414 [20:59<2:22:24, 23.67s/it]\n",
      "13%|█▎        | 54/414 [21:23<2:21:58, 23.66s/it]\n",
      "13%|█▎        | 55/414 [21:46<2:21:33, 23.66s/it]\n",
      "14%|█▎        | 56/414 [22:10<2:21:15, 23.68s/it]\n",
      "14%|█▍        | 57/414 [22:34<2:20:55, 23.69s/it]\n",
      "14%|█▍        | 58/414 [22:58<2:21:02, 23.77s/it]\n",
      "14%|█▍        | 59/414 [23:21<2:20:26, 23.74s/it]\n",
      "14%|█▍        | 60/414 [23:45<2:19:52, 23.71s/it]\n",
      "{'loss': 1.8835, 'grad_norm': 0.12890625, 'learning_rate': 0.0002, 'epoch': 0.43}\n",
      "14%|█▍        | 60/414 [23:45<2:19:52, 23.71s/it]\n",
      "15%|█▍        | 61/414 [24:09<2:19:31, 23.72s/it]\n",
      "15%|█▍        | 62/414 [24:32<2:18:57, 23.69s/it]\n",
      "15%|█▌        | 63/414 [24:56<2:18:29, 23.67s/it]\n",
      "15%|█▌        | 64/414 [25:20<2:18:04, 23.67s/it]\n",
      "16%|█▌        | 65/414 [25:43<2:17:35, 23.66s/it]\n",
      "16%|█▌        | 66/414 [26:07<2:17:11, 23.65s/it]\n",
      "16%|█▌        | 67/414 [26:31<2:16:50, 23.66s/it]\n",
      "16%|█▋        | 68/414 [26:54<2:16:22, 23.65s/it]\n",
      "17%|█▋        | 69/414 [27:18<2:15:58, 23.65s/it]\n",
      "17%|█▋        | 70/414 [27:42<2:15:40, 23.67s/it]\n",
      "{'loss': 1.8539, 'grad_norm': 0.1416015625, 'learning_rate': 0.0002, 'epoch': 0.51}\n",
      "17%|█▋        | 70/414 [27:42<2:15:40, 23.67s/it]\n",
      "17%|█▋        | 71/414 [28:06<2:15:49, 23.76s/it]\n",
      "17%|█▋        | 72/414 [28:29<2:15:14, 23.73s/it]\n",
      "18%|█▊        | 73/414 [28:53<2:14:42, 23.70s/it]\n",
      "18%|█▊        | 74/414 [29:16<2:14:08, 23.67s/it]\n",
      "18%|█▊        | 75/414 [29:40<2:13:40, 23.66s/it]\n",
      "18%|█▊        | 76/414 [30:04<2:13:10, 23.64s/it]\n",
      "19%|█▊        | 77/414 [30:27<2:12:50, 23.65s/it]\n",
      "19%|█▉        | 78/414 [30:51<2:12:25, 23.65s/it]\n",
      "19%|█▉        | 79/414 [31:15<2:11:58, 23.64s/it]\n",
      "19%|█▉        | 80/414 [31:38<2:11:35, 23.64s/it]\n",
      "{'loss': 1.8507, 'grad_norm': 0.130859375, 'learning_rate': 0.0002, 'epoch': 0.58}\n",
      "19%|█▉        | 80/414 [31:38<2:11:35, 23.64s/it]\n",
      "20%|█▉        | 81/414 [32:02<2:11:13, 23.64s/it]\n",
      "20%|█▉        | 82/414 [32:26<2:10:50, 23.65s/it]\n",
      "20%|██        | 83/414 [32:49<2:10:22, 23.63s/it]\n",
      "20%|██        | 84/414 [33:13<2:10:22, 23.71s/it]\n",
      "21%|██        | 85/414 [33:37<2:09:44, 23.66s/it]\n",
      "21%|██        | 86/414 [34:00<2:09:16, 23.65s/it]\n",
      "21%|██        | 87/414 [34:24<2:08:59, 23.67s/it]\n",
      "21%|██▏       | 88/414 [34:48<2:08:37, 23.67s/it]\n",
      "21%|██▏       | 89/414 [35:11<2:08:16, 23.68s/it]\n",
      "22%|██▏       | 90/414 [35:35<2:07:51, 23.68s/it]\n",
      "{'loss': 1.8288, 'grad_norm': 0.140625, 'learning_rate': 0.0002, 'epoch': 0.65}\n",
      "22%|██▏       | 90/414 [35:35<2:07:51, 23.68s/it]\n",
      "22%|██▏       | 91/414 [35:59<2:07:28, 23.68s/it]\n",
      "22%|██▏       | 92/414 [36:22<2:07:00, 23.67s/it]\n",
      "22%|██▏       | 93/414 [36:46<2:06:40, 23.68s/it]\n",
      "23%|██▎       | 94/414 [37:10<2:06:19, 23.69s/it]\n",
      "23%|██▎       | 95/414 [37:33<2:05:53, 23.68s/it]\n",
      "23%|██▎       | 96/414 [37:57<2:05:25, 23.67s/it]\n",
      "23%|██▎       | 97/414 [38:21<2:05:18, 23.72s/it]\n",
      "24%|██▎       | 98/414 [38:45<2:04:57, 23.73s/it]\n",
      "24%|██▍       | 99/414 [39:08<2:04:35, 23.73s/it]\n",
      "24%|██▍       | 100/414 [39:32<2:04:06, 23.71s/it]\n",
      "{'loss': 1.8114, 'grad_norm': 0.146484375, 'learning_rate': 0.0002, 'epoch': 0.72}\n",
      "24%|██▍       | 100/414 [39:32<2:04:06, 23.71s/it]\n",
      "24%|██▍       | 101/414 [39:56<2:03:35, 23.69s/it]\n",
      "25%|██▍       | 102/414 [40:19<2:03:10, 23.69s/it]\n",
      "25%|██▍       | 103/414 [40:43<2:02:46, 23.69s/it]\n",
      "25%|██▌       | 104/414 [41:07<2:02:19, 23.67s/it]\n",
      "25%|██▌       | 105/414 [41:30<2:01:54, 23.67s/it]\n",
      "26%|██▌       | 106/414 [41:54<2:01:27, 23.66s/it]\n",
      "26%|██▌       | 107/414 [42:18<2:01:05, 23.67s/it]\n",
      "26%|██▌       | 108/414 [42:41<2:00:41, 23.66s/it]\n",
      "26%|██▋       | 109/414 [43:05<2:00:17, 23.67s/it]\n",
      "27%|██▋       | 110/414 [43:29<2:00:13, 23.73s/it]\n",
      "{'loss': 1.8089, 'grad_norm': 0.158203125, 'learning_rate': 0.0002, 'epoch': 0.8}\n",
      "27%|██▋       | 110/414 [43:29<2:00:13, 23.73s/it]\n",
      "27%|██▋       | 111/414 [43:52<1:59:43, 23.71s/it]\n",
      "27%|██▋       | 112/414 [44:16<1:59:13, 23.69s/it]\n",
      "27%|██▋       | 113/414 [44:40<1:58:45, 23.67s/it]\n",
      "28%|██▊       | 114/414 [45:03<1:58:24, 23.68s/it]\n",
      "28%|██▊       | 115/414 [45:27<1:57:56, 23.67s/it]\n",
      "28%|██▊       | 116/414 [45:51<1:57:29, 23.66s/it]\n",
      "28%|██▊       | 117/414 [46:14<1:57:02, 23.65s/it]\n",
      "29%|██▊       | 118/414 [46:38<1:56:37, 23.64s/it]\n",
      "29%|██▊       | 119/414 [47:02<1:56:18, 23.66s/it]\n",
      "29%|██▉       | 120/414 [47:25<1:55:56, 23.66s/it]\n",
      "{'loss': 1.7988, 'grad_norm': 0.1533203125, 'learning_rate': 0.0002, 'epoch': 0.87}\n",
      "29%|██▉       | 120/414 [47:25<1:55:56, 23.66s/it]\n",
      "29%|██▉       | 121/414 [47:49<1:55:28, 23.65s/it]\n",
      "29%|██▉       | 122/414 [48:13<1:55:05, 23.65s/it]\n",
      "30%|██▉       | 123/414 [48:37<1:55:06, 23.73s/it]\n",
      "30%|██▉       | 124/414 [49:00<1:54:36, 23.71s/it]\n",
      "30%|███       | 125/414 [49:24<1:54:07, 23.69s/it]\n",
      "30%|███       | 126/414 [49:48<1:53:40, 23.68s/it]\n",
      "31%|███       | 127/414 [50:11<1:53:11, 23.66s/it]\n",
      "31%|███       | 128/414 [50:35<1:52:51, 23.68s/it]\n",
      "31%|███       | 129/414 [50:58<1:52:25, 23.67s/it]\n",
      "31%|███▏      | 130/414 [51:22<1:52:00, 23.66s/it]\n",
      "{'loss': 1.7815, 'grad_norm': 0.169921875, 'learning_rate': 0.0002, 'epoch': 0.94}\n",
      "31%|███▏      | 130/414 [51:22<1:52:00, 23.66s/it]\n",
      "32%|███▏      | 131/414 [51:46<1:51:41, 23.68s/it]\n",
      "32%|███▏      | 132/414 [52:09<1:51:11, 23.66s/it]\n",
      "32%|███▏      | 133/414 [52:33<1:50:44, 23.64s/it]\n",
      "32%|███▏      | 134/414 [52:57<1:50:27, 23.67s/it]\n",
      "33%|███▎      | 135/414 [53:20<1:50:03, 23.67s/it]\n",
      "33%|███▎      | 136/414 [53:44<1:49:58, 23.74s/it]\n",
      "33%|███▎      | 137/414 [54:08<1:49:24, 23.70s/it]\n",
      "33%|███▎      | 138/414 [54:32<1:48:58, 23.69s/it]\n",
      "0%|          | 0/62 [00:00<?, ?it/s]#033[A\n",
      "3%|▎         | 2/62 [00:02<01:14,  1.24s/it]#033[A\n",
      "5%|▍         | 3/62 [00:04<01:43,  1.75s/it]#033[A\n",
      "6%|▋         | 4/62 [00:07<01:57,  2.02s/it]#033[A\n",
      "8%|▊         | 5/62 [00:09<02:04,  2.18s/it]#033[A\n",
      "10%|▉         | 6/62 [00:12<02:07,  2.28s/it]#033[A\n",
      "11%|█▏        | 7/62 [00:14<02:08,  2.34s/it]#033[A\n",
      "13%|█▎        | 8/62 [00:17<02:08,  2.39s/it]#033[A\n",
      "15%|█▍        | 9/62 [00:19<02:07,  2.41s/it]#033[A\n",
      "16%|█▌        | 10/62 [00:22<02:06,  2.43s/it]#033[A\n",
      "18%|█▊        | 11/62 [00:24<02:04,  2.44s/it]#033[A\n",
      "19%|█▉        | 12/62 [00:27<02:02,  2.45s/it]#033[A\n",
      "21%|██        | 13/62 [00:29<02:00,  2.46s/it]#033[A\n",
      "23%|██▎       | 14/62 [00:32<01:58,  2.46s/it]#033[A\n",
      "24%|██▍       | 15/62 [00:34<01:55,  2.47s/it]#033[A\n",
      "26%|██▌       | 16/62 [00:37<01:53,  2.47s/it]#033[A\n",
      "27%|██▋       | 17/62 [00:39<01:51,  2.47s/it]#033[A\n",
      "29%|██▉       | 18/62 [00:42<01:48,  2.47s/it]#033[A\n",
      "31%|███       | 19/62 [00:44<01:46,  2.47s/it]#033[A\n",
      "32%|███▏      | 20/62 [00:47<01:43,  2.47s/it]#033[A\n",
      "34%|███▍      | 21/62 [00:49<01:41,  2.47s/it]#033[A\n",
      "35%|███▌      | 22/62 [00:51<01:38,  2.47s/it]#033[A\n",
      "37%|███▋      | 23/62 [00:54<01:36,  2.47s/it]#033[A\n",
      "39%|███▊      | 24/62 [00:56<01:33,  2.47s/it]#033[A\n",
      "40%|████      | 25/62 [00:59<01:31,  2.47s/it]#033[A\n",
      "42%|████▏     | 26/62 [01:01<01:29,  2.48s/it]#033[A\n",
      "44%|████▎     | 27/62 [01:04<01:26,  2.47s/it]#033[A\n",
      "45%|████▌     | 28/62 [01:06<01:24,  2.48s/it]#033[A\n",
      "47%|████▋     | 29/62 [01:09<01:21,  2.47s/it]#033[A\n",
      "48%|████▊     | 30/62 [01:11<01:19,  2.48s/it]#033[A\n",
      "50%|█████     | 31/62 [01:14<01:16,  2.47s/it]#033[A\n",
      "52%|█████▏    | 32/62 [01:16<01:14,  2.48s/it]#033[A\n",
      "53%|█████▎    | 33/62 [01:19<01:11,  2.47s/it]#033[A\n",
      "55%|█████▍    | 34/62 [01:21<01:09,  2.48s/it]#033[A\n",
      "56%|█████▋    | 35/62 [01:24<01:06,  2.48s/it]#033[A\n",
      "58%|█████▊    | 36/62 [01:26<01:04,  2.48s/it]#033[A\n",
      "60%|█████▉    | 37/62 [01:29<01:01,  2.47s/it]#033[A\n",
      "61%|██████▏   | 38/62 [01:31<00:59,  2.47s/it]#033[A\n",
      "63%|██████▎   | 39/62 [01:34<00:56,  2.47s/it]#033[A\n",
      "65%|██████▍   | 40/62 [01:36<00:54,  2.47s/it]#033[A\n",
      "66%|██████▌   | 41/62 [01:38<00:51,  2.47s/it]#033[A\n",
      "68%|██████▊   | 42/62 [01:41<00:49,  2.48s/it]#033[A\n",
      "69%|██████▉   | 43/62 [01:43<00:47,  2.48s/it]#033[A\n",
      "71%|███████   | 44/62 [01:46<00:44,  2.48s/it]#033[A\n",
      "73%|███████▎  | 45/62 [01:48<00:42,  2.48s/it]#033[A\n",
      "74%|███████▍  | 46/62 [01:51<00:39,  2.48s/it]#033[A\n",
      "76%|███████▌  | 47/62 [01:53<00:37,  2.48s/it]#033[A\n",
      "77%|███████▋  | 48/62 [01:56<00:34,  2.47s/it]#033[A\n",
      "79%|███████▉  | 49/62 [01:58<00:32,  2.47s/it]#033[A\n",
      "81%|████████  | 50/62 [02:01<00:29,  2.47s/it]#033[A\n",
      "82%|████████▏ | 51/62 [02:03<00:27,  2.47s/it]#033[A\n",
      "84%|████████▍ | 52/62 [02:06<00:24,  2.48s/it]#033[A\n",
      "85%|████████▌ | 53/62 [02:08<00:22,  2.48s/it]#033[A\n",
      "87%|████████▋ | 54/62 [02:11<00:19,  2.48s/it]#033[A\n",
      "89%|████████▊ | 55/62 [02:13<00:17,  2.48s/it]#033[A\n",
      "90%|█████████ | 56/62 [02:16<00:14,  2.48s/it]#033[A\n",
      "92%|█████████▏| 57/62 [02:18<00:12,  2.47s/it]#033[A\n",
      "94%|█████████▎| 58/62 [02:21<00:09,  2.47s/it]#033[A\n",
      "95%|█████████▌| 59/62 [02:23<00:07,  2.47s/it]#033[A\n",
      "97%|█████████▋| 60/62 [02:26<00:04,  2.48s/it]#033[A\n",
      "98%|█████████▊| 61/62 [02:28<00:02,  2.48s/it]#033[A\n",
      "100%|██████████| 62/62 [02:30<00:00,  2.47s/it]#033[A\n",
      "#033[A\n",
      "{'eval_loss': 1.787308692932129, 'eval_runtime': 154.2099, 'eval_samples_per_second': 25.699, 'eval_steps_per_second': 0.402, 'epoch': 1.0}\n",
      "33%|███▎      | 138/414 [57:06<1:48:58, 23.69s/it]\n",
      "100%|██████████| 62/62 [02:31<00:00,  2.47s/it]#033[A\n",
      "#033[A\n",
      "34%|███▎      | 139/414 [57:46<5:43:09, 74.87s/it]\n",
      "34%|███▍      | 140/414 [58:10<4:31:45, 59.51s/it]\n",
      "{'loss': 1.7881, 'grad_norm': 0.18359375, 'learning_rate': 0.0002, 'epoch': 1.01}\n",
      "34%|███▍      | 140/414 [58:10<4:31:45, 59.51s/it]\n",
      "34%|███▍      | 141/414 [58:33<3:41:49, 48.75s/it]\n",
      "34%|███▍      | 142/414 [58:57<3:06:58, 41.24s/it]\n",
      "35%|███▍      | 143/414 [59:21<2:42:26, 35.96s/it]\n",
      "35%|███▍      | 144/414 [59:44<2:25:18, 32.29s/it]\n",
      "35%|███▌      | 145/414 [1:00:08<2:13:12, 29.71s/it]\n",
      "35%|███▌      | 146/414 [1:00:32<2:04:41, 27.92s/it]\n",
      "36%|███▌      | 147/414 [1:00:56<1:58:44, 26.68s/it]\n",
      "36%|███▌      | 148/414 [1:01:19<1:54:29, 25.83s/it]\n",
      "36%|███▌      | 149/414 [1:01:43<1:51:09, 25.17s/it]\n",
      "36%|███▌      | 150/414 [1:02:07<1:48:46, 24.72s/it]\n",
      "{'loss': 1.7497, 'grad_norm': 0.1923828125, 'learning_rate': 0.0002, 'epoch': 1.09}\n",
      "36%|███▌      | 150/414 [1:02:07<1:48:46, 24.72s/it]\n",
      "36%|███▋      | 151/414 [1:02:30<1:47:00, 24.41s/it]\n",
      "37%|███▋      | 152/414 [1:02:54<1:45:33, 24.18s/it]\n",
      "37%|███▋      | 153/414 [1:03:18<1:44:30, 24.03s/it]\n",
      "37%|███▋      | 154/414 [1:03:41<1:43:41, 23.93s/it]\n",
      "37%|███▋      | 155/414 [1:04:05<1:42:59, 23.86s/it]\n",
      "38%|███▊      | 156/414 [1:04:29<1:42:18, 23.79s/it]\n",
      "38%|███▊      | 157/414 [1:04:53<1:41:53, 23.79s/it]\n",
      "38%|███▊      | 158/414 [1:05:16<1:41:20, 23.75s/it]\n",
      "38%|███▊      | 159/414 [1:05:40<1:41:01, 23.77s/it]\n",
      "39%|███▊      | 160/414 [1:06:04<1:40:49, 23.82s/it]\n",
      "{'loss': 1.7301, 'grad_norm': 0.1806640625, 'learning_rate': 0.0002, 'epoch': 1.16}\n",
      "39%|███▊      | 160/414 [1:06:04<1:40:49, 23.82s/it]\n",
      "39%|███▉      | 161/414 [1:06:28<1:40:06, 23.74s/it]\n",
      "39%|███▉      | 162/414 [1:06:51<1:39:38, 23.72s/it]\n",
      "39%|███▉      | 163/414 [1:07:15<1:39:14, 23.72s/it]\n",
      "40%|███▉      | 164/414 [1:07:39<1:38:48, 23.71s/it]\n",
      "40%|███▉      | 165/414 [1:08:02<1:38:20, 23.70s/it]\n",
      "40%|████      | 166/414 [1:08:26<1:37:50, 23.67s/it]\n",
      "40%|████      | 167/414 [1:08:49<1:37:21, 23.65s/it]\n",
      "41%|████      | 168/414 [1:09:13<1:37:04, 23.68s/it]\n",
      "41%|████      | 169/414 [1:09:37<1:36:39, 23.67s/it]\n",
      "41%|████      | 170/414 [1:10:01<1:36:17, 23.68s/it]\n",
      "{'loss': 1.7404, 'grad_norm': 0.189453125, 'learning_rate': 0.0002, 'epoch': 1.23}\n",
      "41%|████      | 170/414 [1:10:01<1:36:17, 23.68s/it]\n",
      "41%|████▏     | 171/414 [1:10:24<1:35:52, 23.67s/it]\n",
      "42%|████▏     | 172/414 [1:10:48<1:35:44, 23.74s/it]\n",
      "42%|████▏     | 173/414 [1:11:12<1:35:34, 23.80s/it]\n",
      "42%|████▏     | 174/414 [1:11:36<1:34:58, 23.74s/it]\n",
      "42%|████▏     | 175/414 [1:11:59<1:34:26, 23.71s/it]\n",
      "43%|████▎     | 176/414 [1:12:23<1:34:01, 23.71s/it]\n",
      "43%|████▎     | 177/414 [1:12:47<1:33:35, 23.69s/it]\n",
      "43%|████▎     | 178/414 [1:13:10<1:33:09, 23.68s/it]\n",
      "43%|████▎     | 179/414 [1:13:34<1:32:42, 23.67s/it]\n",
      "43%|████▎     | 180/414 [1:13:58<1:32:21, 23.68s/it]\n",
      "{'loss': 1.7205, 'grad_norm': 0.1806640625, 'learning_rate': 0.0002, 'epoch': 1.3}\n",
      "43%|████▎     | 180/414 [1:13:58<1:32:21, 23.68s/it]\n",
      "44%|████▎     | 181/414 [1:14:21<1:31:57, 23.68s/it]\n",
      "44%|████▍     | 182/414 [1:14:45<1:31:32, 23.67s/it]\n",
      "44%|████▍     | 183/414 [1:15:09<1:31:11, 23.69s/it]\n",
      "44%|████▍     | 184/414 [1:15:32<1:30:48, 23.69s/it]\n",
      "45%|████▍     | 185/414 [1:15:56<1:30:47, 23.79s/it]\n",
      "45%|████▍     | 186/414 [1:16:20<1:30:20, 23.77s/it]\n",
      "45%|████▌     | 187/414 [1:16:44<1:29:49, 23.74s/it]\n",
      "45%|████▌     | 188/414 [1:17:07<1:29:18, 23.71s/it]\n",
      "46%|████▌     | 189/414 [1:17:31<1:28:54, 23.71s/it]\n",
      "46%|████▌     | 190/414 [1:17:55<1:28:27, 23.69s/it]\n",
      "{'loss': 1.7255, 'grad_norm': 0.1728515625, 'learning_rate': 0.0002, 'epoch': 1.38}\n",
      "46%|████▌     | 190/414 [1:17:55<1:28:27, 23.69s/it]\n",
      "46%|████▌     | 191/414 [1:18:18<1:28:00, 23.68s/it]\n",
      "46%|████▋     | 192/414 [1:18:42<1:27:37, 23.68s/it]\n",
      "47%|████▋     | 193/414 [1:19:06<1:27:11, 23.67s/it]\n",
      "47%|████▋     | 194/414 [1:19:30<1:26:48, 23.68s/it]\n",
      "47%|████▋     | 195/414 [1:19:53<1:26:27, 23.69s/it]\n",
      "47%|████▋     | 196/414 [1:20:17<1:26:06, 23.70s/it]\n",
      "48%|████▊     | 197/414 [1:20:41<1:25:40, 23.69s/it]\n",
      "48%|████▊     | 198/414 [1:21:05<1:25:44, 23.82s/it]\n",
      "48%|████▊     | 199/414 [1:21:28<1:25:09, 23.77s/it]\n",
      "48%|████▊     | 200/414 [1:21:52<1:24:45, 23.76s/it]\n",
      "{'loss': 1.7227, 'grad_norm': 0.1796875, 'learning_rate': 0.0002, 'epoch': 1.45}\n",
      "48%|████▊     | 200/414 [1:21:52<1:24:45, 23.76s/it]\n",
      "49%|████▊     | 201/414 [1:22:16<1:24:19, 23.75s/it]\n",
      "49%|████▉     | 202/414 [1:22:40<1:23:51, 23.73s/it]\n",
      "49%|████▉     | 203/414 [1:23:03<1:23:26, 23.73s/it]\n",
      "49%|████▉     | 204/414 [1:23:27<1:22:55, 23.69s/it]\n",
      "50%|████▉     | 205/414 [1:23:51<1:22:28, 23.67s/it]\n",
      "50%|████▉     | 206/414 [1:24:14<1:22:04, 23.67s/it]\n",
      "50%|█████     | 207/414 [1:24:38<1:21:39, 23.67s/it]\n",
      "50%|█████     | 208/414 [1:25:01<1:21:12, 23.65s/it]\n",
      "50%|█████     | 209/414 [1:25:25<1:20:50, 23.66s/it]\n",
      "51%|█████     | 210/414 [1:25:49<1:20:37, 23.71s/it]\n",
      "{'loss': 1.6895, 'grad_norm': 0.1826171875, 'learning_rate': 0.0002, 'epoch': 1.52}\n",
      "51%|█████     | 210/414 [1:25:49<1:20:37, 23.71s/it]\n",
      "51%|█████     | 211/414 [1:26:13<1:20:29, 23.79s/it]\n",
      "51%|█████     | 212/414 [1:26:37<1:19:59, 23.76s/it]\n",
      "51%|█████▏    | 213/414 [1:27:00<1:19:32, 23.74s/it]\n",
      "52%|█████▏    | 214/414 [1:27:24<1:19:08, 23.74s/it]\n",
      "52%|█████▏    | 215/414 [1:27:48<1:18:39, 23.72s/it]\n",
      "52%|█████▏    | 216/414 [1:28:11<1:18:14, 23.71s/it]\n",
      "52%|█████▏    | 217/414 [1:28:35<1:17:48, 23.70s/it]\n",
      "53%|█████▎    | 218/414 [1:28:59<1:17:21, 23.68s/it]\n",
      "53%|█████▎    | 219/414 [1:29:22<1:16:58, 23.68s/it]\n",
      "53%|█████▎    | 220/414 [1:29:46<1:16:35, 23.69s/it]\n",
      "{'loss': 1.6858, 'grad_norm': 0.173828125, 'learning_rate': 0.0002, 'epoch': 1.59}\n",
      "53%|█████▎    | 220/414 [1:29:46<1:16:35, 23.69s/it]\n",
      "53%|█████▎    | 221/414 [1:30:10<1:16:14, 23.70s/it]\n",
      "54%|█████▎    | 222/414 [1:30:34<1:15:49, 23.70s/it]\n",
      "54%|█████▍    | 223/414 [1:30:57<1:15:37, 23.76s/it]\n",
      "54%|█████▍    | 224/414 [1:31:22<1:15:32, 23.85s/it]\n",
      "54%|█████▍    | 225/414 [1:31:45<1:15:00, 23.81s/it]\n",
      "55%|█████▍    | 226/414 [1:32:09<1:14:30, 23.78s/it]\n",
      "55%|█████▍    | 227/414 [1:32:33<1:14:06, 23.78s/it]\n",
      "55%|█████▌    | 228/414 [1:32:56<1:13:36, 23.74s/it]\n",
      "55%|█████▌    | 229/414 [1:33:20<1:13:12, 23.74s/it]\n",
      "56%|█████▌    | 230/414 [1:33:44<1:12:49, 23.75s/it]\n",
      "{'loss': 1.6832, 'grad_norm': 0.224609375, 'learning_rate': 0.0002, 'epoch': 1.67}\n",
      "56%|█████▌    | 230/414 [1:33:44<1:12:49, 23.75s/it]\n",
      "56%|█████▌    | 231/414 [1:34:08<1:12:19, 23.72s/it]\n",
      "56%|█████▌    | 232/414 [1:34:31<1:11:54, 23.71s/it]\n",
      "56%|█████▋    | 233/414 [1:34:55<1:11:36, 23.74s/it]\n",
      "57%|█████▋    | 234/414 [1:35:19<1:11:12, 23.74s/it]\n",
      "57%|█████▋    | 235/414 [1:35:42<1:10:41, 23.70s/it]\n",
      "57%|█████▋    | 236/414 [1:36:06<1:10:22, 23.72s/it]\n",
      "57%|█████▋    | 237/414 [1:36:30<1:10:12, 23.80s/it]\n",
      "57%|█████▋    | 238/414 [1:36:54<1:09:41, 23.76s/it]\n",
      "58%|█████▊    | 239/414 [1:37:17<1:09:11, 23.73s/it]\n",
      "58%|█████▊    | 240/414 [1:37:41<1:08:46, 23.71s/it]\n",
      "{'loss': 1.6863, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 1.74}\n",
      "58%|█████▊    | 240/414 [1:37:41<1:08:46, 23.71s/it]\n",
      "58%|█████▊    | 241/414 [1:38:05<1:08:20, 23.70s/it]\n",
      "58%|█████▊    | 242/414 [1:38:29<1:07:59, 23.72s/it]\n",
      "59%|█████▊    | 243/414 [1:38:52<1:07:35, 23.72s/it]\n",
      "59%|█████▉    | 244/414 [1:39:16<1:07:12, 23.72s/it]\n",
      "59%|█████▉    | 245/414 [1:39:40<1:06:49, 23.72s/it]\n",
      "59%|█████▉    | 246/414 [1:40:03<1:06:20, 23.69s/it]\n",
      "60%|█████▉    | 247/414 [1:40:27<1:05:58, 23.70s/it]\n",
      "60%|█████▉    | 248/414 [1:40:51<1:05:34, 23.70s/it]\n",
      "60%|██████    | 249/414 [1:41:15<1:05:19, 23.76s/it]\n",
      "60%|██████    | 250/414 [1:41:39<1:05:02, 23.80s/it]\n",
      "{'loss': 1.6791, 'grad_norm': 0.216796875, 'learning_rate': 0.0002, 'epoch': 1.81}\n",
      "60%|██████    | 250/414 [1:41:39<1:05:02, 23.80s/it]\n",
      "61%|██████    | 251/414 [1:42:02<1:04:38, 23.79s/it]\n",
      "61%|██████    | 252/414 [1:42:26<1:04:13, 23.79s/it]\n",
      "61%|██████    | 253/414 [1:42:50<1:03:46, 23.77s/it]\n",
      "61%|██████▏   | 254/414 [1:43:14<1:03:19, 23.75s/it]\n",
      "62%|██████▏   | 255/414 [1:43:37<1:02:54, 23.74s/it]\n",
      "62%|██████▏   | 256/414 [1:44:01<1:02:27, 23.72s/it]\n",
      "62%|██████▏   | 257/414 [1:44:25<1:02:01, 23.70s/it]\n",
      "62%|██████▏   | 258/414 [1:44:48<1:01:37, 23.70s/it]\n",
      "63%|██████▎   | 259/414 [1:45:12<1:01:11, 23.69s/it]\n",
      "63%|██████▎   | 260/414 [1:45:36<1:00:46, 23.68s/it]\n",
      "{'loss': 1.6831, 'grad_norm': 0.2333984375, 'learning_rate': 0.0002, 'epoch': 1.88}\n",
      "63%|██████▎   | 260/414 [1:45:36<1:00:46, 23.68s/it]\n",
      "63%|██████▎   | 261/414 [1:45:59<1:00:21, 23.67s/it]\n",
      "63%|██████▎   | 262/414 [1:46:23<1:00:04, 23.72s/it]\n",
      "64%|██████▎   | 263/414 [1:46:47<59:47, 23.76s/it]\n",
      "64%|██████▍   | 264/414 [1:47:11<59:20, 23.74s/it]\n",
      "64%|██████▍   | 265/414 [1:47:34<58:51, 23.70s/it]\n",
      "64%|██████▍   | 266/414 [1:47:58<58:27, 23.70s/it]\n",
      "64%|██████▍   | 267/414 [1:48:22<58:05, 23.71s/it]\n",
      "65%|██████▍   | 268/414 [1:48:45<57:41, 23.71s/it]\n",
      "65%|██████▍   | 269/414 [1:49:09<57:15, 23.69s/it]\n",
      "65%|██████▌   | 270/414 [1:49:33<56:54, 23.71s/it]\n",
      "{'loss': 1.6553, 'grad_norm': 0.2197265625, 'learning_rate': 0.0002, 'epoch': 1.96}\n",
      "65%|██████▌   | 270/414 [1:49:33<56:54, 23.71s/it]\n",
      "65%|██████▌   | 271/414 [1:49:56<56:27, 23.69s/it]\n",
      "66%|██████▌   | 272/414 [1:50:20<56:05, 23.70s/it]\n",
      "66%|██████▌   | 273/414 [1:50:44<55:41, 23.70s/it]\n",
      "66%|██████▌   | 274/414 [1:51:07<55:15, 23.68s/it]\n",
      "66%|██████▋   | 275/414 [1:51:31<54:58, 23.73s/it]\n",
      "67%|██████▋   | 276/414 [1:51:55<54:43, 23.79s/it]\n",
      "0%|          | 0/62 [00:00<?, ?it/s]#033[A\n",
      "3%|▎         | 2/62 [00:02<01:14,  1.24s/it]#033[A\n",
      "5%|▍         | 3/62 [00:04<01:43,  1.76s/it]#033[A\n",
      "6%|▋         | 4/62 [00:07<01:57,  2.02s/it]#033[A\n",
      "8%|▊         | 5/62 [00:09<02:04,  2.18s/it]#033[A\n",
      "10%|▉         | 6/62 [00:12<02:07,  2.28s/it]#033[A\n",
      "11%|█▏        | 7/62 [00:14<02:09,  2.35s/it]#033[A\n",
      "13%|█▎        | 8/62 [00:17<02:08,  2.39s/it]#033[A\n",
      "15%|█▍        | 9/62 [00:19<02:08,  2.42s/it]#033[A\n",
      "16%|█▌        | 10/62 [00:22<02:06,  2.44s/it]#033[A\n",
      "18%|█▊        | 11/62 [00:24<02:04,  2.45s/it]#033[A\n",
      "19%|█▉        | 12/62 [00:27<02:02,  2.46s/it]#033[A\n",
      "21%|██        | 13/62 [00:29<02:00,  2.47s/it]#033[A\n",
      "23%|██▎       | 14/62 [00:32<01:58,  2.47s/it]#033[A\n",
      "24%|██▍       | 15/62 [00:34<01:56,  2.47s/it]#033[A\n",
      "26%|██▌       | 16/62 [00:37<01:53,  2.47s/it]#033[A\n",
      "27%|██▋       | 17/62 [00:39<01:51,  2.48s/it]#033[A\n",
      "29%|██▉       | 18/62 [00:42<01:48,  2.47s/it]#033[A\n",
      "31%|███       | 19/62 [00:44<01:46,  2.48s/it]#033[A\n",
      "32%|███▏      | 20/62 [00:47<01:44,  2.48s/it]#033[A\n",
      "34%|███▍      | 21/62 [00:49<01:41,  2.48s/it]#033[A\n",
      "35%|███▌      | 22/62 [00:52<01:39,  2.48s/it]#033[A\n",
      "37%|███▋      | 23/62 [00:54<01:36,  2.48s/it]#033[A\n",
      "39%|███▊      | 24/62 [00:57<01:34,  2.48s/it]#033[A\n",
      "40%|████      | 25/62 [00:59<01:31,  2.48s/it]#033[A\n",
      "42%|████▏     | 26/62 [01:01<01:29,  2.48s/it]#033[A\n",
      "44%|████▎     | 27/62 [01:04<01:26,  2.48s/it]#033[A\n",
      "45%|████▌     | 28/62 [01:06<01:24,  2.47s/it]#033[A\n",
      "47%|████▋     | 29/62 [01:09<01:21,  2.48s/it]#033[A\n",
      "48%|████▊     | 30/62 [01:11<01:19,  2.48s/it]#033[A\n",
      "50%|█████     | 31/62 [01:14<01:16,  2.47s/it]#033[A\n",
      "52%|█████▏    | 32/62 [01:16<01:14,  2.47s/it]#033[A\n",
      "53%|█████▎    | 33/62 [01:19<01:11,  2.48s/it]#033[A\n",
      "55%|█████▍    | 34/62 [01:21<01:09,  2.47s/it]#033[A\n",
      "56%|█████▋    | 35/62 [01:24<01:06,  2.48s/it]#033[A\n",
      "58%|█████▊    | 36/62 [01:26<01:04,  2.47s/it]#033[A\n",
      "60%|█████▉    | 37/62 [01:29<01:01,  2.48s/it]#033[A\n",
      "61%|██████▏   | 38/62 [01:31<00:59,  2.47s/it]#033[A\n",
      "63%|██████▎   | 39/62 [01:34<00:56,  2.47s/it]#033[A\n",
      "65%|██████▍   | 40/62 [01:36<00:54,  2.47s/it]#033[A\n",
      "66%|██████▌   | 41/62 [01:39<00:52,  2.48s/it]#033[A\n",
      "68%|██████▊   | 42/62 [01:41<00:49,  2.48s/it]#033[A\n",
      "69%|██████▉   | 43/62 [01:44<00:47,  2.48s/it]#033[A\n",
      "71%|███████   | 44/62 [01:46<00:44,  2.47s/it]#033[A\n",
      "73%|███████▎  | 45/62 [01:48<00:42,  2.48s/it]#033[A\n",
      "74%|███████▍  | 46/62 [01:51<00:39,  2.47s/it]#033[A\n",
      "76%|███████▌  | 47/62 [01:53<00:37,  2.47s/it]#033[A\n",
      "77%|███████▋  | 48/62 [01:56<00:34,  2.47s/it]#033[A\n",
      "79%|███████▉  | 49/62 [01:58<00:32,  2.47s/it]#033[A\n",
      "81%|████████  | 50/62 [02:01<00:29,  2.48s/it]#033[A\n",
      "82%|████████▏ | 51/62 [02:03<00:27,  2.48s/it]#033[A\n",
      "84%|████████▍ | 52/62 [02:06<00:24,  2.48s/it]#033[A\n",
      "85%|████████▌ | 53/62 [02:08<00:22,  2.48s/it]#033[A\n",
      "87%|████████▋ | 54/62 [02:11<00:19,  2.48s/it]#033[A\n",
      "89%|████████▊ | 55/62 [02:13<00:17,  2.48s/it]#033[A\n",
      "90%|█████████ | 56/62 [02:16<00:14,  2.48s/it]#033[A\n",
      "92%|█████████▏| 57/62 [02:18<00:12,  2.48s/it]#033[A\n",
      "94%|█████████▎| 58/62 [02:21<00:09,  2.48s/it]#033[A\n",
      "95%|█████████▌| 59/62 [02:23<00:07,  2.47s/it]#033[A\n",
      "97%|█████████▋| 60/62 [02:26<00:04,  2.47s/it]#033[A\n",
      "98%|█████████▊| 61/62 [02:28<00:02,  2.48s/it]#033[A\n",
      "100%|██████████| 62/62 [02:31<00:00,  2.48s/it]#033[A\n",
      "#033[A\n",
      "{'eval_loss': 1.6925750970840454, 'eval_runtime': 154.3155, 'eval_samples_per_second': 25.681, 'eval_steps_per_second': 0.402, 'epoch': 2.0}\n",
      "67%|██████▋   | 276/414 [1:54:30<54:43, 23.79s/it]\n",
      "100%|██████████| 62/62 [02:31<00:00,  2.48s/it]#033[A\n",
      "#033[A\n",
      "67%|██████▋   | 277/414 [1:55:10<2:51:22, 75.06s/it]\n",
      "67%|██████▋   | 278/414 [1:55:34<2:15:11, 59.64s/it]\n",
      "67%|██████▋   | 279/414 [1:55:57<1:49:55, 48.86s/it]\n",
      "68%|██████▊   | 280/414 [1:56:21<1:32:14, 41.30s/it]\n",
      "{'loss': 1.6394, 'grad_norm': 0.1943359375, 'learning_rate': 0.0002, 'epoch': 2.03}\n",
      "68%|██████▊   | 280/414 [1:56:21<1:32:14, 41.30s/it]\n",
      "68%|██████▊   | 281/414 [1:56:45<1:19:51, 36.02s/it]\n",
      "68%|██████▊   | 282/414 [1:57:08<1:11:03, 32.30s/it]\n",
      "68%|██████▊   | 283/414 [1:57:32<1:04:54, 29.73s/it]\n",
      "69%|██████▊   | 284/414 [1:57:56<1:00:29, 27.92s/it]\n",
      "69%|██████▉   | 285/414 [1:58:19<57:19, 26.66s/it]\n",
      "69%|██████▉   | 286/414 [1:58:43<55:01, 25.80s/it]\n",
      "69%|██████▉   | 287/414 [1:59:07<53:30, 25.28s/it]\n",
      "70%|██████▉   | 288/414 [1:59:31<52:05, 24.80s/it]\n",
      "70%|██████▉   | 289/414 [1:59:55<50:57, 24.46s/it]\n",
      "70%|███████   | 290/414 [2:00:18<50:04, 24.23s/it]\n",
      "{'loss': 1.6008, 'grad_norm': 0.2080078125, 'learning_rate': 0.0002, 'epoch': 2.1}\n",
      "70%|███████   | 290/414 [2:00:18<50:04, 24.23s/it]\n",
      "70%|███████   | 291/414 [2:00:42<49:17, 24.04s/it]\n",
      "71%|███████   | 292/414 [2:01:06<48:41, 23.95s/it]\n",
      "71%|███████   | 293/414 [2:01:29<48:09, 23.88s/it]\n",
      "71%|███████   | 294/414 [2:01:53<47:38, 23.82s/it]\n",
      "71%|███████▏  | 295/414 [2:02:17<47:08, 23.77s/it]\n",
      "71%|███████▏  | 296/414 [2:02:40<46:43, 23.76s/it]\n",
      "72%|███████▏  | 297/414 [2:03:04<46:16, 23.73s/it]\n",
      "72%|███████▏  | 298/414 [2:03:28<45:52, 23.73s/it]\n",
      "72%|███████▏  | 299/414 [2:03:52<45:36, 23.80s/it]\n",
      "72%|███████▏  | 300/414 [2:04:16<45:18, 23.85s/it]\n",
      "{'loss': 1.6004, 'grad_norm': 0.1982421875, 'learning_rate': 0.0002, 'epoch': 2.17}\n",
      "72%|███████▏  | 300/414 [2:04:16<45:18, 23.85s/it]\n",
      "73%|███████▎  | 301/414 [2:04:39<44:48, 23.80s/it]\n",
      "73%|███████▎  | 302/414 [2:05:03<44:19, 23.75s/it]\n",
      "73%|███████▎  | 303/414 [2:05:27<43:52, 23.71s/it]\n",
      "73%|███████▎  | 304/414 [2:05:50<43:24, 23.68s/it]\n",
      "74%|███████▎  | 305/414 [2:06:14<43:02, 23.69s/it]\n",
      "74%|███████▍  | 306/414 [2:06:38<42:36, 23.67s/it]\n",
      "74%|███████▍  | 307/414 [2:07:01<42:13, 23.68s/it]\n",
      "74%|███████▍  | 308/414 [2:07:25<41:49, 23.68s/it]\n",
      "75%|███████▍  | 309/414 [2:07:49<41:24, 23.67s/it]\n",
      "75%|███████▍  | 310/414 [2:08:12<41:02, 23.68s/it]\n",
      "{'loss': 1.5941, 'grad_norm': 0.26171875, 'learning_rate': 0.0002, 'epoch': 2.25}\n",
      "75%|███████▍  | 310/414 [2:08:12<41:02, 23.68s/it]\n",
      "75%|███████▌  | 311/414 [2:08:36<40:41, 23.71s/it]\n",
      "75%|███████▌  | 312/414 [2:09:00<40:26, 23.79s/it]\n",
      "76%|███████▌  | 313/414 [2:09:24<40:01, 23.77s/it]\n",
      "76%|███████▌  | 314/414 [2:09:47<39:33, 23.73s/it]\n",
      "76%|███████▌  | 315/414 [2:10:11<39:08, 23.72s/it]\n",
      "76%|███████▋  | 316/414 [2:10:35<38:42, 23.70s/it]\n",
      "77%|███████▋  | 317/414 [2:10:58<38:17, 23.69s/it]\n",
      "77%|███████▋  | 318/414 [2:11:22<37:55, 23.70s/it]\n",
      "77%|███████▋  | 319/414 [2:11:46<37:30, 23.69s/it]\n",
      "77%|███████▋  | 320/414 [2:12:10<37:07, 23.69s/it]\n",
      "{'loss': 1.592, 'grad_norm': 0.21875, 'learning_rate': 0.0002, 'epoch': 2.32}\n",
      "77%|███████▋  | 320/414 [2:12:10<37:07, 23.69s/it]\n",
      "78%|███████▊  | 321/414 [2:12:33<36:44, 23.70s/it]\n",
      "78%|███████▊  | 322/414 [2:12:57<36:18, 23.68s/it]\n",
      "78%|███████▊  | 323/414 [2:13:21<35:55, 23.69s/it]\n",
      "78%|███████▊  | 324/414 [2:13:45<35:41, 23.80s/it]\n",
      "79%|███████▊  | 325/414 [2:14:09<35:18, 23.81s/it]\n",
      "79%|███████▊  | 326/414 [2:14:32<34:49, 23.74s/it]\n",
      "79%|███████▉  | 327/414 [2:14:56<34:25, 23.74s/it]\n",
      "79%|███████▉  | 328/414 [2:15:20<33:59, 23.71s/it]\n",
      "79%|███████▉  | 329/414 [2:15:43<33:35, 23.71s/it]\n",
      "80%|███████▉  | 330/414 [2:16:07<33:11, 23.71s/it]\n",
      "{'loss': 1.5956, 'grad_norm': 0.2197265625, 'learning_rate': 0.0002, 'epoch': 2.39}\n",
      "80%|███████▉  | 330/414 [2:16:07<33:11, 23.71s/it]\n",
      "80%|███████▉  | 331/414 [2:16:31<32:47, 23.70s/it]\n",
      "80%|████████  | 332/414 [2:16:54<32:22, 23.69s/it]\n",
      "80%|████████  | 333/414 [2:17:18<31:56, 23.66s/it]\n",
      "81%|████████  | 334/414 [2:17:42<31:34, 23.68s/it]\n",
      "81%|████████  | 335/414 [2:18:05<31:12, 23.70s/it]\n",
      "81%|████████  | 336/414 [2:18:29<30:53, 23.77s/it]\n",
      "81%|████████▏ | 337/414 [2:18:53<30:30, 23.77s/it]\n",
      "82%|████████▏ | 338/414 [2:19:17<30:10, 23.82s/it]\n",
      "82%|████████▏ | 339/414 [2:19:41<29:42, 23.77s/it]\n",
      "82%|████████▏ | 340/414 [2:20:04<29:17, 23.74s/it]\n",
      "{'loss': 1.5912, 'grad_norm': 0.205078125, 'learning_rate': 0.0002, 'epoch': 2.46}\n",
      "82%|████████▏ | 340/414 [2:20:04<29:17, 23.74s/it]\n",
      "82%|████████▏ | 341/414 [2:20:28<28:50, 23.71s/it]\n",
      "83%|████████▎ | 342/414 [2:20:52<28:26, 23.71s/it]\n",
      "83%|████████▎ | 343/414 [2:21:15<28:01, 23.69s/it]\n",
      "83%|████████▎ | 344/414 [2:21:39<27:37, 23.68s/it]\n",
      "83%|████████▎ | 345/414 [2:22:03<27:13, 23.68s/it]\n",
      "84%|████████▎ | 346/414 [2:22:26<26:50, 23.68s/it]\n",
      "84%|████████▍ | 347/414 [2:22:50<26:26, 23.68s/it]\n",
      "84%|████████▍ | 348/414 [2:23:14<26:03, 23.68s/it]\n",
      "84%|████████▍ | 349/414 [2:23:38<25:48, 23.82s/it]\n",
      "85%|████████▍ | 350/414 [2:24:01<25:21, 23.77s/it]\n",
      "{'loss': 1.5931, 'grad_norm': 0.1923828125, 'learning_rate': 0.0002, 'epoch': 2.54}\n",
      "85%|████████▍ | 350/414 [2:24:01<25:21, 23.77s/it]\n",
      "85%|████████▍ | 351/414 [2:24:25<25:00, 23.83s/it]\n",
      "85%|████████▌ | 352/414 [2:24:49<24:34, 23.78s/it]\n",
      "85%|████████▌ | 353/414 [2:25:13<24:07, 23.73s/it]\n",
      "86%|████████▌ | 354/414 [2:25:36<23:42, 23.70s/it]\n",
      "86%|████████▌ | 355/414 [2:26:00<23:18, 23.70s/it]\n",
      "86%|████████▌ | 356/414 [2:26:24<22:54, 23.69s/it]\n",
      "86%|████████▌ | 357/414 [2:26:47<22:28, 23.67s/it]\n",
      "86%|████████▋ | 358/414 [2:27:11<22:05, 23.66s/it]\n",
      "87%|████████▋ | 359/414 [2:27:35<21:39, 23.64s/it]\n",
      "87%|████████▋ | 360/414 [2:27:58<21:18, 23.67s/it]\n",
      "{'loss': 1.587, 'grad_norm': 0.2314453125, 'learning_rate': 0.0002, 'epoch': 2.61}\n",
      "87%|████████▋ | 360/414 [2:27:58<21:18, 23.67s/it]\n",
      "87%|████████▋ | 361/414 [2:28:22<20:55, 23.69s/it]\n",
      "87%|████████▋ | 362/414 [2:28:46<20:38, 23.81s/it]\n",
      "88%|████████▊ | 363/414 [2:29:10<20:14, 23.81s/it]\n",
      "88%|████████▊ | 364/414 [2:29:34<19:51, 23.83s/it]\n",
      "88%|████████▊ | 365/414 [2:29:57<19:25, 23.78s/it]\n",
      "88%|████████▊ | 366/414 [2:30:21<18:58, 23.72s/it]\n",
      "89%|████████▊ | 367/414 [2:30:45<18:34, 23.71s/it]\n",
      "89%|████████▉ | 368/414 [2:31:08<18:10, 23.70s/it]\n",
      "89%|████████▉ | 369/414 [2:31:32<17:45, 23.68s/it]\n",
      "89%|████████▉ | 370/414 [2:31:56<17:22, 23.70s/it]\n",
      "{'loss': 1.5682, 'grad_norm': 0.216796875, 'learning_rate': 0.0002, 'epoch': 2.68}\n",
      "89%|████████▉ | 370/414 [2:31:56<17:22, 23.70s/it]\n",
      "90%|████████▉ | 371/414 [2:32:19<16:58, 23.68s/it]\n",
      "90%|████████▉ | 372/414 [2:32:43<16:34, 23.67s/it]\n",
      "90%|█████████ | 373/414 [2:33:07<16:10, 23.68s/it]\n",
      "90%|█████████ | 374/414 [2:33:30<15:47, 23.68s/it]\n",
      "91%|█████████ | 375/414 [2:33:55<15:27, 23.79s/it]\n",
      "91%|█████████ | 376/414 [2:34:18<15:03, 23.77s/it]\n",
      "91%|█████████ | 377/414 [2:34:42<14:41, 23.83s/it]\n",
      "91%|█████████▏| 378/414 [2:35:06<14:16, 23.79s/it]\n",
      "92%|█████████▏| 379/414 [2:35:30<13:51, 23.76s/it]\n",
      "92%|█████████▏| 380/414 [2:35:53<13:27, 23.74s/it]\n",
      "{'loss': 1.5814, 'grad_norm': 0.203125, 'learning_rate': 0.0002, 'epoch': 2.75}\n",
      "92%|█████████▏| 380/414 [2:35:53<13:27, 23.74s/it]\n",
      "92%|█████████▏| 381/414 [2:36:17<13:02, 23.72s/it]\n",
      "92%|█████████▏| 382/414 [2:36:41<12:38, 23.71s/it]\n",
      "93%|█████████▎| 383/414 [2:37:04<12:14, 23.70s/it]\n",
      "93%|█████████▎| 384/414 [2:37:28<11:51, 23.71s/it]\n",
      "93%|█████████▎| 385/414 [2:37:52<11:27, 23.70s/it]\n",
      "93%|█████████▎| 386/414 [2:38:15<11:03, 23.68s/it]\n",
      "93%|█████████▎| 387/414 [2:38:39<10:39, 23.69s/it]\n",
      "94%|█████████▎| 388/414 [2:39:03<10:18, 23.79s/it]\n",
      "94%|█████████▍| 389/414 [2:39:27<09:53, 23.75s/it]\n",
      "94%|█████████▍| 390/414 [2:39:51<09:30, 23.79s/it]\n",
      "{'loss': 1.5718, 'grad_norm': 0.2109375, 'learning_rate': 0.0002, 'epoch': 2.83}\n",
      "94%|█████████▍| 390/414 [2:39:51<09:30, 23.79s/it]\n",
      "94%|█████████▍| 391/414 [2:40:14<09:06, 23.76s/it]\n",
      "95%|█████████▍| 392/414 [2:40:38<08:42, 23.74s/it]\n",
      "95%|█████████▍| 393/414 [2:41:02<08:17, 23.70s/it]\n",
      "95%|█████████▌| 394/414 [2:41:25<07:53, 23.70s/it]\n",
      "95%|█████████▌| 395/414 [2:41:49<07:30, 23.70s/it]\n",
      "96%|█████████▌| 396/414 [2:42:13<07:06, 23.71s/it]\n",
      "96%|█████████▌| 397/414 [2:42:36<06:42, 23.69s/it]\n",
      "96%|█████████▌| 398/414 [2:43:00<06:18, 23.68s/it]\n",
      "96%|█████████▋| 399/414 [2:43:24<05:55, 23.67s/it]\n",
      "97%|█████████▋| 400/414 [2:43:47<05:31, 23.69s/it]\n",
      "{'loss': 1.5516, 'grad_norm': 0.29296875, 'learning_rate': 0.0002, 'epoch': 2.9}\n",
      "97%|█████████▋| 400/414 [2:43:47<05:31, 23.69s/it]\n",
      "97%|█████████▋| 401/414 [2:44:11<05:08, 23.75s/it]\n",
      "97%|█████████▋| 402/414 [2:44:35<04:44, 23.75s/it]\n",
      "97%|█████████▋| 403/414 [2:44:59<04:22, 23.82s/it]\n",
      "98%|█████████▊| 404/414 [2:45:23<03:57, 23.78s/it]\n",
      "98%|█████████▊| 405/414 [2:45:46<03:33, 23.75s/it]\n",
      "98%|█████████▊| 406/414 [2:46:10<03:09, 23.72s/it]\n",
      "98%|█████████▊| 407/414 [2:46:34<02:45, 23.71s/it]\n",
      "99%|█████████▊| 408/414 [2:46:57<02:22, 23.70s/it]\n",
      "99%|█████████▉| 409/414 [2:47:21<01:58, 23.70s/it]\n",
      "99%|█████████▉| 410/414 [2:47:45<01:34, 23.70s/it]\n",
      "{'loss': 1.5491, 'grad_norm': 0.2158203125, 'learning_rate': 0.0002, 'epoch': 2.97}\n",
      "99%|█████████▉| 410/414 [2:47:45<01:34, 23.70s/it]\n",
      "99%|█████████▉| 411/414 [2:48:09<01:11, 23.69s/it]\n",
      "100%|█████████▉| 412/414 [2:48:32<00:47, 23.68s/it]\n",
      "100%|█████████▉| 413/414 [2:48:56<00:23, 23.68s/it]\n",
      "100%|██████████| 414/414 [2:49:20<00:00, 23.73s/it]\n",
      "0%|          | 0/62 [00:00<?, ?it/s]#033[A\n",
      "3%|▎         | 2/62 [00:02<01:14,  1.24s/it]#033[A\n",
      "5%|▍         | 3/62 [00:04<01:43,  1.75s/it]#033[A\n",
      "6%|▋         | 4/62 [00:07<01:57,  2.03s/it]#033[A\n",
      "8%|▊         | 5/62 [00:09<02:04,  2.18s/it]#033[A\n",
      "10%|▉         | 6/62 [00:12<02:07,  2.28s/it]#033[A\n",
      "11%|█▏        | 7/62 [00:14<02:08,  2.34s/it]#033[A\n",
      "13%|█▎        | 8/62 [00:17<02:08,  2.39s/it]#033[A\n",
      "15%|█▍        | 9/62 [00:19<02:07,  2.41s/it]#033[A\n",
      "16%|█▌        | 10/62 [00:22<02:06,  2.43s/it]#033[A\n",
      "18%|█▊        | 11/62 [00:24<02:04,  2.44s/it]#033[A\n",
      "19%|█▉        | 12/62 [00:27<02:02,  2.45s/it]#033[A\n",
      "21%|██        | 13/62 [00:29<02:00,  2.46s/it]#033[A\n",
      "23%|██▎       | 14/62 [00:32<01:58,  2.47s/it]#033[A\n",
      "24%|██▍       | 15/62 [00:34<01:56,  2.47s/it]#033[A\n",
      "26%|██▌       | 16/62 [00:37<01:53,  2.47s/it]#033[A\n",
      "27%|██▋       | 17/62 [00:39<01:51,  2.47s/it]#033[A\n",
      "29%|██▉       | 18/62 [00:42<01:48,  2.47s/it]#033[A\n",
      "31%|███       | 19/62 [00:44<01:46,  2.47s/it]#033[A\n",
      "32%|███▏      | 20/62 [00:47<01:43,  2.48s/it]#033[A\n",
      "34%|███▍      | 21/62 [00:49<01:41,  2.47s/it]#033[A\n",
      "35%|███▌      | 22/62 [00:51<01:39,  2.48s/it]#033[A\n",
      "37%|███▋      | 23/62 [00:54<01:36,  2.47s/it]#033[A\n",
      "39%|███▊      | 24/62 [00:56<01:33,  2.47s/it]#033[A\n",
      "40%|████      | 25/62 [00:59<01:31,  2.47s/it]#033[A\n",
      "42%|████▏     | 26/62 [01:01<01:29,  2.47s/it]#033[A\n",
      "44%|████▎     | 27/62 [01:04<01:26,  2.48s/it]#033[A\n",
      "45%|████▌     | 28/62 [01:06<01:24,  2.48s/it]#033[A\n",
      "47%|████▋     | 29/62 [01:09<01:21,  2.48s/it]#033[A\n",
      "48%|████▊     | 30/62 [01:11<01:19,  2.48s/it]#033[A\n",
      "50%|█████     | 31/62 [01:14<01:16,  2.48s/it]#033[A\n",
      "52%|█████▏    | 32/62 [01:16<01:14,  2.48s/it]#033[A\n",
      "53%|█████▎    | 33/62 [01:19<01:11,  2.48s/it]#033[A\n",
      "55%|█████▍    | 34/62 [01:21<01:09,  2.48s/it]#033[A\n",
      "56%|█████▋    | 35/62 [01:24<01:06,  2.47s/it]#033[A\n",
      "58%|█████▊    | 36/62 [01:26<01:04,  2.48s/it]#033[A\n",
      "60%|█████▉    | 37/62 [01:29<01:01,  2.48s/it]#033[A\n",
      "61%|██████▏   | 38/62 [01:31<00:59,  2.48s/it]#033[A\n",
      "63%|██████▎   | 39/62 [01:34<00:56,  2.48s/it]#033[A\n",
      "65%|██████▍   | 40/62 [01:36<00:54,  2.47s/it]#033[A\n",
      "66%|██████▌   | 41/62 [01:39<00:51,  2.47s/it]#033[A\n",
      "68%|██████▊   | 42/62 [01:41<00:49,  2.47s/it]#033[A\n",
      "69%|██████▉   | 43/62 [01:43<00:47,  2.48s/it]#033[A\n",
      "71%|███████   | 44/62 [01:46<00:44,  2.48s/it]#033[A\n",
      "73%|███████▎  | 45/62 [01:48<00:42,  2.48s/it]#033[A\n",
      "74%|███████▍  | 46/62 [01:51<00:39,  2.48s/it]#033[A\n",
      "76%|███████▌  | 47/62 [01:53<00:37,  2.48s/it]#033[A\n",
      "77%|███████▋  | 48/62 [01:56<00:34,  2.48s/it]#033[A\n",
      "79%|███████▉  | 49/62 [01:58<00:32,  2.48s/it]#033[A\n",
      "81%|████████  | 50/62 [02:01<00:29,  2.48s/it]#033[A\n",
      "82%|████████▏ | 51/62 [02:03<00:27,  2.48s/it]#033[A\n",
      "84%|████████▍ | 52/62 [02:06<00:24,  2.48s/it]#033[A\n",
      "85%|████████▌ | 53/62 [02:08<00:22,  2.48s/it]#033[A\n",
      "87%|████████▋ | 54/62 [02:11<00:19,  2.48s/it]#033[A\n",
      "89%|████████▊ | 55/62 [02:13<00:17,  2.48s/it]#033[A\n",
      "90%|█████████ | 56/62 [02:16<00:14,  2.48s/it]#033[A\n",
      "92%|█████████▏| 57/62 [02:18<00:12,  2.48s/it]#033[A\n",
      "94%|█████████▎| 58/62 [02:21<00:09,  2.48s/it]#033[A\n",
      "95%|█████████▌| 59/62 [02:23<00:07,  2.48s/it]#033[A\n",
      "97%|█████████▋| 60/62 [02:26<00:04,  2.48s/it]#033[A\n",
      "98%|█████████▊| 61/62 [02:28<00:02,  2.48s/it]#033[A\n",
      "100%|██████████| 62/62 [02:31<00:00,  2.48s/it]#033[A\n",
      "#033[A\n",
      "{'eval_loss': 1.6220916509628296, 'eval_runtime': 154.2213, 'eval_samples_per_second': 25.697, 'eval_steps_per_second': 0.402, 'epoch': 3.0}\n",
      "100%|██████████| 414/414 [2:51:54<00:00, 23.73s/it]\n",
      "100%|██████████| 62/62 [02:31<00:00,  2.48s/it]#033[A\n",
      "#033[A\n",
      "{'train_runtime': 10331.4535, 'train_samples_per_second': 10.231, 'train_steps_per_second': 0.04, 'train_loss': 1.7268463793584115, 'epoch': 3.0}\n",
      "100%|██████████| 414/414 [2:52:11<00:00, 23.73s/it]\n",
      "100%|██████████| 414/414 [2:52:11<00:00, 24.96s/it]\n",
      "Trying to load a Peft model. It might take a while without feedback\n",
      "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "[W PyInterpreter.cpp:221] Warning: Deallocating Tensor that still has live PyObject references.  This probably happened because you took out a weak reference to Tensor and didn't call _fix_weakref() after dereferencing it.  Subsequent accesses to this tensor via the PyObject will now fail. (function decref)\n",
      "Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.97s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.73s/it]\n",
      "Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.62s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.25s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.79s/it]\n",
      "Saving the newly created merged model to /opt/ml/model\n",
      "2024-06-30 16:22:07,792 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-06-30 16:22:07,792 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-06-30 16:22:07,793 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-06-30 16:22:16 Uploading - Uploading generated training model\n",
      "2024-06-30 16:23:28 Completed - Training job completed\n",
      "Training seconds: 10742\n",
      "Billable seconds: 10742\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example the training Llama 3 70B with Flash Attention for 2 epochs with a dataset of 10k samples takes 5052 seconds (~84minutes) on a `ml.p4d.24xlarge` or ~$50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 경로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_s3_path: \n",
      " {'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-06-30-13-24-2-2024-06-30-13-24-21-342/output/model/', 'S3DataType': 'S3Prefix', 'CompressionType': 'None'}}\n",
      "Stored 'model_s3_path' (dict)\n"
     ]
    }
   ],
   "source": [
    "model_s3_path = huggingface_estimator.model_data\n",
    "print(\"model_s3_path: \\n\", model_s3_path)\n",
    "\n",
    "%store model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llama3_puy310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
