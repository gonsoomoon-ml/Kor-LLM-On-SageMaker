{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4872e4-c90b-434b-bfe5-f88292fba385",
   "metadata": {},
   "source": [
    "# Fine Tune LLM for Text Summary\n",
    "- https://www.kaggle.com/code/mitanshuchakrawarty/fine-tune-llm-for-text-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da7aa7-1a2d-4db1-b011-59217c32a83a",
   "metadata": {},
   "source": [
    "## 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675a4f33-a8ef-498a-9755-c4aefb99be77",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.31\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.31) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.31) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.31) (2024.2.2)\n",
      "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.2\n",
      "    Uninstalling tokenizers-0.15.2:\n",
      "      Successfully uninstalled tokenizers-0.15.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.38.2\n",
      "    Uninstalling transformers-4.38.2:\n",
      "      Successfully uninstalled transformers-4.38.2\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n",
      "Requirement already satisfied: peft in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (4.31.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from peft) (0.23.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes\n",
    "!pip install transformers==4.31\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install peft\n",
    "!pip install -q datasets\n",
    "!pip install -qqq trl==0.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a396bc4f-0b0a-4ffb-8c59-18ed6d0a968d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e4b722-f752-4687-8fbe-12855566892c",
   "metadata": {},
   "source": [
    "## 2. 데이터 셋 준비\n",
    "### 데이터 셋 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3710c3d-71bb-47b1-97eb-a72ef6dcfd53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280a5764c4914005934d90f4d34fd4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 257M/257M [00:00<00:00, 384MB/s] \n",
      "Downloading data: 100%|██████████| 257M/257M [00:00<00:00, 398MB/s] \n",
      "Downloading data: 100%|██████████| 259M/259M [00:00<00:00, 402MB/s] \n",
      "Downloading data: 100%|██████████| 34.7M/34.7M [00:00<00:00, 261MB/s]\n",
      "Downloading data: 100%|██████████| 30.0M/30.0M [00:00<00:00, 191MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39490bde250f429787d55162ceb00087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eaf94f4806431fbd3efbc2a5911f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ded9f26c694606aebd9035442671c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_dataset_name = \"cnn_dailymail\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name, \"3.0.0\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9b4f66-a1f6-484d-9cfd-c5bfe17835cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most s\n",
      "\n",
      "Summary (length: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96451467-4fc0-49af-bedf-040850c11fbb",
   "metadata": {},
   "source": [
    "### 데이터텟 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c0f824-8a38-4df6-9a53-460f52a66f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_instruction(dialogue: str, summary: str):\n",
    "    return f\"\"\"### Instruction:\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue.strip()}\n",
    "\n",
    "### Summary:\n",
    "{summary}\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_instruction_dataset(data_point):\n",
    "\n",
    "    return {\n",
    "        \"article\": data_point[\"article\"],\n",
    "        \"highlights\": data_point[\"highlights\"],\n",
    "        \"text\": format_instruction(data_point[\"article\"],data_point[\"highlights\"])\n",
    "    }\n",
    "\n",
    "def process_dataset(data: Dataset):\n",
    "    return (\n",
    "        data.shuffle(seed=42)\n",
    "        .map(generate_instruction_dataset).remove_columns(['id'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0e2f3d-2c64-4bd4-9796-e32497a7c781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a156200aacf4112b09e8712a0a63789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98a274a1e3340f3a9d464b9ec365375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 1000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 100\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['article', 'highlights', 'text'],\n",
       "     num_rows: 100\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## APPLYING PREPROCESSING ON WHOLE DATASET\n",
    "dataset[\"train\"] = process_dataset(dataset[\"train\"])\n",
    "dataset[\"test\"] = process_dataset(dataset[\"validation\"])\n",
    "dataset[\"validation\"] = process_dataset(dataset[\"validation\"])\n",
    "\n",
    "# Select 1000 rows from the training split\n",
    "train_data = dataset['train'].shuffle(seed=42).select([i for i in range(1000)])\n",
    "\n",
    "# Select 100 rows from the test and validation splits\n",
    "test_data = dataset['test'].shuffle(seed=42).select([i for i in range(100)])\n",
    "validation_data = dataset['validation'].shuffle(seed=42).select([i for i in range(100)])\n",
    "\n",
    "train_data,test_data,validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78f53c-d21d-4fca-b69d-6a85d966353c",
   "metadata": {},
   "source": [
    "## 3. 베이스 모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47341964-d43d-4835-b650-316320567f84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e74c01d5cd74cce8121abe2e492b7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c88844075c44bb6907d1d561cf5b7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3da486a4bd4fd5b39201b246437d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f3404247e5461886f4004e1f998d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a463964cab4c5d8df3a0a4d593eb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c921af1891c744539284686f5b625264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ea09e33ec842b5ba6f11967da1531c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f82306e2ae04a509e016d4c00ed3caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525ccb49c8464884ae5ebcfe422ce4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ed47dd97354131b0a9e1d96d539fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b14676e29f4f1f99ddaa38e036452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id =  \"NousResearch/Llama-2-7b-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441607e4-f93f-438e-8985-99a76233fe47",
   "metadata": {},
   "source": [
    "### 베이스 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4f0471b-27a6-4cbb-a44c-f7e71aef3c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "The court's order after video of fraternity students at the school engaged in a racist chant spread across the Internet .\n",
      "The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris .\n",
      "Meyer says she entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis .\n",
      "Swiss records show Meyer's father, Raoul Meyer,  had owned the painting in Paris .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "A federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to do so. The court's order on Thursday came as the school found itself amid a racial controversy after video of fraternity students engaged in a racist chant spread across the Internet. Dr. Leone-Noelle Meyer maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France . University President David Boren ordered a fraternity house closed and expelled two of its members after reviewing clips of the chant that referenced lynching and said blacks would never be allowed in the fraternity. The school and Boren are defendants in the lawsuit brought in 2013 by 75-year-old Holocaust survivor Leone Meyer, who lives in Paris. She maintained she is entitled to Pissarro's 1886 'Shepherdess Bringing in Sheep' because it belonged to her father when it was taken by the Nazis as Germany moved across France. Her father, Raoul Mayer, died in 1970. Swiss records show Meyer's father in Paris had owned the painting. But a Swiss court ruled that the painting's post-war owners had properly established ownership and rejected her claim. Bequeathed to OU by Clara Weitzenhoffer, the wife of oil tycoon Aaron Weitzenhoffer, the school displayed it publicly for over a decade. The painting: Swiss records show Leone-Noelle Meyer's father in Paris had owned the painting 'Shepherdess Bringing in Sheep' by Camille Pissaro . Disputed item: This Monday, May 12, 2014 photo shows a display of information on the 1886 painting 'Shepherdess Bringing in Sheep' by Camille Pissarro . The Weitzenhoffers bought the painting from a New York gallery in 1956. When she died in 2000, she donated more than 30 works worth about $50 million to the University of Oklahoma. In an emailed statement Saturday, Oklahoma University spokeswoman Catherine F. Bishop said: 'The University is continuing its efforts to work with the plaintiffs to determine all the facts in this matter, some of which may still be unknown, and to seek a mutually agreeable resolution.' Last year, Boren defended Oklahoma University's ownership, saying the school does not want to keep any items it does not legitimately own but also wants to avoid a bad precedent by automatically giving away gifts it receives to anyone who claims them. Boren and the school have opposed the lawsuit on largely procedural grounds, saying the school has sovereign immunity and that Meyer was not diligent in pursuing her claim and had sued in New York rather than Oklahoma as a 'forum shopping strategy' to avoid Oklahoma's more restrictive statute of limitations. Several Oklahoma lawmakers who authored a resolution in the state Legislature seeking to force the school to turn the painting over have spoken out against the university's position. In a letter to the people of Oklahoma, Meyer has said her quest 'has nothing to do with money. It is about justice and a duty to remember.' Pierre Ciric, a lawyer for Meyer, said Saturday he welcomed 'any progress toward the resolution of our client's claim.' 'It appears that everyone involved with this case agrees that `La Bergere' was the property of my client's father prior to the Nazi occupation of France, which we have asserted since the complaint was filed,' he said. Under fire: The court's order on Thursday came as the school found itself amid a racial controversy after video showing Sigma Alpha Epsilon members singing a racist chant while traveling on a tour bus went viral .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "The federal appeals court has given new life to a Holocaust survivor's claim that the University of Oklahoma is unjustly harboring a Camille Pissarro painting that the Nazis stole from her father during World War II. The 2nd U.S. Circuit Court of Appeals in Manhattan has directed a lower-court judge to consider whether the lawsuit she threw out should be transferred to Oklahoma, saying she has authority to\n"
     ]
    }
   ],
   "source": [
    "index = 2\n",
    "\n",
    "dialogue = test_data['article'][index]\n",
    "summary = test_data['highlights'][index]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "output = tokenizer.decode(\n",
    "    model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=100,\n",
    "    )[0],\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dash_line)\n",
    "print(f'INPUT PROMPT:\\n{prompt}')\n",
    "print(dash_line)\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "print(dash_line)\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd060a15-6c13-4c47-a34f-2648cdceab3a",
   "metadata": {},
   "source": [
    "### 모델을 LoRA 를 사용할 수 있게 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d6a3db-b8b3-4213-8914-b0f37eba1068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfdbfc-f5f5-4c00-8de2-24fc5fc8a58d",
   "metadata": {},
   "source": [
    "### PEFT 모델로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d716e1d4-a4c9-42ca-b8b3-a61cdc1f0249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16777216 || all params: 3517190144 || trainable%: 0.477006226934315\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"], #specific to Llama models.\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe112b1-6bb2-40d4-8ff9-43e315ad0f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13dfc45-65a7-4997-81e4-52dcefcbdffa",
   "metadata": {},
   "source": [
    "## 4. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae17c43-d23e-4639-9a6c-a116f88da6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "OUTPUT_DIR = \"llama2-docsum-adapter\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    # report_to=\"tensorboard\",\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9fb7f9-5a2a-42e0-875b-0c57b096a562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae1072c40b84fc1801eb98a322b5570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [248/248 31:55, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.793900</td>\n",
       "      <td>1.662905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.723900</td>\n",
       "      <td>1.656829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>1.657528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.577800</td>\n",
       "      <td>1.657586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=248, training_loss=1.6403747984478552, metrics={'train_runtime': 1926.6331, 'train_samples_per_second': 2.076, 'train_steps_per_second': 0.129, 'total_flos': 7.08923925085225e+16, 'train_loss': 1.6403747984478552, 'epoch': 3.97})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a1f50a-9185-4043-a57d-39b272f1b694",
   "metadata": {},
   "source": [
    "## 5. 훈련 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef76c46-357b-4484-a6d3-6884045cb39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af4770-553a-4bba-a809-c40e4ff92373",
   "metadata": {},
   "source": [
    "## 6. 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecfd8052-6448-4bee-ba32-e1120d54b2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./peft-dialogue-summary/tokenizer_config.json',\n",
       " './peft-dialogue-summary/special_tokens_map.json',\n",
       " './peft-dialogue-summary/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_path=\"./peft-dialogue-summary\"\n",
    "\n",
    "trainer.model.save_pretrained(peft_model_path)\n",
    "tokenizer.save_pretrained(peft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc3561d7-ad92-4e9a-a172-fe8cd85b0921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "total 66M\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4.0K Jun 25 11:32 .\n",
      "drwxrwxr-x 6 ec2-user ec2-user 4.0K Jun 25 11:32 ..\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  650 Jun 25 11:32 adapter_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  65M Jun 25 11:32 adapter_model.safetensors\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 5.0K Jun 25 11:32 README.md\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  434 Jun 25 11:32 special_tokens_map.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user  695 Jun 25 11:32 tokenizer_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 1.8M Jun 25 11:32 tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "! ls {peft_model_path} -al -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd98ed-f3a6-41ba-939c-9f54e65c17a8",
   "metadata": {},
   "source": [
    "## 7.Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22ba6172-d121-40df-a555-23a7d564f1d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "model.config.use_cache = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec4e3e-cae5-40c1-8e5a-93c60a82e04c",
   "metadata": {},
   "source": [
    "### 훈련된 모델 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f971571-2ec6-4e7d-b71a-b6ccbdc47666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343cee85e4ba4c5aaebea004260173d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "peft_model_dir = \"peft-dialogue-summary\"\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "trained_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f049247-6160-41c6-b127-c8fad69fc210",
   "metadata": {},
   "source": [
    "### 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "742528e4-5208-406b-89ba-8307dc264ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 51\n",
    "\n",
    "dialogue = train_data['article'][index][:10000]\n",
    "summary = train_data['highlights'][index]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "### Input:\n",
    "{dialogue}\n",
    "\n",
    "### Summary:\n",
    "\"\"\"\n",
    "\n",
    "def inference_model(tokenizer,prompt, model ):\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt',truncation=True).input_ids.cuda()\n",
    "    outputs = model.generate(input_ids=input_ids, max_new_tokens=200, )\n",
    "    output= tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0][len(prompt):]\n",
    "\n",
    "    dash_line = '-'.join('' for x in range(100))\n",
    "    print(dash_line)\n",
    "    print(f'INPUT PROMPT:\\n{prompt}')\n",
    "    print(dash_line)\n",
    "    print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
    "    print(dash_line)\n",
    "    print(f'TRAINED MODEL GENERATED TEXT :\\n{output}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e642bb0-d131-4536-ae94-a2d37a43437e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "You might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Polar bears have evolved special large, flat paws for walking on sea ice .\n",
      "But this specimen from Svalbard nevertheless struggled with its footing .\n",
      "The Arctic killer ventured off the thick ice that can support his weight .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED TEXT :\n",
      "Polar bear caught on camera slipping and sliding across thin sea ice in Svalbard, Norway .\n",
      "The beast finally gave up and pushed a hole in the ice to dive into the freezing water .\n",
      "Polar bears are regarded as marine mammals because of the many months they spend at sea .\n",
      "They have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice .\n",
      "Polar bears can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea .\n",
      "The beasts are regarded as marine mammals because of the many months they spend at sea .\n",
      "They have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice .\n",
      "Polar bears can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inference_model(tokenizer = tokenizer,\n",
    "                prompt = prompt, \n",
    "                model = trained_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "084e2b86-aa67-4acf-b2d2-d197a2fc7c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------\n",
      "INPUT PROMPT:\n",
      "\n",
      "Summarize the following conversation.\n",
      "\n",
      "### Input:\n",
      "You might expect polar bears, the Artic Circle's apex predators, to be dab hands at dancing on ice. But as this specimen in Svalbard shows, even after thousands of years of evolutionary adaptation, some still suffer from two-left feet on the frozen ocean. Heinrich Eggenfellner, a 49-year-old videographer from Norway, said: 'I have encountered polar bears many times every year since I live up here and am used to them. 'This episode, however, was extraordinary.' Born slippy: A polar walks across thin sea ice in Svalbard, Norway, where it was caught on camera looking very unsteady on its feet as it made its way across the slippery surface . Spreading its weight: The polar bear does its best not to collapse through the fragile ice by spreading out . In its element: The beast finally gave up and pushed a hole in the ice to dive into the freezing water . Mr Eggenfellner and his friend Svein Wik spent hours in Norway's northernmost territory hunting for a polar bear to film and photograph, then hours more waiting for the slumbering beast to wake up. It was time well spent. The patient duo were treated to a farcical display of slipping and sliding across the frozen sea, with their subject falling flat on its face at least once. 'Maybe we waited 3-4 hours before the bear woke up and came out onto thinner and thinner ice,' Mr Wik told Caters News Agency. 'At one point, it spread out on all four legs to prevent falling thorough the ice until finally the bear gave up, pushed through the ice and started to swim. 'He dived for a few seconds and showed up again, looking up and then started to shake of the water.' Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia . Evolution: Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice . Brains: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it . Weighty: Polar bears can weigh up to 1,100lbs, more than enough to smash through thin layers of frozen sea . Taking a dip: The polar bear pictured just after deciding it was better off taking a swim in the freezing sea . Regarded as marine mammals because of the many months they spend at sea, polar bears have nevertheless adapted large, flat paws to distribute their bulk as they pad across thin ice. They can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man. Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of the most charismatic animals in the world. 'It was a rare and very interesting situation to watch everything and this was, without doubt, the ultimate wilderness experience for me.' Stunning: Photographer Svein Wik and videographer Heinrich Eggenfellner spent hours trying to find a polar bear to document in the stark frozen landscape of Svalbard, the Norwegian Arctic territory .\n",
      "\n",
      "### Summary:\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "Polar bears have evolved special large, flat paws for walking on sea ice .\n",
      "But this specimen from Svalbard nevertheless struggled with its footing .\n",
      "The Arctic killer ventured off the thick ice that can support his weight .\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "TRAINED MODEL GENERATED TEXT :\n",
      "Polar bear caught on camera looking very unsteady on its feet as it made its way across the slippery surface .\n",
      "Born slippy: The beast finally gave up and pushed a hole in the ice to dive into the freezing water .\n",
      "Proud: Polar bears are the Arctic Circle's apex predators and have adapted to the habitat over millennia .\n",
      "Evolution: However this beast seems to have realised that big feet are not enough to stop it smashing through the thin ice and is trying to spread its weight to lessen the pressure beneath it .\n",
      "Weighing up: Polar bears can weigh up to 1,100lbs, more than enough to smash through layers of frozen sea that would easily hold a man .\n",
      "Mr Wik added: 'It is difficult to explain my feelings in situations like this. I think the Polar bear is one of\n"
     ]
    }
   ],
   "source": [
    "inference_model(tokenizer = tokenizer,\n",
    "                prompt = prompt, \n",
    "                model = model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60aaa4-b654-49b3-bb87-34ad6a9f375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
