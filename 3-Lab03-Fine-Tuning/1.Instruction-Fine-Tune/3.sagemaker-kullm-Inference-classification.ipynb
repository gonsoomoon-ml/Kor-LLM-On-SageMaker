{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Retail Store 상품 분류 LoRA 모델 서빙 및 평가\n",
    "\n",
    "---\n",
    "\n",
    "> 이 노트북은 SageMaker Studio Notebook PyTorch 1.13 Python 3.9 docker image 와 ml.t3.medium 에서 테스트 되었습니다. :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기본 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# src 폴더 경로 설정\n",
    "import sys\n",
    "sys.path.append('../../common_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::057716757052:role/gen_ai_gsmoon\n",
      "sagemaker bucket: sagemaker-us-east-1-057716757052\n",
      "sagemaker session region: us-east-1\n",
      "bucket: sagemaker-us-east-1-057716757052\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"bucket: {sagemaker_session_bucket}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_id = \"nlpai-lab/kullm-polyglot-12.8b-v2\"\n",
    "# model_name = model_id.split('/')[1]\n",
    "# model_name = model_name.split('.')[0]\n",
    "# print(\"model_name: \", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. 파인 튜닝 모델 배포 및 추론\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 훈련 잡 이름으로 Estimator 다시 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- 이전 노트북에서 훈련한 잡 이름을 가져 옵니다.\n",
    "- 잡 이름을 통해서 모델 정보(모델 가중치 파일 등) 를 가져와서 Estimator 를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retail_store_training_job_name: \n",
      " kullm-polyglot-12-ko-retail-store-data--2023-09-24-08-06-25-412\n"
     ]
    }
   ],
   "source": [
    "%store -r retail_store_training_job_name\n",
    "print(\"retail_store_training_job_name: \\n\", retail_store_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "\n",
      "2023-09-24 09:07:01 Starting - Preparing the instances for training\n",
      "2023-09-24 09:07:01 Downloading - Downloading input data\n",
      "2023-09-24 09:07:01 Training - Training image download completed. Training in progress.\n",
      "2023-09-24 09:07:01 Uploading - Uploading generated training model\n",
      "2023-09-24 09:07:01 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "attached_estimator = Estimator.attach(retail_store_training_job_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Model 을 생성하여 모델 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=attached_estimator.model_data,\n",
    "   #model_data=\"s3://hf-sagemaker-inference/model.tar.gz\",  # Change to your model path\n",
    "   role=role, \n",
    "   transformers_version=\"4.26\", \n",
    "   pytorch_version=\"1.13\", \n",
    "   py_version=\"py39\",\n",
    "   model_server_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now deploy our model using the `deploy()` on our HuggingFace estimator object, passing in our desired number of instances and instance type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앤드포인트 이름 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'fine-tuned-kullm-polyglot-12-8b-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "time_stamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "fine_tuned_model_endpoint_name = f\"{model_name}-\" + time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!CPU times: user 144 ms, sys: 15.4 ms, total: 160 ms\n",
      "Wall time: 6min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "   endpoint_name= fine_tuned_model_endpoint_name,    \n",
    "   initial_instance_count=1,\n",
    "   instance_type= \"ml.g5.4xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래는 실험을 위하여 하드 코딩 하였습니다. \n",
    "- 실제 작업시에 주석 처리하고 사용 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fine_tuned_model_endpoint_name = 'fine-tuned-kullm-polyglot-12-8b-v2-2023-09-24-09-18-08'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. 베이스 모델 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [중요] 아래 노트북을 실행한 후에 생성되는 엔드포인트 이름을 아래에 넣어 주세요.\n",
    "- Kor-LLM-On-SageMaker/1-Lab01-Deploy-LLM/1.Deploy-Kor-LLM-PythonSDK.ipynb\n",
    "- 이후에 아래 셀에 하드코딩된 엔드포인트 이름은 지워 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_endpoint_name = '<Type Your Endpoint Name'\n",
    "base_model_endpoint_name = 'Kullm-polyglot-12-8b-v2-2023-09-24-10-48-02'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(prompt, is_fine_tuned=False):\n",
    "    '''\n",
    "    구름의 모델 경우는 베이스 모델 엔드포인트 생성시에 model.py 를 자제 정의한 기준으로 엔드포인트 생성함.\n",
    "    반면에 파인 튜닝시는 모델 제공자의 디폴트 모델 설정 파일로 엔드포인트를 생성하기에 \"입력 프로프트\" 의 정의가 약간 다름. 그래서 아래 처럼 2가지로 구분하여 프로프트 생성. \n",
    "    '''\n",
    "    max_new_tokens = 64\n",
    "    temperature = 0.8\n",
    "    top_k = 10\n",
    "    top_p = 0.5\n",
    "    repetition_penalty = 1.5\n",
    "    \n",
    "    \n",
    "    if is_fine_tuned:        \n",
    "        fomatted_sample = {\n",
    "          # \"inputs\": prompter.generate_prompt(q, c),\n",
    "          \"inputs\": prompt,  \n",
    "          \"parameters\": {\n",
    "            \"do_sample\":False, \n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "            \"repetition_penalty\": repetition_penalty,\n",
    "            \"presence_penalty\":None,\n",
    "            \"eos_token_id\":2,              \n",
    "          }\n",
    "        }\n",
    "    else:\n",
    "        fomatted_sample = {\n",
    "          # \"inputs\": prompter.generate_prompt(q, c),\n",
    "          \"prompt\": prompt,  \n",
    "          \"params\": {\n",
    "            \"do_sample\":False, \n",
    "            \"max_new_tokens\": max_new_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "            \"repetition_penalty\": repetition_penalty,\n",
    "            \"presence_penalty\":None,\n",
    "            \"eos_token_id\":2,              \n",
    "          }\n",
    "        }\n",
    "        \n",
    "    # print(\"fomatted_sample: \\n\", fomatted_sample)\n",
    "    \n",
    "    return fomatted_sample\n",
    "\n",
    "def generate_llm(prompt):\n",
    "    # predict\n",
    "    res = predictor.predict(prompt)\n",
    "\n",
    "    print(res[0][\"generated_text\"].split(\"Summary:\")[-1])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inference_lib import print_ww\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inference_lib import invoke_inference_DJ,  parse_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_data: \n",
      " 다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 방을 돋보이게 해주는 세련된 게인즈버러 액센트 테이블\n",
      "\n",
      "### 답변:\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"다음의 상품 설명을 분류하세요.\\n\\\n",
    "### 상품 설명: {question}\\n\\n### 답변:\"\"\"\n",
    "\n",
    "prompt_template_object = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"question\"]\n",
    ")\n",
    "# Pass in values to the input variables\n",
    "q = \"방을 돋보이게 해주는 세련된 게인즈버러 액센트 테이블\" # 레이블: 가구|테이블\n",
    "prompt_data = prompt_template_object.format(question=q)\n",
    "print(\"prompt_data: \\n\", prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fomatted_prompt: : \n",
      " {'prompt': '다음의 상품 설명을 분류하세요.\\n### 상품 설명: 방을 돋보이게 해주는 세련된 게인즈버러 액센트 테이블\\n\\n### 답변:', 'params': {'do_sample': False, 'max_new_tokens': 64, 'temperature': 0.8, 'top_k': 10, 'top_p': 0.5, 'repetition_penalty': 1.5, 'presence_penalty': None, 'eos_token_id': 2}}\n"
     ]
    }
   ],
   "source": [
    "fomatted_prompt = create_prompt(prompt_data, is_fine_tuned=False)\n",
    "print(\"fomatted_prompt: : \\n\", fomatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 방을 돋보이게 해주는 세련된 게인즈버러 액센트 테이블\n",
      "\n",
      "### 답변:\n",
      "방에 어울리고, 아름답지만 비싸지 않으며, 고급스럽거나 화려한 느낌이 나지않으면서도 우아하고 매력적입니다.\"\n"
     ]
    }
   ],
   "source": [
    "res = invoke_inference_DJ(base_model_endpoint_name, fomatted_prompt)\n",
    "res = json.loads(res)\n",
    "print_ww(res[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fune-Tuned 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 방을 돋보이게 해주는 세련된 게인즈버러 액센트 테이블\n",
      "\n",
      "### 답변:\n",
      "가구|테이블\n"
     ]
    }
   ],
   "source": [
    "fomatted_prompt = create_prompt(prompt_data, is_fine_tuned=True)\n",
    "res = invoke_inference_DJ(fine_tuned_model_endpoint_name, fomatted_prompt)\n",
    "res = json.loads(res)\n",
    "print_ww(res[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 베이스 모델, 튜닝 모델 동시 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_comppare_result(question, label, prompt_template_object, base_model_endpoint_name, fine_tuned_model_endpoint_name):\n",
    "    prompt_data = prompt_template_object.format(question=question)\n",
    "    \n",
    "    # (1) Base Model\n",
    "    fomatted_prompt = create_prompt(prompt_data, is_fine_tuned=False)\n",
    "    res = invoke_inference_DJ(base_model_endpoint_name, fomatted_prompt)\n",
    "    res = json.loads(res)\n",
    "    print(\"> Base Model: \\n\")\n",
    "    print_ww(res[0]['generated_text'])\n",
    "\n",
    "    \n",
    "    # (2) Fine-tuned Model\n",
    "    fomatted_prompt = create_prompt(prompt_data, is_fine_tuned=True)\n",
    "    res = invoke_inference_DJ(fine_tuned_model_endpoint_name, fomatted_prompt)\n",
    "    res = json.loads(res)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"> Fine-Tuned Model: \\n\")    \n",
    "    print_ww(res[0]['generated_text'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Base Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 페루 오렌지 드레시 핸드백은 흠잡을 데 없습니다\n",
      "\n",
      "### 답변: 다음과 같으면 됩니다.\"흠 잡기 어려운\"이라는 단어는 \"완벽한\", 또는 그에 상응한다고 볼 수 있으므로, 가방 자체가 완벽하고 결함이나 결점 없이 만들어졌다는 것으로\n",
      "해석할 수도있고 아닐수도 있지만 후자를 선택했다고 가정해 보겠니다 :\n",
      "\n",
      "\n",
      "> Fine-Tuned Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 페루 오렌지 드레시 핸드백은 흠잡을 데 없습니다\n",
      "\n",
      "### 답변:\n",
      "액세서리|핸드백\n"
     ]
    }
   ],
   "source": [
    "q = \"이 페루 오렌지 드레시 핸드백은 흠잡을 데 없습니다\" \n",
    "label = \"액세서리|핸드백\"\n",
    "run_comppare_result(question = q, \n",
    "                    label = label,\n",
    "                    prompt_template_object = prompt_template_object,\n",
    "                    base_model_endpoint_name = base_model_endpoint_name, \n",
    "                    fine_tuned_model_endpoint_name = fine_tuned_model_endpoint_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Base Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 부드러운 시에나 소파를 즐기세요\n",
      "\n",
      "### 답변:\n",
      "이 제품은 가구가 아닙니다\n",
      "\n",
      "\n",
      "> Fine-Tuned Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 부드러운 시에나 소파를 즐기세요\n",
      "\n",
      "### 답변:\n",
      "가구|소파\n"
     ]
    }
   ],
   "source": [
    "q = \"이 부드러운 시에나 소파를 즐기세요\" \n",
    "label = \"가구|소파\"\n",
    "run_comppare_result(question = q, \n",
    "                    label = label,\n",
    "                    prompt_template_object = prompt_template_object,\n",
    "                    base_model_endpoint_name = base_model_endpoint_name, \n",
    "                    fine_tuned_model_endpoint_name = fine_tuned_model_endpoint_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Base Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 맛있는 채소는 모든 식료품 저장실에 꼭 있어야 합니다\n",
      "\n",
      "### 답변: 맛이 좋고 신선한 녹색 잎채소를 찾으신다면 브로콜리와 케일은 훌륭합니다! 두 가지 모두 비타민, 미네랄 및 기타 영양소가 풍부하여 건강에 도움되며 다양하고 풍미있게\n",
      "요리할 수 있습니다.\"\n",
      "\n",
      "\n",
      "> Fine-Tuned Model: \n",
      "\n",
      "다음의 상품 설명을 분류하세요.\n",
      "### 상품 설명: 이 맛있는 채소는 모든 식료품 저장실에 꼭 있어야 합니다\n",
      "\n",
      "### 답변:\n",
      "식료품|야채\n"
     ]
    }
   ],
   "source": [
    "q = \"이 맛있는 채소는 모든 식료품 저장실에 꼭 있어야 합니다\" \n",
    "label = \"식료품|야채\"\n",
    "run_comppare_result(question = q, \n",
    "                    label = label,\n",
    "                    prompt_template_object = prompt_template_object,\n",
    "                    base_model_endpoint_name = base_model_endpoint_name, \n",
    "                    fine_tuned_model_endpoint_name = fine_tuned_model_endpoint_name)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 엔드포인트 삭제\n",
    "- SageMaker Console 에 가셔서 반드시 지위시기 바랍니다. 돈이 무지하게 발생 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![endpont.png](img/endpont.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
